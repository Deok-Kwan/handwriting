# ArcFace ê¸°ë°˜ MIL íŒŒì´í”„ë¼ì¸ ë°ì´í„° ìƒëª…ì£¼ê¸° ìƒì„¸ ë¶„ì„

> ğŸ“… ì‘ì„±ì¼: 2025ë…„ 8ì›” 3ì¼  
> ğŸ“ ì‘ì„±ì: ë°ì´í„° ì•„í‚¤í…íŠ¸  
> ğŸ¯ ëª©ì : ë³µìˆ˜ ì‘ì„±ì í•„ê¸° ë¬¸ì„œ íƒì§€ë¥¼ ìœ„í•œ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì˜ ë°ì´í„° íë¦„ ì™„ë²½ ì´í•´

## ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ë°ì´í„° ìƒëª…ì£¼ê¸° ìš”ì•½](#2-ë°ì´í„°-ìƒëª…ì£¼ê¸°-ìš”ì•½)
3. [Stage 0: ì›ì‹œ ë°ì´í„°](#3-stage-0-ì›ì‹œ-ë°ì´í„°)
4. [Stage 1: ArcFace íŠ¹ì§• ì¶”ì¶œ](#4-stage-1-arcface-íŠ¹ì§•-ì¶”ì¶œ)
5. [Stage 2: MIL Bag ìƒì„±](#5-stage-2-mil-bag-ìƒì„±)
6. [Stage 3: MIL ëª¨ë¸ í•™ìŠµ ë° í‰ê°€](#6-stage-3-mil-ëª¨ë¸-í•™ìŠµ-ë°-í‰ê°€)
7. [ë°ì´í„° ë³€í™˜ í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨](#7-ë°ì´í„°-ë³€í™˜-í”Œë¡œìš°-ë‹¤ì´ì–´ê·¸ë¨)
8. [í•µì‹¬ í†µì°° ë° ê²°ë¡ ](#8-í•µì‹¬-í†µì°°-ë°-ê²°ë¡ )

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ì—°êµ¬ ëª©í‘œ
**"í•˜ë‚˜ì˜ ë¬¸ì„œ ë‚´ì— ìˆ¨ê²¨ì§„ ë³µìˆ˜ ì‘ì„±ìë¥¼ ìë™ìœ¼ë¡œ íƒì§€í•˜ëŠ” AI ì‹œìŠ¤í…œ ê°œë°œ"**

ì „í†µì ì¸ í•„ê¸° ë¶„ì„ì´ ë‘ ë¬¸ì„œ ê°„ ë¹„êµì— ì¤‘ì ì„ ë‘”ë‹¤ë©´, ë³¸ ì—°êµ¬ëŠ” í•œ ë¬¸ì„œ ë‚´ë¶€ì˜ ë¯¸ë¬˜í•œ ë³€í™”ë¥¼ í¬ì°©í•˜ëŠ” í˜ì‹ ì  ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

### 1.2 í•µì‹¬ ë„ì „ ê³¼ì œ
- **ì•½ì§€ë„ í•™ìŠµ**: ê°œë³„ íŒ¨ì¹˜(ë‹¨ì–´)ì˜ ì‘ì„±ì ì •ë³´ ì—†ì´ ë¬¸ì„œ ì „ì²´ ìˆ˜ì¤€ì—ì„œë§Œ ë ˆì´ë¸” ì œê³µ
- **ë¯¸ì„¸í•œ ë³€í™” íƒì§€**: 5~30%ì˜ ì‘ì€ ë¹„ìœ¨ë¡œ ì„ì¸ ë‹¤ë¥¸ ì‘ì„±ìì˜ í•„ì  íƒì§€
- **ì¼ë°˜í™” ëŠ¥ë ¥**: í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ ì‘ì„±ìì— ëŒ€í•œ ì„±ëŠ¥ ìœ ì§€

### 1.3 ê¸°ìˆ  ìŠ¤íƒ
- **íŠ¹ì§• ì¶”ì¶œ**: Vision Transformer + ArcFace Loss
- **ì•½ì§€ë„ í•™ìŠµ**: Multiple Instance Learning (MIL)
- **í‰ê°€ í”„ë ˆì„ì›Œí¬**: ë‚œì´ë„ë³„ ì„±ëŠ¥ í‰ê°€ ì‹œìŠ¤í…œ

---

## 2. ë°ì´í„° ìƒëª…ì£¼ê¸° ìš”ì•½

### 2.1 ì „ì²´ íë¦„ ê°œìš”

```
ì´ë¯¸ì§€ íŒŒì¼ â†’ íŠ¹ì§• ë²¡í„° â†’ Instance â†’ Bag â†’ ì˜ˆì¸¡
   (í”½ì…€)      (128ì°¨ì›)    (5ë‹¨ì–´)   (10ë¬¸ì¥)  (í™•ë¥ )
```

### 2.2 ë‹¨ê³„ë³„ ë°ì´í„° ë³€í™˜ í…Œì´ë¸”

| ë‹¨ê³„ | ë°ì´í„° ë‹¨ìœ„ | í¬ë§· | ì°¨ì› | í¬ê¸° (ì˜ˆì‹œ) | ì˜ë¯¸ |
|------|------------|------|------|------------|------|
| **Stage 0** | ë‹¨ì–´ ì´ë¯¸ì§€ | .png | HÃ—WÃ—3 | 100Ã—50Ã—3 | ì›ë³¸ í•„ê¸°ì²´ ì´ë¯¸ì§€ |
| | ë©”íƒ€ë°ì´í„° | .csv | NÃ—4 | 351,311Ã—4 | ì´ë¯¸ì§€ ê²½ë¡œ, ì‘ì„±ì ì •ë³´ |
| **Stage 1** | íŠ¹ì§• ë²¡í„° | CSV í–‰ | 1Ã—128 | 1Ã—128 | ì´ë¯¸ì§€ì˜ ìˆ˜í•™ì  í‘œí˜„ |
| | ì„ë² ë”© íŒŒì¼ | .csv | NÃ—130 | 208,233Ã—130 | ì „ì²´ íŠ¹ì§• ë²¡í„° ì§‘í•© |
| **Stage 2** | Instance | ë©”ëª¨ë¦¬ | 5Ã—128 | 5Ã—128 | ì—°ì†ëœ 5ë‹¨ì–´ì˜ íŠ¹ì§• |
| | Bag | .pkl | 10Ã—5Ã—128 | 10Ã—5Ã—128 | ë¬¸ì„œë¥¼ í‘œí˜„í•˜ëŠ” 10ê°œ Instance |
| **Stage 3** | Attention | ë°°ì—´ | 10 | 10 | Instanceë³„ ì¤‘ìš”ë„ |
| | ì˜ˆì¸¡ í™•ë¥  | ìŠ¤ì¹¼ë¼ | 1 | 1 | ë³µìˆ˜ ì‘ì„±ì í™•ë¥  |

---

## 3. Stage 0: ì›ì‹œ ë°ì´í„°

### 3.1 ë°ì´í„°ì…‹ êµ¬ì¡°

```
/workspace/MIL/data/raw/
â”œâ”€â”€ csafe_version5_xai_train/          # ì´ë¯¸ì§€ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ 0/                             # ì‘ì„±ì 0ë²ˆ í´ë”
â”‚   â”‚   â”œâ”€â”€ 'YX'_17.png               # ë‹¨ì–´: 'YX', ë°˜ë³µ: 17
â”‚   â”‚   â”œâ”€â”€ -he_10.png                # ë‹¨ì–´: '-he', ë°˜ë³µ: 10
â”‚   â”‚   â””â”€â”€ ... (ì•½ 1,171ê°œ ì´ë¯¸ì§€)
â”‚   â”œâ”€â”€ 1/                             # ì‘ì„±ì 1ë²ˆ í´ë”
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ 299/                           # ì‘ì„±ì 299ë²ˆ í´ë”
â”‚       â””â”€â”€ ...
â””â”€â”€ naver_ocr.csv                      # ë©”íƒ€ë°ì´í„° (351,311 í–‰)
```

### 3.2 ë©”íƒ€ë°ì´í„° êµ¬ì¡° (naver_ocr.csv)

| ì»¬ëŸ¼ëª… | íƒ€ì… | ì„¤ëª… | ì˜ˆì‹œ |
|--------|------|------|------|
| image_path | string | ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ | "0/'YX'_17.png" |
| label | int | ì‘ì„±ì ID (0-299) | 0 |
| detected_word | string | OCRë¡œ ì¸ì‹ëœ ë‹¨ì–´ | "YX" |
| repetition | int | ë°˜ë³µ ë²ˆí˜¸ (0-26) | 17 |

### 3.3 ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œí† ì½œ
- **ì‘ì„±ì ìˆ˜**: 300ëª… (ID: 0~299)
- **ë°˜ë³µ íšŸìˆ˜**: 27íšŒ (3ì„¸ì…˜ Ã— 9íšŒ)
  - ì„¸ì…˜ 1: ë°˜ë³µ 0-8
  - ì„¸ì…˜ 2: ë°˜ë³µ 9-17
  - ì„¸ì…˜ 3: ë°˜ë³µ 18-26
- **í…ìŠ¤íŠ¸ ìœ í˜•**: WOZ, LND, PHR (ë¬¸í•™, í¸ì§€, êµ¬ë¬¸)
- **ì „ì²˜ë¦¬**: EasyOCRë¡œ ë‹¨ì–´ ë‹¨ìœ„ ë¶„í• 

### 3.4 ë°ì´í„° íŠ¹ì„±
```python
# ë°ì´í„° í†µê³„
ì´ ì´ë¯¸ì§€ ìˆ˜: 351,311ê°œ
ì‘ì„±ìë‹¹ í‰ê· : 1,171ê°œ
íŒŒì¼ í˜•ì‹: PNG (ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë˜ëŠ” RGB)
í•´ìƒë„: ê°€ë³€ (í‰ê·  100Ã—50 í”½ì…€)
```

---

## 4. Stage 1: ArcFace íŠ¹ì§• ì¶”ì¶œ

### 4.1 ì…ë ¥ ë°ì´í„°

**ë°ì´í„° ë¶„í•  ì „ëµ**:
```python
# ì „ì²´ 300ëª…ì„ 60:20:20 ë¹„ìœ¨ë¡œ ë¶„í• 
Train: ì‘ì„±ì 0-179 (180ëª…) â†’ 208,233 ì´ë¯¸ì§€
Val:   ì‘ì„±ì 180-239 (60ëª…) â†’ 70,533 ì´ë¯¸ì§€  
Test:  ì‘ì„±ì 240-299 (60ëª…) â†’ 72,457 ì´ë¯¸ì§€
```

**ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**:
```python
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomAffine(
        degrees=7,
        translate=(0.05, 0.05),
        scale=(0.95, 1.05),
        shear=10
    ),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                       std=[0.229, 0.224, 0.225])
])
```

### 4.2 ëª¨ë¸ ì•„í‚¤í…ì²˜

#### 4.2.1 Vision Transformer ë°±ë³¸
```python
class ViTArcFace(nn.Module):
    def __init__(self, num_classes=300, embedding_dim=128):
        # 1. Vision Transformer ë°±ë³¸
        self.backbone = timm.create_model('vit_base_patch16_224', 
                                        pretrained=True, 
                                        num_classes=0)
        
        # 2. ì„ë² ë”© íˆ¬ì˜ ë ˆì´ì–´
        self.embedding = nn.Sequential(
            nn.Linear(768, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(512, embedding_dim),  # 128ì°¨ì›
            nn.BatchNorm1d(embedding_dim)
        )
        
        # 3. ArcFace ë¶„ë¥˜ ë ˆì´ì–´
        self.arcface = ArcFaceLoss(embedding_dim, num_classes)
```

#### 4.2.2 ArcFace Loss êµ¬í˜„
```python
class ArcFaceLoss(nn.Module):
    def __init__(self, in_features, out_features, scale=30.0, margin=0.50):
        self.scale = scale      # ìŠ¤ì¼€ì¼ë§ íŒ©í„°
        self.margin = margin    # ê°ë„ ë§ˆì§„
        self.cos_m = torch.cos(margin)
        self.sin_m = torch.sin(margin)
```

**í•µì‹¬ ì›ë¦¬**: 
- ê°™ì€ í´ë˜ìŠ¤ì˜ íŠ¹ì§• ë²¡í„°ëŠ” ê°ë„ìƒ ê°€ê¹ê²Œ
- ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ íŠ¹ì§• ë²¡í„°ëŠ” ê°ë„ìƒ ë©€ê²Œ
- ë§ˆì§„ì„ ì¶”ê°€í•˜ì—¬ ë” ì—„ê²©í•œ ë¶„ë¥˜ ê²½ê³„ ìƒì„±

### 4.3 í•™ìŠµ ê³¼ì •

#### 4.3.1 í•˜ì´í¼íŒŒë¼ë¯¸í„°
```python
# ìµœì í™” ì„¤ì •
optimizer = AdamW(lr=1e-5, weight_decay=5e-4)
scheduler = OneCycleLR(
    max_lr=1e-4,
    epochs=30,
    pct_start=0.1,  # 10% warm-up
)

# í•™ìŠµ ì„¤ì •
batch_size = 64
num_gpus = 5
effective_batch_size = 320  # 64 Ã— 5
```

#### 4.3.2 í•™ìŠµ ê²°ê³¼
```
ìµœì¢… ê²€ì¦ ì„±ëŠ¥:
- AUC: 0.9240
- EER: 0.1361
- í•™ìŠµ ì‹œê°„: 4.04ì‹œê°„ (15 ì—í­)
- Early Stopping ë°œë™
```

### 4.4 ì¶œë ¥ ë°ì´í„°

#### 4.4.1 CSV íŒŒì¼ êµ¬ì¡°
```
mil_arcface_train_data.csv (307.72 MB)
â”œâ”€â”€ label (ì‘ì„±ì ID)
â”œâ”€â”€ path (ì´ë¯¸ì§€ ê²½ë¡œ)
â”œâ”€â”€ embedding_0
â”œâ”€â”€ embedding_1
â”œâ”€â”€ ...
â””â”€â”€ embedding_127
```

#### 4.4.2 ì„ë² ë”© íŠ¹ì„±
```python
# ì„ë² ë”© í†µê³„
í‰ê· : -0.0006
í‘œì¤€í¸ì°¨: 0.0884
L2 norm: 1.0000 (ì •ê·œí™”ë¨)
ì°¨ì›: 128
```

**í•µì‹¬ ë³€í™˜**: ì´ë¯¸ì§€(í”½ì…€) â†’ 128ì°¨ì› ë²¡í„°(í•„ì²´ì˜ ìˆ˜í•™ì  ì§€ë¬¸)

---

## 5. Stage 2: MIL Bag ìƒì„±

### 5.1 ì…ë ¥ ì²˜ë¦¬

```python
# CSV ë¡œë“œ
df_train = pd.read_csv("mil_arcface_train_data.csv")  # 208,233 í–‰
df_val = pd.read_csv("mil_arcface_val_data.csv")      # 70,533 í–‰
df_test = pd.read_csv("mil_arcface_test_data.csv")    # 72,457 í–‰
```

### 5.2 Instance ìƒì„± ê³¼ì •

#### 5.2.1 ë¬¸ì„œ ì¬êµ¬ì„±
```python
# ë¬¸ì„œ í‚¤ ìƒì„±: ì‘ì„±ìID + ì„¸ì…˜
def get_session(path):
    rep_num = int(path.split('_')[-1].split('.')[0])
    return rep_num // 9  # 3ê°œ ì„¸ì…˜ìœ¼ë¡œ ê·¸ë£¹í™”

df["doc_key"] = f"{label}/session_{get_session(path)}"
# ì˜ˆ: "0/session_0", "0/session_1", "0/session_2"
```

#### 5.2.2 ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
```python
# í•˜ì´í¼íŒŒë¼ë¯¸í„°
window_size = 5    # 5ê°œ ë‹¨ì–´ = 1 Instance
stride = 1         # 1ë‹¨ì–´ì”© ì´ë™
block_size = 10    # 10 Instance = 1 Bag

# Instance ìƒì„±
for start in range(0, len(doc) - window_size + 1, stride):
    instance = embeddings[start:start+window_size]  # (5, 128)
```

**ì‹œê°í™”**:
```
ë¬¸ì„œ: [w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, ...]
        â””â”€â”€â”€â”€â”€Instance1â”€â”€â”€â”€â”€â”˜
           â””â”€â”€â”€â”€â”€Instance2â”€â”€â”€â”€â”€â”˜
              â””â”€â”€â”€â”€â”€Instance3â”€â”€â”€â”€â”€â”˜
```

### 5.3 Bag í•©ì„± ì „ëµ

#### 5.3.1 Positive Bag (ë‹¨ì¼ ì‘ì„±ì)
```python
# í•œ ì‘ì„±ìì˜ 10ê°œ ì—°ì† Instance
positive_bag = {
    "bag_emb": base_emb,        # (10, 5, 128)
    "bag_label": 0,             # ë‹¨ì¼ ì‘ì„±ì
    "writer": base_writer,
    "neg_ratio": 0.0
}
```

#### 5.3.2 Negative Bag (ë³µìˆ˜ ì‘ì„±ì)
```python
# ë‚œì´ë„ë³„ ìœ„ì¡° ë¹„ìœ¨
neg_mix_ratio = [0.05, 0.10, 0.20, 0.30]

for ratio in neg_mix_ratio:
    k_replace = max(1, int(10 * ratio))  # êµì²´í•  Instance ìˆ˜
    # ë‹¤ë¥¸ ì‘ì„±ìì˜ Instanceë¡œ êµì²´
    negative_bag = {
        "bag_emb": mixed_emb,    # (10, 5, 128)
        "bag_label": 1,          # ë³µìˆ˜ ì‘ì„±ì
        "neg_ratio": ratio       # ìœ„ì¡° ë¹„ìœ¨
    }
```

**ìœ„ì¡° ì‹œë®¬ë ˆì´ì…˜**:
```
ì›ë³¸ Bag: [A, A, A, A, A, A, A, A, A, A]  (ì‘ì„±ì A)

5% ìœ„ì¡°:  [A, A, A, A, A, A, A, A, A, B]  (1ê°œ êµì²´)
10% ìœ„ì¡°: [A, A, A, A, A, A, A, A, B, B]  (1ê°œ êµì²´, ìµœì†Œ ë³´ì¥)
20% ìœ„ì¡°: [A, A, A, A, A, A, A, A, B, B]  (2ê°œ êµì²´)
30% ìœ„ì¡°: [A, A, A, A, A, A, A, B, B, B]  (3ê°œ êµì²´)
```

### 5.4 í´ë˜ìŠ¤ ê· í˜• ì¡°ì •

```python
# ì›ë³¸ ë¹„ìœ¨ (1:4)
Positive bags: 4,321ê°œ
Negative bags: 17,284ê°œ

# ê· í˜• ì¡°ì • í›„ (1:2)
Positive bags: 4,321ê°œ
Negative bags: 8,642ê°œ
Total: 12,963ê°œ

# ë‚œì´ë„ë³„ ê· ë“± ë¶„í¬
ê° neg_ratioë‹¹: 2,160ê°œ (25%)
```

### 5.5 ì¶œë ¥ ë°ì´í„°

#### 5.5.1 Pickle íŒŒì¼ êµ¬ì¡°
```python
bags = [
    {
        "bag_emb": np.array(10, 5, 128),  # 10ê°œ Instance
        "bag_label": 0 or 1,               # í´ë˜ìŠ¤
        "writer": int,                     # ê¸°ì¤€ ì‘ì„±ì
        "doc": str,                        # ë¬¸ì„œ ID
        "neg_ratio": float,                # ìœ„ì¡° ë¹„ìœ¨
        "bag_id": str                      # ê³ ìœ  ID
    },
    ...
]
```

#### 5.5.2 ë°ì´í„° í¬ê¸°
```
Train: bags_arcface_margin_0.4_train.pkl (12,963 bags)
Val:   bags_arcface_margin_0.4_val.pkl   (4,320 bags)
Test:  bags_arcface_margin_0.4_test.pkl  (4,320 bags)
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~0.62 GB
```

---

## 6. Stage 3: MIL ëª¨ë¸ í•™ìŠµ ë° í‰ê°€

### 6.1 ëª¨ë¸ ì•„í‚¤í…ì²˜

#### 6.1.1 Attention-based MIL
```python
class AttentionMIL(nn.Module):
    def __init__(self, inst_dim=256, hidden=128):
        # 1. Instance íˆ¬ì˜
        self.proj = nn.Linear(inst_dim, hidden)
        
        # 2. Attention ë„¤íŠ¸ì›Œí¬
        self.attn = nn.Sequential(
            nn.Tanh(),
            nn.Linear(hidden, 1)
        )
        
        # 3. ë¶„ë¥˜ê¸°
        self.classifier = nn.Sequential(
            nn.ReLU(),
            nn.Linear(hidden, 1)
        )
```

#### 6.1.2 Forward Pass
```python
def forward(self, x):  # x: (B, 10, 5, 128)
    # 1. Mean pooling over words
    x = x.mean(dim=2)  # (B, 10, 128)
    
    # 2. Project to hidden space
    h = self.proj(x)   # (B, 10, 128)
    
    # 3. Calculate attention
    a = self.attn(h)   # (B, 10, 1)
    weights = torch.softmax(a, dim=1)
    
    # 4. Weighted aggregation
    m = (h * weights).sum(dim=1)  # (B, 128)
    
    # 5. Classification
    logits = self.classifier(m)    # (B, 1)
    
    return logits, weights
```

### 6.2 í•™ìŠµ ì „ëµ

#### 6.2.1 Balanced Sampling
```python
class PosNegBatchSampler:
    # ë°°ì¹˜ êµ¬ì„±: 50% Positive + 50% Negative
    # ëª©ì : í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
    batch_size = 64  # 32 pos + 32 neg
```

#### 6.2.2 ì´ì¤‘ ê²€ì¦ ì „ëµ
```python
# 1. ë¹ ë¥¸ ëª¨ë‹ˆí„°ë§: Balanced validation (F1 ê³„ì‚°)
val_loader_balanced  # 1:1 ë¹„ìœ¨ë¡œ ìƒ˜í”Œë§

# 2. ì •í™•í•œ ì„ê³„ê°’: Natural distribution
val_loader_natural   # ì‹¤ì œ ë¶„í¬ ìœ ì§€ (1:2)
```

#### 6.2.3 OneCycleLR ìŠ¤ì¼€ì¤„ë§
```
ì—í­ 1-4:   Warm-up (1e-5 â†’ 1e-4)
ì—í­ 5:     Peak (1e-4)
ì—í­ 6-9:   Annealing (1e-4 â†’ 1e-6)
Early Stop: ì—í­ 9ì—ì„œ ë°œë™
```

### 6.3 ì„±ëŠ¥ í‰ê°€

#### 6.3.1 ì „ì²´ ì„±ëŠ¥
```
Validation (Best):
- F1 Score: 0.660
- AUC: 0.652
- Threshold: 0.497

Test Set:
- F1 Score: 0.756
- Recall: 0.807
- AUC: 0.635
```

#### 6.3.2 ë‚œì´ë„ë³„ ì„±ëŠ¥

| ìœ„ì¡° ë¹„ìœ¨ | F1 Score | Recall | ìƒ˜í”Œ ìˆ˜ |
|----------|----------|--------|---------|
| 0% (ì§„ë³¸) | 0.000 | 0.000 | 1,440 |
| 5% | 0.838 | 0.721 | 720 |
| 10% | 0.861 | 0.756 | 720 |
| 20% | 0.903 | 0.824 | 720 |
| 30% | 0.963 | 0.928 | 720 |

**í•´ì„**: 
- 0% (ì§„ë³¸)ì˜ F1=0ì€ ëª¨ë“  ì§„ë³¸ì„ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜í–ˆìŒì„ ì˜ë¯¸
- ìœ„ì¡° ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ íƒì§€ê°€ ì‰¬ì›Œì§

### 6.4 Attention ë¶„ì„

**Single Writer Bag**:
```
Attention ë¶„í¬: ê· ë“± (0.08~0.12)
í•´ì„: ëª¨ë“  Instanceê°€ ë¹„ìŠ·í•œ íŒ¨í„´
```

**Multi Writer Bag**:
```
Attention ë¶„í¬: ë¶ˆê· ë“± (0.02~0.25)
í•´ì„: íŠ¹ì • Instanceì— ë†’ì€ ì£¼ëª©
```

---

## 7. ë°ì´í„° ë³€í™˜ í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

### 7.1 ì „ì²´ íŒŒì´í”„ë¼ì¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Stage 0       â”‚     â”‚   Stage 1       â”‚     â”‚   Stage 2       â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚  Image Files    â”‚ --> â”‚  Feature Ext.   â”‚ --> â”‚  Bag Creation   â”‚
â”‚  (351KÃ—HÃ—WÃ—3)  â”‚     â”‚  (351KÃ—128)     â”‚     â”‚  (21K Bags)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          |
                                                          v
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Stage 3       â”‚     â”‚   Output        â”‚
                        â”‚                 â”‚     â”‚                 â”‚
                        â”‚  MIL Training   â”‚ --> â”‚  Predictions    â”‚
                        â”‚  (Attention)    â”‚     â”‚  (Probability)  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 ë°ì´í„° ì°¨ì› ë³€í™”

```
Stage 0: ì´ë¯¸ì§€ (HÃ—WÃ—3)
         â†“ [Vision Transformer]
Stage 1: ë²¡í„° (1Ã—128)
         â†“ [Sliding Window]
Stage 2: Instance (5Ã—128)
         â†“ [Blocking]
         Bag (10Ã—5Ã—128)
         â†“ [Attention MIL]
Stage 3: í™•ë¥  (1)
```

### 7.3 ìƒ˜í”Œ ìˆ˜ ë³€í™”

```
ì›ì‹œ ì´ë¯¸ì§€:     351,311ê°œ
    â†“
íŠ¹ì§• ë²¡í„°:       351,311ê°œ (1:1)
    â†“
Instance:        346,429ê°œ (ìŠ¬ë¼ì´ë”©)
    â†“
Bag (ì›ë³¸):      21,605ê°œ
    â†“
Bag (ê· í˜•í™”):    12,963ê°œ (Train)
```

---

## 8. í•µì‹¬ í†µì°° ë° ê²°ë¡ 

### 8.1 ê¸°ìˆ ì  í†µì°°

1. **ArcFaceì˜ íš¨ê³¼ì„±**
   - 128ì°¨ì›ì˜ compactí•œ í‘œí˜„ìœ¼ë¡œë„ 300ëª… ì‘ì„±ì êµ¬ë¶„ ê°€ëŠ¥
   - L2 ì •ê·œí™”ëœ ì„ë² ë”©ì´ ì•ˆì •ì ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì œê³µ

2. **MILì˜ ì í•©ì„±**
   - ì•½ì§€ë„ í•™ìŠµìœ¼ë¡œ ë¼ë²¨ë§ ë¹„ìš© ëŒ€í­ ì ˆê°
   - Instance ìˆ˜ì¤€ì˜ Attentionìœ¼ë¡œ í•´ì„ ê°€ëŠ¥ì„± ì œê³µ

3. **ë‚œì´ë„ë³„ ì„±ëŠ¥ íŒ¨í„´**
   - 5% ìœ„ì¡°ë„ 83.8% F1ë¡œ íƒì§€ ê°€ëŠ¥
   - ìœ„ì¡° ë¹„ìœ¨ ì¦ê°€ ì‹œ ì„±ëŠ¥ í–¥ìƒ (ë” ëª…í™•í•œ íŒ¨í„´)

### 8.2 ê°œì„  ë°©í–¥

1. **ë°ì´í„° ì¦ê°•**
   - ë” ë‹¤ì–‘í•œ ìœ„ì¡° íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜
   - ì‹¤ì œ ìœ„ì¡° ë¬¸ì„œ ë°ì´í„° ìˆ˜ì§‘

2. **ëª¨ë¸ ê³ ë„í™”**
   - Transformer ê¸°ë°˜ MIL ì•„í‚¤í…ì²˜
   - Multi-scale attention ë©”ì»¤ë‹ˆì¦˜

3. **ì‹¤ìš©í™”**
   - í•œêµ­ì–´ í•„ê¸°ì²´ ì ìš©
   - ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”

### 8.3 ê²°ë¡ 

ë³¸ íŒŒì´í”„ë¼ì¸ì€ ì´ë¯¸ì§€ì—ì„œ ì‹œì‘í•˜ì—¬ ë³µìˆ˜ ì‘ì„±ì í™•ë¥ ê¹Œì§€, ë°ì´í„°ì˜ ì ì§„ì  ì¶”ìƒí™” ê³¼ì •ì„ í†µí•´ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ê° ë‹¨ê³„ëŠ” ëª…í™•í•œ ëª©ì ê³¼ ë³€í™˜ ë¡œì§ì„ ê°€ì§€ë©°, ì „ì²´ê°€ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ì„±ê³¼**:
- Test F1: 75.6% (ì‹¤ìš© ê°€ëŠ¥ ìˆ˜ì¤€)
- 5% ìœ„ì¡° íƒì§€: 83.8% F1
- í•´ì„ ê°€ëŠ¥í•œ Attention ë©”ì»¤ë‹ˆì¦˜

ì´ëŠ” ë²•ì˜í•™ ë¬¸ì„œ ë¶„ì„ ë¶„ì•¼ì—ì„œ AIì˜ ì‹¤ì§ˆì  í™œìš© ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ì§„ì „ì…ë‹ˆë‹¤.

---

## ë¶€ë¡ A: ì£¼ìš” ì½”ë“œ ìŠ¤ë‹ˆí«

### A.1 ArcFace Loss ê³„ì‚°
```python
def forward(self, input, label):
    # ì •ê·œí™”
    input = F.normalize(input)
    weight = F.normalize(self.weight)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    cosine = F.linear(input, weight)
    
    # ë§ˆì§„ ì¶”ê°€
    phi = cosine * self.cos_m - sine * self.sin_m
    
    # One-hot ì¸ì½”ë”©
    one_hot = torch.zeros_like(cosine)
    one_hot.scatter_(1, label.view(-1, 1), 1)
    
    # ìµœì¢… ì¶œë ¥
    output = (one_hot * phi) + ((1.0 - one_hot) * cosine)
    return output * self.scale
```

### A.2 Bag ìƒì„± í•µì‹¬ ë¡œì§
```python
def synthesize_bags(inst_list, neg_source):
    # Positive Bag
    positive_bag = {
        "bag_emb": base_emb,
        "bag_label": 0,
        "neg_ratio": 0.0
    }
    
    # Negative Bags
    for ratio in [0.05, 0.10, 0.20, 0.30]:
        k_replace = max(1, int(10 * ratio))
        # Instance êµì²´ ë¡œì§
        negative_bag = {
            "bag_emb": mixed_emb,
            "bag_label": 1,
            "neg_ratio": ratio
        }
```

---

## ë¶€ë¡ B: íŒŒì¼ ì‹œìŠ¤í…œ êµ¬ì¡°

```
/workspace/MIL/
â”œâ”€â”€ experiments/arcface/
â”‚   â”œâ”€â”€ train_arcface.ipynb              # Stage 1
â”‚   â”œâ”€â”€ mil_data_generator2_arcface.ipynb # Stage 2
â”‚   â””â”€â”€ AB_MIL_arcface_256d.ipynb        # Stage 3
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ csafe_version5_xai_train/    # ì›ë³¸ ì´ë¯¸ì§€
â”‚   â”‚   â””â”€â”€ naver_ocr.csv                # ë©”íƒ€ë°ì´í„°
â”‚   â”‚
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ embeddings/                  # Stage 1 ì¶œë ¥
â”‚       â”‚   â”œâ”€â”€ mil_arcface_train_data.csv
â”‚       â”‚   â”œâ”€â”€ mil_arcface_val_data.csv
â”‚       â”‚   â””â”€â”€ mil_arcface_test_data.csv
â”‚       â”‚
â”‚       â””â”€â”€ bags/                        # Stage 2 ì¶œë ¥
â”‚           â”œâ”€â”€ bags_arcface_margin_0.4_train.pkl
â”‚           â”œâ”€â”€ bags_arcface_margin_0.4_val.pkl
â”‚           â””â”€â”€ bags_arcface_margin_0.4_test.pkl
â”‚
â””â”€â”€ output/arcface_margin_0.4_*/         # Stage 3 ì¶œë ¥
    â”œâ”€â”€ models/
    â”‚   â””â”€â”€ mil_best.pth
    â”œâ”€â”€ figures/
    â”‚   â”œâ”€â”€ training_curves.png
    â”‚   â”œâ”€â”€ test_results.png
    â”‚   â””â”€â”€ attention_analysis.png
    â””â”€â”€ results/
        â””â”€â”€ experiment_results.json
```

---

*ì´ ë¬¸ì„œëŠ” ArcFace ê¸°ë°˜ MIL íŒŒì´í”„ë¼ì¸ì˜ ë°ì´í„° íë¦„ì„ ì™„ë²½íˆ ì´í•´í•˜ê¸° ìœ„í•œ ê¸°ìˆ  ë¬¸ì„œì…ë‹ˆë‹¤.*