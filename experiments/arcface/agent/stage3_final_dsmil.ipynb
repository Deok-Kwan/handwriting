{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c918235",
   "metadata": {},
   "source": "# Stage 3 Final DS-MIL: Fair Comparison with Baseline\n\nì´ ë…¸íŠ¸ë¶ì€ Stage 2ì—ì„œ ìƒì„±í•œ MIL Bag ë°ì´í„°ë¥¼ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„ DS-MIL (Dual-Stream Multiple Instance Learning) ëª¨ë¸ì„ í•™ìŠµí•˜ê³  baseline AttentionMILê³¼ ê³µì •í•œ ë¹„êµë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n\n## ì‹¤í—˜ ëª©ì \n- **ê³µì •í•œ ë¹„êµ**: baseline AttentionMILê³¼ ë™ì¼í•œ ì¡°ê±´ì—ì„œ DS-MIL ì„±ëŠ¥ í‰ê°€\n- **DS-MIL íš¨ê³¼ ê²€ì¦**: dual-stream architectureê°€ ë‹¨ì¼ attention ë°©ì‹ë³´ë‹¤ ìš°ìˆ˜í•œì§€ í™•ì¸\n- **ì•„í‚¤í…ì²˜ ë¶„ì„**: critical instance identificationê³¼ cross-attentionì˜ íš¨ê³¼ ë¶„ì„\n\n## ì‹¤í—˜ ì¡°ê±´ (Baselineê³¼ ë™ì¼)\n1. **ë°ì´í„°ì…‹**: `bags_arcface_margin_0.4_50p_random_*.pkl` (baselineê³¼ ë™ì¼)\n2. **ì†ì‹¤í•¨ìˆ˜**: WeightedBCE(fp_weight=2.0)\n3. **ìµœì í™”**: Adam optimizer (lr=1e-3), ReduceLROnPlateau scheduler\n4. **ìž„ê³„ê°’ ìµœì í™”**: validation setì—ì„œ F1 score ê¸°ì¤€ìœ¼ë¡œ ìµœì  threshold ì„ íƒ\n5. **í‰ê°€ ì§€í‘œ**: Accuracy, F1, Precision, Recall, AUC\n\n## DS-MIL vs AttentionMIL ì•„í‚¤í…ì²˜ ì°¨ì´ì \n\n### AttentionMIL (Baseline)\n```\ninstances â†’ attention â†’ bag_representation â†’ classifier â†’ prediction\n```\n\n### DS-MIL (This Work)\n```\ninstances â†’ instance_classifier â†’ critical_instance_identification\n         â†“\n         cross_attention â†’ bag_representation â†’ bag_classifier â†’ prediction\n```\n\n**í•µì‹¬ ì°¨ì´ì :**\n- **Dual Loss**: bag-level + instance-level loss ë™ì‹œ ì‚¬ìš©\n- **Critical Instance**: ê° bagì—ì„œ ê°€ìž¥ ì¤‘ìš”í•œ instance ìžë™ ì‹ë³„\n- **Cross-Attention**: critical instanceë¥¼ queryë¡œ ì‚¬ìš©í•˜ëŠ” attention mechanism"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39044d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:37:59.377065Z",
     "start_time": "2025-08-10T10:37:47.818164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, roc_curve, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = os.getenv('MIL_STAGE3_GPU', '3')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.')\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742eb10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:00.535620Z",
     "start_time": "2025-08-10T10:37:59.381977Z"
    }
   },
   "outputs": [],
   "source": "# Stage 2 Bag ë°ì´í„° ë¡œë“œ ë° Instance í‰ê·  ê³„ì‚°\n# baselineê³¼ ë™ì¼í•œ ë°ì´í„°ì…‹ ì‚¬ìš© (random)\nembedding_margin = '0.4'\nbags_dir = '/workspace/MIL/data/processed/bags'\ntrain_pkl = os.path.join(bags_dir, f'bags_arcface_margin_{embedding_margin}_50p_random_train.pkl')\nval_pkl   = os.path.join(bags_dir, f'bags_arcface_margin_{embedding_margin}_50p_random_val.pkl')\ntest_pkl  = os.path.join(bags_dir, f'bags_arcface_margin_{embedding_margin}_50p_random_test.pkl')\n\nprint('Loading MIL bags...')\ntry:\n    with open(train_pkl, 'rb') as f:\n        train_data = pickle.load(f)\n    with open(val_pkl, 'rb') as f:\n        val_data = pickle.load(f)\n    with open(test_pkl, 'rb') as f:\n        test_data = pickle.load(f)\nexcept FileNotFoundError as e:\n    print(f'Error loading data files: {e}')\n    raise\nexcept Exception as e:\n    print(f'Unexpected error loading data: {e}')\n    raise\n\n# Instance mean ê³„ì‚°: (10,5,256) â†’ (10,256)\n# ê° bagì˜ instanceë“¤ì„ í‰ê· ë‚´ì–´ ë” ê°„ë‹¨í•œ representation ìƒì„±\ndef to_instance_means(bags):\n    \"\"\"ê° bagì˜ instanceë“¤ì„ í‰ê· ë‚´ì–´ (num_instances, embedding_dim) í˜•íƒœë¡œ ë³€í™˜\"\"\"\n    return [bag.mean(axis=1).astype(np.float32) for bag in bags]\n\ntrain_features = to_instance_means(train_data['bags'])\nval_features   = to_instance_means(val_data['bags'])\ntest_features  = to_instance_means(test_data['bags'])\n\ntrain_labels = train_data['labels']\nval_labels   = val_data['labels']\ntest_labels  = test_data['labels']\n\nprint(f'Train bags: {len(train_labels)}, Val bags: {len(val_labels)}, Test bags: {len(test_labels)}')\nprint(f'Class distribution in train: {np.bincount(train_labels)}')\nprint(f'Class distribution in val: {np.bincount(val_labels)}')\nprint(f'Class distribution in test: {np.bincount(test_labels)}')"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17dbf94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:00.542991Z",
     "start_time": "2025-08-10T10:38:00.537605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset í´ëž˜ìŠ¤ (onâ€‘theâ€‘fly Tensor ë³€í™˜)\n",
    "\n",
    "class MILDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features  # list of np.ndarray\n",
    "        self.labels = labels      # list of int\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(MILDataset(train_features, train_labels), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(MILDataset(val_features,   val_labels),   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(MILDataset(test_features,  test_labels),  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79407013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:02.299004Z",
     "start_time": "2025-08-10T10:38:00.545364Z"
    }
   },
   "outputs": [],
   "source": "# ëª¨ë¸ ì •ì˜ ë° ì´ˆê¸°í™” í•¨ìˆ˜ â€“ DSMIL (Dualâ€‘Stream Multiple Instance Learning)\n\nclass DSMIL(nn.Module):\n    \"\"\"\n    Dualâ€‘Stream MIL model based on the DSMIL architecture.\n    \n    DS-MILì€ ë‘ ê°€ì§€ ìŠ¤íŠ¸ë¦¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n    1. Instance-level classifier: ê° instanceì˜ ì¤‘ìš”ë„ë¥¼ ì˜ˆì¸¡\n    2. Bag-level classifier: attentionì„ í†µí•´ ì „ì²´ bagì„ ë¶„ë¥˜\n    \n    ì£¼ìš” íŠ¹ì§•:\n    - Critical instance identification: instance classifierë¡œ ê°€ìž¥ ì¤‘ìš”í•œ instance ì‹ë³„\n    - Cross-attention: critical instanceë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ instanceë“¤ì˜ ê°€ì¤‘ì¹˜ ê³„ì‚°\n    - Dual loss: bag-levelê³¼ instance-level lossë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ\n    \"\"\"\n    def __init__(self, input_dim=256, att_dim=128, dropout=0.1):\n        super().__init__()\n        # Instance classifier: predicts a score per instance\n        self.instance_fc = nn.Linear(input_dim, 1)\n        # Query network for attention\n        self.q_net = nn.Sequential(\n            nn.Linear(input_dim, att_dim),\n            nn.ReLU(),\n            nn.Linear(att_dim, att_dim),\n            nn.Tanh(),\n        )\n        # Value network (with dropout)\n        self.v_net = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(input_dim, input_dim),\n            nn.ReLU(),\n        )\n        # Bag classifier: maps aggregated representation to a single logit\n        self.bag_fc = nn.Linear(input_dim, 1)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass.\n        Args:\n            x (Tensor): bag of instance features with shape (batch_size, num_instances, input_dim)\n        Returns:\n            bag_logits (Tensor): shape (batch_size,), logits for bag labels\n            inst_logits (Tensor): shape (batch_size, num_instances), logits for instances\n            att_weights (Tensor): shape (batch_size, num_instances), attention weights\n        \"\"\"\n        # Instance logits for each instance in the bag\n        inst_logits = self.instance_fc(x).squeeze(-1)  # (batch_size, num_instances)\n\n        # Identify the critical instance for each bag via the highest instance logit\n        top_indices = torch.argmax(inst_logits, dim=1)  # (batch_size,)\n\n        # Compute query vectors for all instances\n        Q = self.q_net(x)  # (batch_size, num_instances, att_dim)\n\n        # Extract the features of the critical instances and compute their queries\n        batch_indices = torch.arange(x.size(0), device=x.device)\n        m_feats = x[batch_indices, top_indices]  # (batch_size, input_dim)\n        q_max = self.q_net(m_feats)  # (batch_size, att_dim)\n\n        # Compute attention scores via the inner product between Q and q_max\n        att_scores = torch.bmm(Q, q_max.unsqueeze(-1)).squeeze(-1)  # (batch_size, num_instances)\n\n        # Normalize attention scores\n        att_weights = torch.softmax(att_scores / (Q.size(-1) ** 0.5), dim=1)  # (batch_size, num_instances)\n\n        # Compute value representations\n        V = self.v_net(x)  # (batch_size, num_instances, input_dim)\n\n        # Aggregate the values using attention weights\n        bag_repr = torch.bmm(att_weights.unsqueeze(1), V).squeeze(1)  # (batch_size, input_dim)\n\n        # Predict bag logits\n        bag_logits = self.bag_fc(bag_repr).squeeze(-1)  # (batch_size,)\n\n        return bag_logits, inst_logits, att_weights\n\nclass MeanPoolingModel(nn.Module):\n    \"\"\"\n    A simple baseline model that pools instance features by averaging and\n    produces a single logit per bag.\n    \"\"\"\n    def __init__(self, input_dim=256):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, 1)\n        nn.init.xavier_uniform_(self.fc.weight)\n        nn.init.zeros_(self.fc.bias)\n\n    def forward(self, x):\n        # Average pooling over instances\n        bag_mean = x.mean(dim=1)\n        logits = self.fc(bag_mean).squeeze(-1)\n        return logits\n\n# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤\nmil_model = DSMIL(input_dim=256, att_dim=128, dropout=0.1).to(device)\nbase_model = MeanPoolingModel(input_dim=256).to(device)\n\n# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” ê¸°ë²•\n# Note: A Weighted BCE loss will be defined in the training pipeline later\ncriterion = nn.BCEWithLogitsLoss()\noptimizer_mil  = torch.optim.Adam(mil_model.parameters(), lr=1e-3)\noptimizer_base = torch.optim.Adam(base_model.parameters(), lr=1e-3)\nscheduler_mil  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_mil, mode='max', factor=0.5, patience=1, verbose=True)\nscheduler_base = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_base, mode='max', factor=0.5, patience=1, verbose=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb9c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:02.315033Z",
     "start_time": "2025-08-10T10:38:02.301147Z"
    }
   },
   "outputs": [],
   "source": "# í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ (Early Stopping í¬í•¨)\n\ndef train_one_epoch(model, optimizer, loader):\n    \"\"\"í•œ ì—í¬í¬ í•™ìŠµ ìˆ˜í–‰\n    \n    DS-MILì˜ ê²½ìš° bag-levelê³¼ instance-level lossë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ\n    \"\"\"\n    model.train()\n    total_loss = 0.0\n    preds_all = []\n    labels_all = []\n    \n    for X, y in tqdm(loader, desc='Train', leave=False):\n        X, y = X.to(device), y.to(device)\n        optimizer.zero_grad()\n        \n        try:\n            # DS-MIL ëª¨ë¸ì¸ì§€ í™•ì¸\n            if isinstance(model, DSMIL):\n                bag_logits, inst_logits, _ = model(X)\n                # Critical instanceì˜ logit ì¶”ì¶œ (ê° bagì—ì„œ ìµœëŒ€ê°’)\n                top_logits = inst_logits.max(dim=1).values\n                \n                # Dual loss ê³„ì‚°: bag-level + instance-level\n                loss_bag = criterion(bag_logits, y)\n                loss_top = criterion(top_logits, y)\n                loss = loss_bag + loss_top\n                \n                # ìµœì¢… ì˜ˆì¸¡ì€ bag-level logits ì‚¬ìš©\n                logits = bag_logits\n            else:\n                # ë‹¤ë¥¸ ëª¨ë¸ë“¤ ì²˜ë¦¬\n                logits = model(X)[0] if hasattr(model, 'instance_fc') else model(X)\n                loss = criterion(logits, y)\n            \n            loss.backward()\n            # Gradient clippingìœ¼ë¡œ ì•ˆì •ì  í•™ìŠµ\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            total_loss += loss.item() * y.size(0)\n            preds = (torch.sigmoid(logits) >= 0.5).float()\n            preds_all.extend(preds.cpu().numpy())\n            labels_all.extend(y.cpu().numpy())\n            \n        except Exception as e:\n            print(f'Error in training step: {e}')\n            raise\n    \n    return total_loss / len(loader.dataset), accuracy_score(labels_all, preds_all)\n\ndef evaluate(model, loader):\n    \"\"\"ëª¨ë¸ í‰ê°€ ìˆ˜í–‰\n    \n    Returns:\n        tuple: (loss, accuracy, auc, f1, probabilities, labels, predictions)\n    \"\"\"\n    model.eval()\n    total_loss = 0.0\n    probs_all = []\n    preds_all = []\n    labels_all = []\n    \n    with torch.no_grad():\n        for X, y in tqdm(loader, desc='Eval', leave=False):\n            X, y = X.to(device), y.to(device)\n            \n            try:\n                if isinstance(model, DSMIL):\n                    bag_logits, inst_logits, _ = model(X)\n                    top_logits = inst_logits.max(dim=1).values\n                    \n                    # í‰ê°€ì‹œì—ë„ ë™ì¼í•œ loss ê³„ì‚°\n                    loss_bag = criterion(bag_logits, y)\n                    loss_top = criterion(top_logits, y)\n                    loss = loss_bag + loss_top\n                    \n                    logits = bag_logits\n                else:\n                    logits = model(X)[0] if hasattr(model, 'instance_fc') else model(X)\n                    loss = criterion(logits, y)\n                \n                total_loss += loss.item() * y.size(0)\n                probs = torch.sigmoid(logits)\n                preds = (probs >= 0.5).float()\n                \n                probs_all.extend(probs.cpu().numpy())\n                preds_all.extend(preds.cpu().numpy())\n                labels_all.extend(y.cpu().numpy())\n                \n            except Exception as e:\n                print(f'Error in evaluation step: {e}')\n                raise\n    \n    # ë©”íŠ¸ë¦­ ê³„ì‚°\n    acc = accuracy_score(labels_all, preds_all)\n    auc = roc_auc_score(labels_all, probs_all) if len(set(labels_all)) > 1 else 0.0\n    f1 = f1_score(labels_all, preds_all) if len(set(preds_all)) > 1 else 0.0\n    \n    return total_loss / len(loader.dataset), acc, auc, f1, np.array(probs_all), np.array(labels_all), np.array(preds_all)\n\ndef train_model(model, optimizer, scheduler, train_loader, val_loader, max_epochs=10, patience=3, name='model'):\n    \"\"\"ì „ì²´ ëª¨ë¸ í•™ìŠµ ë£¨í”„ (Early Stopping í¬í•¨)\"\"\"\n    best_auc = 0.0\n    best_state = None\n    epochs_no_improve = 0\n    \n    print(f\"\\nStarting training for {name}...\")\n    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    \n    for epoch in range(1, max_epochs+1):\n        print(f\"\\nEpoch {epoch}/{max_epochs} â€“ {name}\")\n        tr_loss, tr_acc = train_one_epoch(model, optimizer, train_loader)\n        val_loss, val_acc, val_auc, val_f1, _, _, _ = evaluate(model, val_loader)\n        print(f\"  Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.4f}\")\n        print(f\"  Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, AUC: {val_auc:.4f}, F1: {val_f1:.4f}\")\n        \n        scheduler.step(val_auc)\n        \n        if val_auc > best_auc:\n            best_auc = val_auc\n            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n            torch.save(best_state, f'best_{name}.pth')\n            print(f\"  âœ… New best AUC: {best_auc:.4f} â€“ model saved.\")\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            print(f\"  No improvement. Patience: {epochs_no_improve}/{patience}\")\n            if epochs_no_improve >= patience:\n                print(\"  ðŸ›‘ Early stopping triggered.\")\n                break\n    \n    if best_state is not None:\n        model.load_state_dict(best_state)\n        print(f\"\\nLoaded best model with AUC: {best_auc:.4f}\")\n    \n    return model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c244e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:42.396780Z",
     "start_time": "2025-08-10T10:38:02.316983Z"
    }
   },
   "outputs": [],
   "source": "# ==============================================================================\n# Final Pipeline: DS-MIL training with validationâ€‘based threshold search\n#\n# ì´ ì…€ì€ baseline AttentionMILê³¼ ë™ì¼í•œ ì¡°ê±´ìœ¼ë¡œ DS-MIL ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤:\n# 1. ë™ì¼í•œ ë°ì´í„°ì…‹ ì‚¬ìš© (random split)\n# 2. ë™ì¼í•œ ì†ì‹¤í•¨ìˆ˜ (WeightedBCE, fp_weight=2.0)\n# 3. ë™ì¼í•œ threshold ìµœì í™” ë°©ì‹ (F1 ê¸°ì¤€)\n# \n# DS-MILì˜ í•µì‹¬ íŠ¹ì§•:\n# - Dual-stream architecture: bag-level + instance-level classification\n# - Critical instance identificationì„ í†µí•œ attention mechanism\n# - Dual lossë¡œ ë” robustí•œ í•™ìŠµ\n# ==============================================================================\n\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc, confusion_matrix\n\n# Define Weighted BCE loss - baselineê³¼ ë™ì¼í•œ ì„¤ì •\nclass WeightedBCE(nn.Module):\n    def __init__(self, fp_weight=2.0):\n        super().__init__()\n        self.fp_weight = fp_weight\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n    def forward(self, logits, labels):\n        loss = self.bce(logits, labels)\n        fp_mask = (labels == 0).float()\n        loss = loss * (1 + self.fp_weight * fp_mask)\n        return loss.mean()\n\n# Use Weighted BCE as the criterion for the DSMIL model\ncriterion = WeightedBCE(fp_weight=2.0)\nprint(\"Using WeightedBCE loss with fp_weight=2.0 (same as baseline)\")\n\n# Initialise a fresh DSMIL model\nmil_model_final = DSMIL(input_dim=256, att_dim=128, dropout=0.1).to(device)\noptimizer_final = torch.optim.Adam(mil_model_final.parameters(), lr=1e-3)\nscheduler_final = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer_final, mode='max', factor=0.5, patience=1, verbose=True\n)\n\n# Train the model\nmil_model_final = train_model(\n    mil_model_final, optimizer_final, scheduler_final,\n    train_loader, val_loader, max_epochs=10, patience=3, name='dsmil_final'\n)\n\n# Evaluate on validation and test\nval_loss_final, val_acc_final, val_auc_final, val_f1_final, val_probs_final, val_labels_final, _ = evaluate(\n    mil_model_final, val_loader\n)\ntest_loss_final, test_acc_final, test_auc_final, test_f1_final, test_probs_final, test_labels_final, _ = evaluate(\n    mil_model_final, test_loader\n)\n\n# Function to find best threshold based on F1 - baselineê³¼ ë™ì¼í•œ ë°©ì‹\ndef find_best_threshold(probs, labels):\n    \"\"\"F1 scoreë¥¼ ìµœëŒ€í™”í•˜ëŠ” threshold ì°¾ê¸°\"\"\"\n    best_thr, best_val = 0.5, 0.0\n    for thr in np.linspace(0.05, 0.95, 37):  # baselineê³¼ ë™ì¼í•œ ë²”ìœ„\n        preds = (probs >= thr).astype(int)\n        val = f1_score(labels, preds, zero_division=0)\n        if val > best_val:\n            best_val, best_thr = val, thr\n    return best_thr, best_val\n\n# Determine the best threshold on validation set\nbest_thr_final, best_f1_valid = find_best_threshold(val_probs_final, val_labels_final)\nprint(f'Best validation F1 threshold: {best_thr_final:.3f} (F1={best_f1_valid:.3f})')\n\n# Apply the threshold to test set\ntest_preds_adj_final = (test_probs_final >= best_thr_final).astype(int)\nacc_final = accuracy_score(test_labels_final, test_preds_adj_final)\nf1_final = f1_score(test_labels_final, test_preds_adj_final, zero_division=0)\nprec_final = precision_score(test_labels_final, test_preds_adj_final, zero_division=0)\nrecall_final = recall_score(test_labels_final, test_preds_adj_final, zero_division=0)\n\nprint('\\n' + '='*60)\nprint('DS-MIL FINAL RESULTS (vs Baseline Comparison)')\nprint('='*60)\nprint('Final test metrics (Weighted BCE + optimised threshold):')\nprint(f'  Accuracy: {acc_final:.3f}, F1: {f1_final:.3f}, Precision: {prec_final:.3f}, Recall: {recall_final:.3f}, AUC: {test_auc_final:.3f}')\nprint('\\nBaseline AttentionMIL Results (for comparison):')\nprint('  Accuracy: 0.792, F1: 0.759, Precision: 0.750, Recall: 0.768, AUC: 0.829')\nprint('\\nPerformance Comparison:')\nprint(f'  AUC improvement: {test_auc_final:.3f} - 0.829 = {test_auc_final - 0.829:+.3f}')\nprint(f'  F1 improvement: {f1_final:.3f} - 0.759 = {f1_final - 0.759:+.3f}')\nprint(f'  Accuracy improvement: {acc_final:.3f} - 0.792 = {acc_final - 0.792:+.3f}')\n\n# Confusion matrix\ncm_final = confusion_matrix(test_labels_final.astype(int), test_preds_adj_final.astype(int), labels=[0,1])\nplt.figure(figsize=(4,3))\nsns.heatmap(\n    cm_final, annot=True, fmt='d', cmap='Blues',\n    xticklabels=['Genuine','Forged'], yticklabels=['Genuine','Forged']\n)\nplt.title(f'DS-MIL Confusion Matrix (Thr={best_thr_final:.2f})')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.tight_layout()\nplt.show()\n\n# ROC curve with baseline comparison\nfpr_final, tpr_final, _ = roc_curve(test_labels_final, test_probs_final)\nauc_final_value = auc(fpr_final, tpr_final)\nplt.figure(figsize=(6,5))\nplt.plot(fpr_final, tpr_final, color='blue', linewidth=2, \n         label=f'DS-MIL (AUC={auc_final_value:.3f})')\nplt.axhline(y=0.829, color='red', linestyle='--', alpha=0.7, \n           label='Baseline AttentionMIL (AUC=0.829)')\nplt.plot([0,1],[0,1],'k--', alpha=0.5, label='Random')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve â€“ DS-MIL vs Baseline Comparison')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Summary of improvements\nprint('\\n' + '='*60)\nprint('PERFORMANCE ANALYSIS SUMMARY')\nprint('='*60)\nif test_auc_final > 0.829:\n    print(\"âœ… DS-MIL shows IMPROVEMENT over baseline AttentionMIL\")\n    print(f\"   - AUC improved by {test_auc_final - 0.829:.3f} points\")\nelse:\n    print(\"âŒ DS-MIL shows DECLINE compared to baseline AttentionMIL\")\n    print(f\"   - AUC decreased by {0.829 - test_auc_final:.3f} points\")\n\nif f1_final > 0.759:\n    print(f\"âœ… F1 Score improved by {f1_final - 0.759:.3f} points\")\nelse:\n    print(f\"âŒ F1 Score decreased by {0.759 - f1_final:.3f} points\")\n\nprint(f\"\\nKey factors in DS-MIL architecture:\")\nprint(f\"- Dual-stream learning (bag + instance level)\")\nprint(f\"- Critical instance identification\")\nprint(f\"- Cross-attention mechanism\")\nprint(f\"- Combined loss function (bag_loss + instance_loss)\")"
  },
  {
   "cell_type": "code",
   "id": "d4y2ol0yzuo",
   "source": "# ì‹¤í—˜ ê²°ê³¼ ì €ìž¥ ë° ìš”ì•½\nimport json\nfrom datetime import datetime\n\n# ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„±\nimport os\nos.makedirs('/workspace/MIL/output/results', exist_ok=True)\nos.makedirs('/workspace/MIL/output/models', exist_ok=True)\n\n# ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬\nresults = {\n    'experiment': 'DS-MIL vs AttentionMIL Comparison',\n    'timestamp': datetime.now().isoformat(),\n    'model': 'DS-MIL',\n    'data': {\n        'dataset': f'bags_arcface_margin_{embedding_margin}_50p_random',\n        'train_samples': len(train_labels),\n        'val_samples': len(val_labels), \n        'test_samples': len(test_labels),\n        'train_pos_ratio': np.mean(train_labels),\n        'val_pos_ratio': np.mean(val_labels),\n        'test_pos_ratio': np.mean(test_labels)\n    },\n    'model_config': {\n        'input_dim': 256,\n        'attention_dim': 128,\n        'dropout': 0.1,\n        'total_parameters': sum(p.numel() for p in mil_model_final.parameters())\n    },\n    'training': {\n        'loss_function': 'WeightedBCE',\n        'fp_weight': 2.0,\n        'optimizer': 'Adam',\n        'learning_rate': 1e-3,\n        'scheduler': 'ReduceLROnPlateau',\n        'max_epochs': 10,\n        'patience': 3,\n        'best_val_auc': float(val_auc_final)\n    },\n    'results': {\n        'validation': {\n            'loss': float(val_loss_final),\n            'accuracy': float(val_acc_final),\n            'auc': float(val_auc_final),\n            'f1': float(val_f1_final)\n        },\n        'test': {\n            'loss': float(test_loss_final),\n            'accuracy': float(acc_final),\n            'auc': float(test_auc_final), \n            'f1': float(f1_final),\n            'precision': float(prec_final),\n            'recall': float(recall_final),\n            'best_threshold': float(best_thr_final)\n        },\n        'baseline_comparison': {\n            'baseline_auc': 0.829,\n            'baseline_f1': 0.759,\n            'baseline_accuracy': 0.792,\n            'auc_improvement': float(test_auc_final - 0.829),\n            'f1_improvement': float(f1_final - 0.759),\n            'accuracy_improvement': float(acc_final - 0.792)\n        }\n    }\n}\n\n# JSONìœ¼ë¡œ ê²°ê³¼ ì €ìž¥\nresults_file = '/workspace/MIL/output/results/dsmil_vs_baseline_results.json'\nwith open(results_file, 'w') as f:\n    json.dump(results, f, indent=2)\n\n# ëª¨ë¸ ì €ìž¥\nmodel_file = '/workspace/MIL/output/models/dsmil_final_model.pth'\ntorch.save({\n    'model_state_dict': mil_model_final.state_dict(),\n    'model_config': results['model_config'],\n    'results': results['results']\n}, model_file)\n\nprint(f\"\\nðŸ“ Results saved to: {results_file}\")\nprint(f\"ðŸ”§ Model saved to: {model_file}\")\n\n# ìµœì¢… ìš”ì•½ ì¶œë ¥\nprint(f\"\\n{'='*80}\")\nprint(f\"EXPERIMENT COMPLETED: DS-MIL vs Baseline AttentionMIL\")\nprint(f\"{'='*80}\")\nprint(f\"Dataset: ArcFace margin {embedding_margin}, 50% positive, random split\")\nprint(f\"DS-MIL Parameters: {results['model_config']['total_parameters']:,}\")\nprint(f\"Training completed with best validation AUC: {val_auc_final:.4f}\")\nprint(f\"\\nFINAL TEST RESULTS:\")\nprint(f\"  DS-MIL:     AUC={test_auc_final:.3f}, F1={f1_final:.3f}, Acc={acc_final:.3f}\")\nprint(f\"  Baseline:   AUC=0.829, F1=0.759, Acc=0.792\")\nprint(f\"  Difference: AUC={test_auc_final-0.829:+.3f}, F1={f1_final-0.759:+.3f}, Acc={acc_final-0.792:+.3f}\")\n\nif test_auc_final > 0.829:\n    print(f\"ðŸŽ‰ DS-MIL OUTPERFORMS baseline by {test_auc_final-0.829:.3f} AUC points!\")\nelse:\n    print(f\"ðŸ“‰ DS-MIL underperforms baseline by {0.829-test_auc_final:.3f} AUC points.\")\n    \nprint(f\"{'='*80}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}