{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c918235",
   "metadata": {},
   "source": "# Stage 3 Final DS-MIL: Fair Comparison with Baseline\n\n이 노트북은 Stage 2에서 생성한 MIL Bag 데이터를 입력으로 받아 DS-MIL (Dual-Stream Multiple Instance Learning) 모델을 학습하고 baseline AttentionMIL과 공정한 비교를 수행합니다.\n\n## 실험 목적\n- **공정한 비교**: baseline AttentionMIL과 동일한 조건에서 DS-MIL 성능 평가\n- **DS-MIL 효과 검증**: dual-stream architecture가 단일 attention 방식보다 우수한지 확인\n- **아키텍처 분석**: critical instance identification과 cross-attention의 효과 분석\n\n## 실험 조건 (Baseline과 동일)\n1. **데이터셋**: `bags_arcface_margin_0.4_50p_random_*.pkl` (baseline과 동일)\n2. **손실함수**: WeightedBCE(fp_weight=2.0)\n3. **최적화**: Adam optimizer (lr=1e-3), ReduceLROnPlateau scheduler\n4. **임계값 최적화**: validation set에서 F1 score 기준으로 최적 threshold 선택\n5. **평가 지표**: Accuracy, F1, Precision, Recall, AUC\n\n## DS-MIL vs AttentionMIL 아키텍처 차이점\n\n### AttentionMIL (Baseline)\n```\ninstances → attention → bag_representation → classifier → prediction\n```\n\n### DS-MIL (This Work)\n```\ninstances → instance_classifier → critical_instance_identification\n         ↓\n         cross_attention → bag_representation → bag_classifier → prediction\n```\n\n**핵심 차이점:**\n- **Dual Loss**: bag-level + instance-level loss 동시 사용\n- **Critical Instance**: 각 bag에서 가장 중요한 instance 자동 식별\n- **Cross-Attention**: critical instance를 query로 사용하는 attention mechanism"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39044d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:37:59.377065Z",
     "start_time": "2025-08-10T10:37:47.818164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, roc_curve, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU 설정\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = os.getenv('MIL_STAGE3_GPU', '3')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('CUDA를 사용할 수 없습니다. CPU 모드로 실행됩니다.')\n",
    "\n",
    "# 시드 고정\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742eb10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:00.535620Z",
     "start_time": "2025-08-10T10:37:59.381977Z"
    }
   },
   "outputs": [],
   "source": "# Stage 2 Bag 데이터 로드 및 Instance 평균 계산\n# baseline과 동일한 데이터셋 사용 (random)\nembedding_margin = '0.4'\nbags_dir = '/workspace/MIL/data/processed/bags'\ntrain_pkl = os.path.join(bags_dir, f'bags_arcface_margin_{embedding_margin}_50p_random_train.pkl')\nval_pkl   = os.path.join(bags_dir, f'bags_arcface_margin_{embedding_margin}_50p_random_val.pkl')\ntest_pkl  = os.path.join(bags_dir, f'bags_arcface_margin_{embedding_margin}_50p_random_test.pkl')\n\nprint('Loading MIL bags...')\ntry:\n    with open(train_pkl, 'rb') as f:\n        train_data = pickle.load(f)\n    with open(val_pkl, 'rb') as f:\n        val_data = pickle.load(f)\n    with open(test_pkl, 'rb') as f:\n        test_data = pickle.load(f)\nexcept FileNotFoundError as e:\n    print(f'Error loading data files: {e}')\n    raise\nexcept Exception as e:\n    print(f'Unexpected error loading data: {e}')\n    raise\n\n# Instance mean 계산: (10,5,256) → (10,256)\n# 각 bag의 instance들을 평균내어 더 간단한 representation 생성\ndef to_instance_means(bags):\n    \"\"\"각 bag의 instance들을 평균내어 (num_instances, embedding_dim) 형태로 변환\"\"\"\n    return [bag.mean(axis=1).astype(np.float32) for bag in bags]\n\ntrain_features = to_instance_means(train_data['bags'])\nval_features   = to_instance_means(val_data['bags'])\ntest_features  = to_instance_means(test_data['bags'])\n\ntrain_labels = train_data['labels']\nval_labels   = val_data['labels']\ntest_labels  = test_data['labels']\n\nprint(f'Train bags: {len(train_labels)}, Val bags: {len(val_labels)}, Test bags: {len(test_labels)}')\nprint(f'Class distribution in train: {np.bincount(train_labels)}')\nprint(f'Class distribution in val: {np.bincount(val_labels)}')\nprint(f'Class distribution in test: {np.bincount(test_labels)}')"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17dbf94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:00.542991Z",
     "start_time": "2025-08-10T10:38:00.537605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset 클래스 (on‑the‑fly Tensor 변환)\n",
    "\n",
    "class MILDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features  # list of np.ndarray\n",
    "        self.labels = labels      # list of int\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(MILDataset(train_features, train_labels), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(MILDataset(val_features,   val_labels),   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(MILDataset(test_features,  test_labels),  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79407013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:02.299004Z",
     "start_time": "2025-08-10T10:38:00.545364Z"
    }
   },
   "outputs": [],
   "source": "# 모델 정의 및 초기화 함수 – DSMIL (Dual‑Stream Multiple Instance Learning)\n\nclass DSMIL(nn.Module):\n    \"\"\"\n    Dual‑Stream MIL model based on the DSMIL architecture.\n    \n    DS-MIL은 두 가지 스트림을 사용합니다:\n    1. Instance-level classifier: 각 instance의 중요도를 예측\n    2. Bag-level classifier: attention을 통해 전체 bag을 분류\n    \n    주요 특징:\n    - Critical instance identification: instance classifier로 가장 중요한 instance 식별\n    - Cross-attention: critical instance를 기준으로 다른 instance들의 가중치 계산\n    - Dual loss: bag-level과 instance-level loss를 모두 사용하여 학습\n    \"\"\"\n    def __init__(self, input_dim=256, att_dim=128, dropout=0.1):\n        super().__init__()\n        # Instance classifier: predicts a score per instance\n        self.instance_fc = nn.Linear(input_dim, 1)\n        # Query network for attention\n        self.q_net = nn.Sequential(\n            nn.Linear(input_dim, att_dim),\n            nn.ReLU(),\n            nn.Linear(att_dim, att_dim),\n            nn.Tanh(),\n        )\n        # Value network (with dropout)\n        self.v_net = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(input_dim, input_dim),\n            nn.ReLU(),\n        )\n        # Bag classifier: maps aggregated representation to a single logit\n        self.bag_fc = nn.Linear(input_dim, 1)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass.\n        Args:\n            x (Tensor): bag of instance features with shape (batch_size, num_instances, input_dim)\n        Returns:\n            bag_logits (Tensor): shape (batch_size,), logits for bag labels\n            inst_logits (Tensor): shape (batch_size, num_instances), logits for instances\n            att_weights (Tensor): shape (batch_size, num_instances), attention weights\n        \"\"\"\n        # Instance logits for each instance in the bag\n        inst_logits = self.instance_fc(x).squeeze(-1)  # (batch_size, num_instances)\n\n        # Identify the critical instance for each bag via the highest instance logit\n        top_indices = torch.argmax(inst_logits, dim=1)  # (batch_size,)\n\n        # Compute query vectors for all instances\n        Q = self.q_net(x)  # (batch_size, num_instances, att_dim)\n\n        # Extract the features of the critical instances and compute their queries\n        batch_indices = torch.arange(x.size(0), device=x.device)\n        m_feats = x[batch_indices, top_indices]  # (batch_size, input_dim)\n        q_max = self.q_net(m_feats)  # (batch_size, att_dim)\n\n        # Compute attention scores via the inner product between Q and q_max\n        att_scores = torch.bmm(Q, q_max.unsqueeze(-1)).squeeze(-1)  # (batch_size, num_instances)\n\n        # Normalize attention scores\n        att_weights = torch.softmax(att_scores / (Q.size(-1) ** 0.5), dim=1)  # (batch_size, num_instances)\n\n        # Compute value representations\n        V = self.v_net(x)  # (batch_size, num_instances, input_dim)\n\n        # Aggregate the values using attention weights\n        bag_repr = torch.bmm(att_weights.unsqueeze(1), V).squeeze(1)  # (batch_size, input_dim)\n\n        # Predict bag logits\n        bag_logits = self.bag_fc(bag_repr).squeeze(-1)  # (batch_size,)\n\n        return bag_logits, inst_logits, att_weights\n\nclass MeanPoolingModel(nn.Module):\n    \"\"\"\n    A simple baseline model that pools instance features by averaging and\n    produces a single logit per bag.\n    \"\"\"\n    def __init__(self, input_dim=256):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, 1)\n        nn.init.xavier_uniform_(self.fc.weight)\n        nn.init.zeros_(self.fc.bias)\n\n    def forward(self, x):\n        # Average pooling over instances\n        bag_mean = x.mean(dim=1)\n        logits = self.fc(bag_mean).squeeze(-1)\n        return logits\n\n# 모델 인스턴스\nmil_model = DSMIL(input_dim=256, att_dim=128, dropout=0.1).to(device)\nbase_model = MeanPoolingModel(input_dim=256).to(device)\n\n# 손실 함수 및 최적화 기법\n# Note: A Weighted BCE loss will be defined in the training pipeline later\ncriterion = nn.BCEWithLogitsLoss()\noptimizer_mil  = torch.optim.Adam(mil_model.parameters(), lr=1e-3)\noptimizer_base = torch.optim.Adam(base_model.parameters(), lr=1e-3)\nscheduler_mil  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_mil, mode='max', factor=0.5, patience=1, verbose=True)\nscheduler_base = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_base, mode='max', factor=0.5, patience=1, verbose=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb9c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:02.315033Z",
     "start_time": "2025-08-10T10:38:02.301147Z"
    }
   },
   "outputs": [],
   "source": "# 학습 및 평가 함수 (Early Stopping 포함)\n\ndef train_one_epoch(model, optimizer, loader):\n    \"\"\"한 에포크 학습 수행\n    \n    DS-MIL의 경우 bag-level과 instance-level loss를 모두 사용하여 학습\n    \"\"\"\n    model.train()\n    total_loss = 0.0\n    preds_all = []\n    labels_all = []\n    \n    for X, y in tqdm(loader, desc='Train', leave=False):\n        X, y = X.to(device), y.to(device)\n        optimizer.zero_grad()\n        \n        try:\n            # DS-MIL 모델인지 확인\n            if isinstance(model, DSMIL):\n                bag_logits, inst_logits, _ = model(X)\n                # Critical instance의 logit 추출 (각 bag에서 최대값)\n                top_logits = inst_logits.max(dim=1).values\n                \n                # Dual loss 계산: bag-level + instance-level\n                loss_bag = criterion(bag_logits, y)\n                loss_top = criterion(top_logits, y)\n                loss = loss_bag + loss_top\n                \n                # 최종 예측은 bag-level logits 사용\n                logits = bag_logits\n            else:\n                # 다른 모델들 처리\n                logits = model(X)[0] if hasattr(model, 'instance_fc') else model(X)\n                loss = criterion(logits, y)\n            \n            loss.backward()\n            # Gradient clipping으로 안정적 학습\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            total_loss += loss.item() * y.size(0)\n            preds = (torch.sigmoid(logits) >= 0.5).float()\n            preds_all.extend(preds.cpu().numpy())\n            labels_all.extend(y.cpu().numpy())\n            \n        except Exception as e:\n            print(f'Error in training step: {e}')\n            raise\n    \n    return total_loss / len(loader.dataset), accuracy_score(labels_all, preds_all)\n\ndef evaluate(model, loader):\n    \"\"\"모델 평가 수행\n    \n    Returns:\n        tuple: (loss, accuracy, auc, f1, probabilities, labels, predictions)\n    \"\"\"\n    model.eval()\n    total_loss = 0.0\n    probs_all = []\n    preds_all = []\n    labels_all = []\n    \n    with torch.no_grad():\n        for X, y in tqdm(loader, desc='Eval', leave=False):\n            X, y = X.to(device), y.to(device)\n            \n            try:\n                if isinstance(model, DSMIL):\n                    bag_logits, inst_logits, _ = model(X)\n                    top_logits = inst_logits.max(dim=1).values\n                    \n                    # 평가시에도 동일한 loss 계산\n                    loss_bag = criterion(bag_logits, y)\n                    loss_top = criterion(top_logits, y)\n                    loss = loss_bag + loss_top\n                    \n                    logits = bag_logits\n                else:\n                    logits = model(X)[0] if hasattr(model, 'instance_fc') else model(X)\n                    loss = criterion(logits, y)\n                \n                total_loss += loss.item() * y.size(0)\n                probs = torch.sigmoid(logits)\n                preds = (probs >= 0.5).float()\n                \n                probs_all.extend(probs.cpu().numpy())\n                preds_all.extend(preds.cpu().numpy())\n                labels_all.extend(y.cpu().numpy())\n                \n            except Exception as e:\n                print(f'Error in evaluation step: {e}')\n                raise\n    \n    # 메트릭 계산\n    acc = accuracy_score(labels_all, preds_all)\n    auc = roc_auc_score(labels_all, probs_all) if len(set(labels_all)) > 1 else 0.0\n    f1 = f1_score(labels_all, preds_all) if len(set(preds_all)) > 1 else 0.0\n    \n    return total_loss / len(loader.dataset), acc, auc, f1, np.array(probs_all), np.array(labels_all), np.array(preds_all)\n\ndef train_model(model, optimizer, scheduler, train_loader, val_loader, max_epochs=10, patience=3, name='model'):\n    \"\"\"전체 모델 학습 루프 (Early Stopping 포함)\"\"\"\n    best_auc = 0.0\n    best_state = None\n    epochs_no_improve = 0\n    \n    print(f\"\\nStarting training for {name}...\")\n    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    \n    for epoch in range(1, max_epochs+1):\n        print(f\"\\nEpoch {epoch}/{max_epochs} – {name}\")\n        tr_loss, tr_acc = train_one_epoch(model, optimizer, train_loader)\n        val_loss, val_acc, val_auc, val_f1, _, _, _ = evaluate(model, val_loader)\n        print(f\"  Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.4f}\")\n        print(f\"  Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, AUC: {val_auc:.4f}, F1: {val_f1:.4f}\")\n        \n        scheduler.step(val_auc)\n        \n        if val_auc > best_auc:\n            best_auc = val_auc\n            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n            torch.save(best_state, f'best_{name}.pth')\n            print(f\"  ✅ New best AUC: {best_auc:.4f} – model saved.\")\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            print(f\"  No improvement. Patience: {epochs_no_improve}/{patience}\")\n            if epochs_no_improve >= patience:\n                print(\"  🛑 Early stopping triggered.\")\n                break\n    \n    if best_state is not None:\n        model.load_state_dict(best_state)\n        print(f\"\\nLoaded best model with AUC: {best_auc:.4f}\")\n    \n    return model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c244e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:38:42.396780Z",
     "start_time": "2025-08-10T10:38:02.316983Z"
    }
   },
   "outputs": [],
   "source": "# ==============================================================================\n# Final Pipeline: DS-MIL training with validation‑based threshold search\n#\n# 이 셀은 baseline AttentionMIL과 동일한 조건으로 DS-MIL 모델을 학습합니다:\n# 1. 동일한 데이터셋 사용 (random split)\n# 2. 동일한 손실함수 (WeightedBCE, fp_weight=2.0)\n# 3. 동일한 threshold 최적화 방식 (F1 기준)\n# \n# DS-MIL의 핵심 특징:\n# - Dual-stream architecture: bag-level + instance-level classification\n# - Critical instance identification을 통한 attention mechanism\n# - Dual loss로 더 robust한 학습\n# ==============================================================================\n\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc, confusion_matrix\n\n# Define Weighted BCE loss - baseline과 동일한 설정\nclass WeightedBCE(nn.Module):\n    def __init__(self, fp_weight=2.0):\n        super().__init__()\n        self.fp_weight = fp_weight\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n    def forward(self, logits, labels):\n        loss = self.bce(logits, labels)\n        fp_mask = (labels == 0).float()\n        loss = loss * (1 + self.fp_weight * fp_mask)\n        return loss.mean()\n\n# Use Weighted BCE as the criterion for the DSMIL model\ncriterion = WeightedBCE(fp_weight=2.0)\nprint(\"Using WeightedBCE loss with fp_weight=2.0 (same as baseline)\")\n\n# Initialise a fresh DSMIL model\nmil_model_final = DSMIL(input_dim=256, att_dim=128, dropout=0.1).to(device)\noptimizer_final = torch.optim.Adam(mil_model_final.parameters(), lr=1e-3)\nscheduler_final = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer_final, mode='max', factor=0.5, patience=1, verbose=True\n)\n\n# Train the model\nmil_model_final = train_model(\n    mil_model_final, optimizer_final, scheduler_final,\n    train_loader, val_loader, max_epochs=10, patience=3, name='dsmil_final'\n)\n\n# Evaluate on validation and test\nval_loss_final, val_acc_final, val_auc_final, val_f1_final, val_probs_final, val_labels_final, _ = evaluate(\n    mil_model_final, val_loader\n)\ntest_loss_final, test_acc_final, test_auc_final, test_f1_final, test_probs_final, test_labels_final, _ = evaluate(\n    mil_model_final, test_loader\n)\n\n# Function to find best threshold based on F1 - baseline과 동일한 방식\ndef find_best_threshold(probs, labels):\n    \"\"\"F1 score를 최대화하는 threshold 찾기\"\"\"\n    best_thr, best_val = 0.5, 0.0\n    for thr in np.linspace(0.05, 0.95, 37):  # baseline과 동일한 범위\n        preds = (probs >= thr).astype(int)\n        val = f1_score(labels, preds, zero_division=0)\n        if val > best_val:\n            best_val, best_thr = val, thr\n    return best_thr, best_val\n\n# Determine the best threshold on validation set\nbest_thr_final, best_f1_valid = find_best_threshold(val_probs_final, val_labels_final)\nprint(f'Best validation F1 threshold: {best_thr_final:.3f} (F1={best_f1_valid:.3f})')\n\n# Apply the threshold to test set\ntest_preds_adj_final = (test_probs_final >= best_thr_final).astype(int)\nacc_final = accuracy_score(test_labels_final, test_preds_adj_final)\nf1_final = f1_score(test_labels_final, test_preds_adj_final, zero_division=0)\nprec_final = precision_score(test_labels_final, test_preds_adj_final, zero_division=0)\nrecall_final = recall_score(test_labels_final, test_preds_adj_final, zero_division=0)\n\nprint('\\n' + '='*60)\nprint('DS-MIL FINAL RESULTS (vs Baseline Comparison)')\nprint('='*60)\nprint('Final test metrics (Weighted BCE + optimised threshold):')\nprint(f'  Accuracy: {acc_final:.3f}, F1: {f1_final:.3f}, Precision: {prec_final:.3f}, Recall: {recall_final:.3f}, AUC: {test_auc_final:.3f}')\nprint('\\nBaseline AttentionMIL Results (for comparison):')\nprint('  Accuracy: 0.792, F1: 0.759, Precision: 0.750, Recall: 0.768, AUC: 0.829')\nprint('\\nPerformance Comparison:')\nprint(f'  AUC improvement: {test_auc_final:.3f} - 0.829 = {test_auc_final - 0.829:+.3f}')\nprint(f'  F1 improvement: {f1_final:.3f} - 0.759 = {f1_final - 0.759:+.3f}')\nprint(f'  Accuracy improvement: {acc_final:.3f} - 0.792 = {acc_final - 0.792:+.3f}')\n\n# Confusion matrix\ncm_final = confusion_matrix(test_labels_final.astype(int), test_preds_adj_final.astype(int), labels=[0,1])\nplt.figure(figsize=(4,3))\nsns.heatmap(\n    cm_final, annot=True, fmt='d', cmap='Blues',\n    xticklabels=['Genuine','Forged'], yticklabels=['Genuine','Forged']\n)\nplt.title(f'DS-MIL Confusion Matrix (Thr={best_thr_final:.2f})')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.tight_layout()\nplt.show()\n\n# ROC curve with baseline comparison\nfpr_final, tpr_final, _ = roc_curve(test_labels_final, test_probs_final)\nauc_final_value = auc(fpr_final, tpr_final)\nplt.figure(figsize=(6,5))\nplt.plot(fpr_final, tpr_final, color='blue', linewidth=2, \n         label=f'DS-MIL (AUC={auc_final_value:.3f})')\nplt.axhline(y=0.829, color='red', linestyle='--', alpha=0.7, \n           label='Baseline AttentionMIL (AUC=0.829)')\nplt.plot([0,1],[0,1],'k--', alpha=0.5, label='Random')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve – DS-MIL vs Baseline Comparison')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Summary of improvements\nprint('\\n' + '='*60)\nprint('PERFORMANCE ANALYSIS SUMMARY')\nprint('='*60)\nif test_auc_final > 0.829:\n    print(\"✅ DS-MIL shows IMPROVEMENT over baseline AttentionMIL\")\n    print(f\"   - AUC improved by {test_auc_final - 0.829:.3f} points\")\nelse:\n    print(\"❌ DS-MIL shows DECLINE compared to baseline AttentionMIL\")\n    print(f\"   - AUC decreased by {0.829 - test_auc_final:.3f} points\")\n\nif f1_final > 0.759:\n    print(f\"✅ F1 Score improved by {f1_final - 0.759:.3f} points\")\nelse:\n    print(f\"❌ F1 Score decreased by {0.759 - f1_final:.3f} points\")\n\nprint(f\"\\nKey factors in DS-MIL architecture:\")\nprint(f\"- Dual-stream learning (bag + instance level)\")\nprint(f\"- Critical instance identification\")\nprint(f\"- Cross-attention mechanism\")\nprint(f\"- Combined loss function (bag_loss + instance_loss)\")"
  },
  {
   "cell_type": "code",
   "id": "d4y2ol0yzuo",
   "source": "# 실험 결과 저장 및 요약\nimport json\nfrom datetime import datetime\n\n# 결과 저장 디렉토리 생성\nimport os\nos.makedirs('/workspace/MIL/output/results', exist_ok=True)\nos.makedirs('/workspace/MIL/output/models', exist_ok=True)\n\n# 실험 결과 정리\nresults = {\n    'experiment': 'DS-MIL vs AttentionMIL Comparison',\n    'timestamp': datetime.now().isoformat(),\n    'model': 'DS-MIL',\n    'data': {\n        'dataset': f'bags_arcface_margin_{embedding_margin}_50p_random',\n        'train_samples': len(train_labels),\n        'val_samples': len(val_labels), \n        'test_samples': len(test_labels),\n        'train_pos_ratio': np.mean(train_labels),\n        'val_pos_ratio': np.mean(val_labels),\n        'test_pos_ratio': np.mean(test_labels)\n    },\n    'model_config': {\n        'input_dim': 256,\n        'attention_dim': 128,\n        'dropout': 0.1,\n        'total_parameters': sum(p.numel() for p in mil_model_final.parameters())\n    },\n    'training': {\n        'loss_function': 'WeightedBCE',\n        'fp_weight': 2.0,\n        'optimizer': 'Adam',\n        'learning_rate': 1e-3,\n        'scheduler': 'ReduceLROnPlateau',\n        'max_epochs': 10,\n        'patience': 3,\n        'best_val_auc': float(val_auc_final)\n    },\n    'results': {\n        'validation': {\n            'loss': float(val_loss_final),\n            'accuracy': float(val_acc_final),\n            'auc': float(val_auc_final),\n            'f1': float(val_f1_final)\n        },\n        'test': {\n            'loss': float(test_loss_final),\n            'accuracy': float(acc_final),\n            'auc': float(test_auc_final), \n            'f1': float(f1_final),\n            'precision': float(prec_final),\n            'recall': float(recall_final),\n            'best_threshold': float(best_thr_final)\n        },\n        'baseline_comparison': {\n            'baseline_auc': 0.829,\n            'baseline_f1': 0.759,\n            'baseline_accuracy': 0.792,\n            'auc_improvement': float(test_auc_final - 0.829),\n            'f1_improvement': float(f1_final - 0.759),\n            'accuracy_improvement': float(acc_final - 0.792)\n        }\n    }\n}\n\n# JSON으로 결과 저장\nresults_file = '/workspace/MIL/output/results/dsmil_vs_baseline_results.json'\nwith open(results_file, 'w') as f:\n    json.dump(results, f, indent=2)\n\n# 모델 저장\nmodel_file = '/workspace/MIL/output/models/dsmil_final_model.pth'\ntorch.save({\n    'model_state_dict': mil_model_final.state_dict(),\n    'model_config': results['model_config'],\n    'results': results['results']\n}, model_file)\n\nprint(f\"\\n📁 Results saved to: {results_file}\")\nprint(f\"🔧 Model saved to: {model_file}\")\n\n# 최종 요약 출력\nprint(f\"\\n{'='*80}\")\nprint(f\"EXPERIMENT COMPLETED: DS-MIL vs Baseline AttentionMIL\")\nprint(f\"{'='*80}\")\nprint(f\"Dataset: ArcFace margin {embedding_margin}, 50% positive, random split\")\nprint(f\"DS-MIL Parameters: {results['model_config']['total_parameters']:,}\")\nprint(f\"Training completed with best validation AUC: {val_auc_final:.4f}\")\nprint(f\"\\nFINAL TEST RESULTS:\")\nprint(f\"  DS-MIL:     AUC={test_auc_final:.3f}, F1={f1_final:.3f}, Acc={acc_final:.3f}\")\nprint(f\"  Baseline:   AUC=0.829, F1=0.759, Acc=0.792\")\nprint(f\"  Difference: AUC={test_auc_final-0.829:+.3f}, F1={f1_final-0.759:+.3f}, Acc={acc_final-0.792:+.3f}\")\n\nif test_auc_final > 0.829:\n    print(f\"🎉 DS-MIL OUTPERFORMS baseline by {test_auc_final-0.829:.3f} AUC points!\")\nelse:\n    print(f\"📉 DS-MIL underperforms baseline by {0.829-test_auc_final:.3f} AUC points.\")\n    \nprint(f\"{'='*80}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}