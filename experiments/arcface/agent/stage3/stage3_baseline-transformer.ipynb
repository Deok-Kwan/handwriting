{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 모델 비교 (Baseline 동등 조건): Attention vs Transformer MIL\n",
    "\n",
    "Baseline과 완전히 동일한 조건(데이터/하이퍼파라미터/평가)에서 모델(Architecture)만 달리하여 성능을 비교합니다.\n",
    "\n",
    "- 데이터: Stage 2에서 생성한 bag (baseline 동일 스냅샷 강제)\n",
    "- 학습/평가: baseline과 동일 설정 (WeightedBCE, Adam, ReduceLROnPlateau, EarlyStopping 등)\n",
    "- 비교 모델: AttentionMIL vs TransformerMIL\n",
    "\n",
    "참고: 이 노트북은 내부 유틸을 재사용하기 위해 `experiments/arcface/agent/stage3_baseline_transformer.py` 모듈을 임포트하여 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 임포트 및 환경 확인\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import experiments.arcface.agent.stage3_baseline_transformer as exp\n",
    "\n",
    "print('Using device:', exp.device)\n",
    "if exp.device.type == 'cuda':\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# 동일 시드 적용\n",
    "exp.seed_everything(42)\n",
    "\n",
    "# 동일 데이터 로드 (baseline 데이터 크기 검증 포함)\n",
    "train_loader, val_loader, test_loader = exp.load_data_loaders(batch_size=16)\n",
    "print('Data loaders ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 설정 (baseline 동일)\n",
    "criterion = exp.WeightedBCE(fp_weight=2.0)\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 10\n",
    "patience = 3\n",
    "scheduler_patience = 1\n",
    "\n",
    "results = {}\n",
    "histories = {}\n",
    "\n",
    "print('🔬 모델 비교 실험 (Baseline과 완전 동일 조건)')\n",
    "print('='*60)\n",
    "print(f'손실 함수: WeightedBCE(fp_weight=2.0)')\n",
    "print(f'학습률: {learning_rate}')\n",
    "print(f'최대 에포크: {max_epochs}, Patience: {patience}')\n",
    "print(f'Scheduler Patience: {scheduler_patience}')\n",
    "print('='*60)\n",
    "\n",
    "# 1) AttentionMIL\n",
    "exp.seed_everything(42)\n",
    "att_model = exp.AttentionMIL(input_dim=256, hidden_dim=128, dropout_p=0.1).to(exp.device)\n",
    "att_opt = torch.optim.Adam(att_model.parameters(), lr=learning_rate)\n",
    "att_sch = torch.optim.lr_scheduler.ReduceLROnPlateau(att_opt, mode='max', factor=0.5, patience=scheduler_patience, verbose=True)\n",
    "att_model, att_hist = exp.train_model(att_model, att_opt, att_sch, train_loader, val_loader, criterion, max_epochs=max_epochs, patience=patience, name='attention_mil')\n",
    "att_val = exp.evaluate(att_model, val_loader, criterion)\n",
    "att_tst = exp.evaluate(att_model, test_loader, criterion)\n",
    "results['Attention'] = {'val': att_val, 'test': att_tst}\n",
    "histories['Attention'] = att_hist\n",
    "\n",
    "# 2) TransformerMIL\n",
    "exp.seed_everything(42)\n",
    "tr_model = exp.TransformerMIL(input_dim=256, hidden_dim=128, num_heads=4, num_layers=2, dropout_p=0.1).to(exp.device)\n",
    "tr_opt = torch.optim.Adam(tr_model.parameters(), lr=learning_rate)\n",
    "tr_sch = torch.optim.lr_scheduler.ReduceLROnPlateau(tr_opt, mode='max', factor=0.5, patience=scheduler_patience, verbose=True)\n",
    "tr_model, tr_hist = exp.train_model(tr_model, tr_opt, tr_sch, train_loader, val_loader, criterion, max_epochs=max_epochs, patience=patience, name='transformer_mil')\n",
    "tr_val = exp.evaluate(tr_model, val_loader, criterion)\n",
    "tr_tst = exp.evaluate(tr_model, test_loader, criterion)\n",
    "results['Transformer'] = {'val': tr_val, 'test': tr_tst}\n",
    "histories['Transformer'] = tr_hist\n",
    "\n",
    "print('✅ 두 모델 학습/평가 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 리포트 (validation 최적 임계값을 test에 적용)\n",
    "def find_best_threshold(probs, labels):\n",
    "    return exp.find_best_threshold(probs, labels)\n",
    "\n",
    "final_results = {}\n",
    "print('\n📊 모델별 최종 성능 비교')\n",
    "print('='*80)\n",
    "for name, res in results.items():\n",
    "    val_res, tst_res = res['val'], res['test']\n",
    "    thr, best_f1_val = find_best_threshold(val_res['probs'], val_res['labels'])\n",
    "    test_preds_adj = (tst_res['probs'] >= thr).astype(int)\n",
    "    acc = accuracy_score(tst_res['labels'], test_preds_adj)\n",
    "    f1 = f1_score(tst_res['labels'], test_preds_adj, zero_division=0)\n",
    "    prec = precision_score(tst_res['labels'], test_preds_adj, zero_division=0)\n",
    "    rec = recall_score(tst_res['labels'], test_preds_adj, zero_division=0)\n",
    "    auc_v = tst_res['auc']\n",
    "    final_results[name] = {\n+        'threshold': thr, 'accuracy': acc, 'f1': f1, 'precision': prec, 'recall': rec, 'auc': auc_v,\n+        'test_probs': tst_res['probs'], 'test_labels': tst_res['labels'], 'test_preds_adj': test_preds_adj,\n+    }\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f'  최적 임계값: {thr:.3f} (Val F1: {best_f1_val:.3f})')\n",
    "    print(f'  Test Accuracy: {acc:.3f}')\n",
    "    print(f'  Test F1: {f1:.3f}')\n",
    "    print(f'  Test Precision: {prec:.3f}')\n",
    "    print(f'  Test Recall: {rec:.3f}')\n",
    "    print(f'  Test AUC: {auc_v:.3f}')\n",
    "\n",
    "print('\n' + '='*80)\n",
    "print('📈 모델 성능 요약 테이블')\n",
    "print('='*80)\n",
    "print(f\"{'Model':<15} {'Accuracy':<10} {'F1':<8} {'Precision':<11} {'Recall':<8} {'AUC':<8}\")\n",
    "print('-'*80)\n",
    "for name, r in final_results.items():\n",
    "    print(f\"{name:<15} {r['accuracy']:<10.3f} {r['f1']:<8.3f} {r['precision']:<11.3f} {r['recall']:<8.3f} {r['auc']:<8.3f}\")\n",
    "\n",
    "best_auc = max(final_results.items(), key=lambda x: x[1]['auc']) if final_results else (None, None)\n",
    "best_f1  = max(final_results.items(), key=lambda x: x[1]['f1']) if final_results else (None, None)\n",
    "print('\n🏆 최고 성능:')\n",
    "if best_auc[0] is not None:\n",
    "    print(f\"  AUC 기준: {best_auc[0]} (AUC: {best_auc[1]['auc']:.3f})\")\n",
    "if best_f1[0] is not None:\n",
    "    print(f\"  F1 기준:  {best_f1[0]} (F1: {best_f1[1]['f1']:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
