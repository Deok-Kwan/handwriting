{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 ëª¨ë¸ ë¹„êµ (Baseline ë™ë“± ì¡°ê±´): Attention vs Transformer MIL\n",
    "\n",
    "Baselineê³¼ ì™„ì „íˆ ë™ì¼í•œ ì¡°ê±´(ë°ì´í„°/í•˜ì´í¼íŒŒë¼ë¯¸í„°/í‰ê°€)ì—ì„œ ëª¨ë¸(Architecture)ë§Œ ë‹¬ë¦¬í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "- ë°ì´í„°: Stage 2ì—ì„œ ìƒì„±í•œ bag (baseline ë™ì¼ ìŠ¤ëƒ…ìƒ· ê°•ì œ)\n",
    "- í•™ìŠµ/í‰ê°€: baselineê³¼ ë™ì¼ ì„¤ì • (WeightedBCE, Adam, ReduceLROnPlateau, EarlyStopping ë“±)\n",
    "- ë¹„êµ ëª¨ë¸: AttentionMIL vs TransformerMIL\n",
    "\n",
    "ì°¸ê³ : ì´ ë…¸íŠ¸ë¶ì€ ë‚´ë¶€ ìœ í‹¸ì„ ì¬ì‚¬ìš©í•˜ê¸° ìœ„í•´ `experiments/arcface/agent/stage3_baseline_transformer.py` ëª¨ë“ˆì„ ì„í¬íŠ¸í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“ˆ ì„í¬íŠ¸ ë° í™˜ê²½ í™•ì¸\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import experiments.arcface.agent.stage3_baseline_transformer as exp\n",
    "\n",
    "print('Using device:', exp.device)\n",
    "if exp.device.type == 'cuda':\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# ë™ì¼ ì‹œë“œ ì ìš©\n",
    "exp.seed_everything(42)\n",
    "\n",
    "# ë™ì¼ ë°ì´í„° ë¡œë“œ (baseline ë°ì´í„° í¬ê¸° ê²€ì¦ í¬í•¨)\n",
    "train_loader, val_loader, test_loader = exp.load_data_loaders(batch_size=16)\n",
    "print('Data loaders ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ì„¤ì • (baseline ë™ì¼)\n",
    "criterion = exp.WeightedBCE(fp_weight=2.0)\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 10\n",
    "patience = 3\n",
    "scheduler_patience = 1\n",
    "\n",
    "results = {}\n",
    "histories = {}\n",
    "\n",
    "print('ğŸ”¬ ëª¨ë¸ ë¹„êµ ì‹¤í—˜ (Baselineê³¼ ì™„ì „ ë™ì¼ ì¡°ê±´)')\n",
    "print('='*60)\n",
    "print(f'ì†ì‹¤ í•¨ìˆ˜: WeightedBCE(fp_weight=2.0)')\n",
    "print(f'í•™ìŠµë¥ : {learning_rate}')\n",
    "print(f'ìµœëŒ€ ì—í¬í¬: {max_epochs}, Patience: {patience}')\n",
    "print(f'Scheduler Patience: {scheduler_patience}')\n",
    "print('='*60)\n",
    "\n",
    "# 1) AttentionMIL\n",
    "exp.seed_everything(42)\n",
    "att_model = exp.AttentionMIL(input_dim=256, hidden_dim=128, dropout_p=0.1).to(exp.device)\n",
    "att_opt = torch.optim.Adam(att_model.parameters(), lr=learning_rate)\n",
    "att_sch = torch.optim.lr_scheduler.ReduceLROnPlateau(att_opt, mode='max', factor=0.5, patience=scheduler_patience, verbose=True)\n",
    "att_model, att_hist = exp.train_model(att_model, att_opt, att_sch, train_loader, val_loader, criterion, max_epochs=max_epochs, patience=patience, name='attention_mil')\n",
    "att_val = exp.evaluate(att_model, val_loader, criterion)\n",
    "att_tst = exp.evaluate(att_model, test_loader, criterion)\n",
    "results['Attention'] = {'val': att_val, 'test': att_tst}\n",
    "histories['Attention'] = att_hist\n",
    "\n",
    "# 2) TransformerMIL\n",
    "exp.seed_everything(42)\n",
    "tr_model = exp.TransformerMIL(input_dim=256, hidden_dim=128, num_heads=4, num_layers=2, dropout_p=0.1).to(exp.device)\n",
    "tr_opt = torch.optim.Adam(tr_model.parameters(), lr=learning_rate)\n",
    "tr_sch = torch.optim.lr_scheduler.ReduceLROnPlateau(tr_opt, mode='max', factor=0.5, patience=scheduler_patience, verbose=True)\n",
    "tr_model, tr_hist = exp.train_model(tr_model, tr_opt, tr_sch, train_loader, val_loader, criterion, max_epochs=max_epochs, patience=patience, name='transformer_mil')\n",
    "tr_val = exp.evaluate(tr_model, val_loader, criterion)\n",
    "tr_tst = exp.evaluate(tr_model, test_loader, criterion)\n",
    "results['Transformer'] = {'val': tr_val, 'test': tr_tst}\n",
    "histories['Transformer'] = tr_hist\n",
    "\n",
    "print('âœ… ë‘ ëª¨ë¸ í•™ìŠµ/í‰ê°€ ì™„ë£Œ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ë¦¬í¬íŠ¸ (validation ìµœì  ì„ê³„ê°’ì„ testì— ì ìš©)\n",
    "def find_best_threshold(probs, labels):\n",
    "    return exp.find_best_threshold(probs, labels)\n",
    "\n",
    "final_results = {}\n",
    "print('\nğŸ“Š ëª¨ë¸ë³„ ìµœì¢… ì„±ëŠ¥ ë¹„êµ')\n",
    "print('='*80)\n",
    "for name, res in results.items():\n",
    "    val_res, tst_res = res['val'], res['test']\n",
    "    thr, best_f1_val = find_best_threshold(val_res['probs'], val_res['labels'])\n",
    "    test_preds_adj = (tst_res['probs'] >= thr).astype(int)\n",
    "    acc = accuracy_score(tst_res['labels'], test_preds_adj)\n",
    "    f1 = f1_score(tst_res['labels'], test_preds_adj, zero_division=0)\n",
    "    prec = precision_score(tst_res['labels'], test_preds_adj, zero_division=0)\n",
    "    rec = recall_score(tst_res['labels'], test_preds_adj, zero_division=0)\n",
    "    auc_v = tst_res['auc']\n",
    "    final_results[name] = {\n+        'threshold': thr, 'accuracy': acc, 'f1': f1, 'precision': prec, 'recall': rec, 'auc': auc_v,\n+        'test_probs': tst_res['probs'], 'test_labels': tst_res['labels'], 'test_preds_adj': test_preds_adj,\n+    }\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f'  ìµœì  ì„ê³„ê°’: {thr:.3f} (Val F1: {best_f1_val:.3f})')\n",
    "    print(f'  Test Accuracy: {acc:.3f}')\n",
    "    print(f'  Test F1: {f1:.3f}')\n",
    "    print(f'  Test Precision: {prec:.3f}')\n",
    "    print(f'  Test Recall: {rec:.3f}')\n",
    "    print(f'  Test AUC: {auc_v:.3f}')\n",
    "\n",
    "print('\n' + '='*80)\n",
    "print('ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸”')\n",
    "print('='*80)\n",
    "print(f\"{'Model':<15} {'Accuracy':<10} {'F1':<8} {'Precision':<11} {'Recall':<8} {'AUC':<8}\")\n",
    "print('-'*80)\n",
    "for name, r in final_results.items():\n",
    "    print(f\"{name:<15} {r['accuracy']:<10.3f} {r['f1']:<8.3f} {r['precision']:<11.3f} {r['recall']:<8.3f} {r['auc']:<8.3f}\")\n",
    "\n",
    "best_auc = max(final_results.items(), key=lambda x: x[1]['auc']) if final_results else (None, None)\n",
    "best_f1  = max(final_results.items(), key=lambda x: x[1]['f1']) if final_results else (None, None)\n",
    "print('\nğŸ† ìµœê³  ì„±ëŠ¥:')\n",
    "if best_auc[0] is not None:\n",
    "    print(f\"  AUC ê¸°ì¤€: {best_auc[0]} (AUC: {best_auc[1]['auc']:.3f})\")\n",
    "if best_f1[0] is not None:\n",
    "    print(f\"  F1 ê¸°ì¤€:  {best_f1[0]} (F1: {best_f1[1]['f1']:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
