{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30792b37",
   "metadata": {},
   "source": [
    "# Stage 2 Baseline: MIL Bag Generation (50% Forgery) - ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Stage 1ì—ì„œ ì¶”ì¶œí•œ ArcFace ì„ë² ë”©ì„ ì´ìš©í•´ Multiple Instance Learning(MIL) í•™ìŠµì„ ìœ„í•œ **ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸** Bag ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "\n",
    "**í•µì‹¬ ë‹¨ìˆœí™”:**\n",
    "- **ë‹¨ì¼ ê·œì¹™**: Negative=í•œ ì‘ì„±ì 14ê°œ ë‹¨ì–´, Positive=ë‘ ì‘ì„±ì 7+7ê°œ ë‹¨ì–´ ëœë¤ ì…”í”Œ\n",
    "- **ê³ ì • ìœˆë„ìš°**: (win=5, stride=1) â†’ 10ê°œ ì¸ìŠ¤í„´ìŠ¤ â†’ ê° bagì€ (10, 5, 256)\n",
    "- **50/50 ê· í˜•**: ê° splitì—ì„œ ì •í™•íˆ 50% Positive, 50% Negative ë¹„ìœ¨\n",
    "- **ë³µì¡í•œ ì„¤ì • ì œê±°**: ê²Œì´íŠ¸, ì»¤ìŠ¤í…€ í˜ì–´ë§, ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë“± ëª¨ë“  ë³µì¡í•œ ê¸°ëŠ¥ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01af97fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:07.386622Z",
     "start_time": "2025-08-19T07:41:06.892361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™˜ê²½ ì„¤ì • ì™„ë£Œ: GPU=1, SEED=42\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
    "import os, random, pickle, numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# GPU ì„¤ì • (ì„ íƒì )\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv('MIL_STAGE2_GPU', '1')\n",
    "\n",
    "# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
    "SEED_BASE = 42\n",
    "np.random.seed(SEED_BASE)\n",
    "random.seed(SEED_BASE)\n",
    "\n",
    "print(f'í™˜ê²½ ì„¤ì • ì™„ë£Œ: GPU={os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"N/A\")}, SEED={SEED_BASE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801ad3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:21.721062Z",
     "start_time": "2025-08-19T07:41:07.388666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¡œë”© ì™„ë£Œ:\n",
      "  - Embedding ì°¨ì›: 256\n",
      "  - Label ì»¬ëŸ¼: label\n",
      "  - Train: 208233, Val: 70533, Test: 72457\n",
      "  - ì›ë³¸ ë©”íƒ€ë°ì´í„°: 556128 rows\n"
     ]
    }
   ],
   "source": [
    "# ê²½ë¡œ ì„¤ì • ë° ë°ì´í„° ë¡œë”©\n",
    "embedding_dir = '/workspace/MIL/data/processed/embeddings'\n",
    "raw_meta_csv  = '/workspace/MIL/data/raw/naver_ocr.csv'  # ì„ íƒ ì‚¬í•­\n",
    "bags_dir      = '/workspace/MIL/data/processed/bags'\n",
    "os.makedirs(bags_dir, exist_ok=True)\n",
    "\n",
    "margin_value = '0.4'\n",
    "rng_global = np.random.default_rng(SEED_BASE)\n",
    "\n",
    "# CSV ë¡œë”© í•¨ìˆ˜\n",
    "def load_split_csv(split):\n",
    "    csv_path = os.path.join(embedding_dir, f'mil_arcface_margin_{margin_value}_{split}_data.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    label_col = 'label' if 'label' in df.columns else 'author_id'\n",
    "    emb_cols  = [c for c in df.columns if c.startswith('embedding')]\n",
    "    assert len(emb_cols) > 0, \"No embedding_* columns found.\"\n",
    "    return df, label_col, emb_cols\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "train_df, label_col, emb_cols = load_split_csv('train')\n",
    "val_df,   _,         _        = load_split_csv('val')\n",
    "test_df,  _,         _        = load_split_csv('test')\n",
    "embed_dim = len(emb_cols)\n",
    "\n",
    "print(f\"ë°ì´í„° ë¡œë”© ì™„ë£Œ:\")\n",
    "print(f\"  - Embedding ì°¨ì›: {embed_dim}\")\n",
    "print(f\"  - Label ì»¬ëŸ¼: {label_col}\")\n",
    "print(f\"  - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# ì„ íƒì  ì›ë³¸ ë©”íƒ€ë°ì´í„° ë¡œë”©\n",
    "try:\n",
    "    original_df = pd.read_csv(raw_meta_csv)\n",
    "    print(f\"  - ì›ë³¸ ë©”íƒ€ë°ì´í„°: {len(original_df)} rows\")\n",
    "    has_raw_meta = True\n",
    "except Exception:\n",
    "    print(f\"  - ì›ë³¸ ë©”íƒ€ë°ì´í„°: ì—†ìŒ\")\n",
    "    has_raw_meta = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vlqa78d208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:22.734402Z",
     "start_time": "2025-08-19T07:41:21.725128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ì„±ì ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ:\n",
      "  - Train writers: 180\n",
      "  - Val writers: 60\n",
      "  - Test writers: 60\n",
      "âœ“ í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# Stage 2 Baseline: MIL Bags (50% Forgery), Minimal & Reproducible\n",
    "# ==============================================================\n",
    "\n",
    "# ì‘ì„±ìë³„ ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "def build_writer_index(df, label_col, emb_cols):\n",
    "    w2 = {}\n",
    "    for wid, g in df.groupby(label_col):\n",
    "        w2[int(wid)] = {\n",
    "            'emb': g[emb_cols].to_numpy(dtype=np.float32),\n",
    "            'paths': g['path'].tolist() if 'path' in g.columns else [''] * len(g),\n",
    "            'idx': g.index.to_list()\n",
    "        }\n",
    "    return w2\n",
    "\n",
    "train_writers = build_writer_index(train_df, label_col, emb_cols)\n",
    "val_writers   = build_writer_index(val_df,   label_col, emb_cols)\n",
    "test_writers  = build_writer_index(test_df,  label_col, emb_cols)\n",
    "\n",
    "def list_writer_ids(wdict): \n",
    "    return list(wdict.keys())\n",
    "\n",
    "print(f\"ì‘ì„±ì ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ:\")\n",
    "print(f\"  - Train writers: {len(train_writers)}\")\n",
    "print(f\"  - Val writers: {len(val_writers)}\")\n",
    "print(f\"  - Test writers: {len(test_writers)}\")\n",
    "\n",
    "# ìƒ˜í”Œë§ í—¬í¼ í•¨ìˆ˜ë“¤\n",
    "def sample_k(n, k, rng, replace_if_needed=True):\n",
    "    \"\"\"nê°œ ì¤‘ì—ì„œ kê°œ ìƒ˜í”Œë§ (ë¶€ì¡±í•˜ë©´ ì¤‘ë³µ í—ˆìš©)\"\"\"\n",
    "    if (not replace_if_needed) and n >= k:\n",
    "        return rng.choice(n, size=k, replace=False).tolist()\n",
    "    # ë¶€ì¡±í•˜ë©´ ì¤‘ë³µ í—ˆìš©\n",
    "    return rng.choice(n, size=k, replace=True).tolist()\n",
    "\n",
    "def sliding_windows(seq, win=5, stride=1):\n",
    "    \"\"\"ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ë¶„í• \"\"\"\n",
    "    # seq: list of tuples (emb, wid, path, orig_idx)\n",
    "    windows, metas = [], []\n",
    "    for i in range(0, len(seq) - win + 1, stride):\n",
    "        chunk = seq[i:i+win]\n",
    "        windows.append(np.stack([e for (e,_,_,_) in chunk], axis=0))  # (5, D)\n",
    "        metas.append({\n",
    "            'window_idx': i,\n",
    "            'word_indices': [oi for (_,_,_,oi) in chunk],\n",
    "            'word_paths':   [p  for (_,_,p, _) in chunk],\n",
    "            'writer_ids':   [w  for (_,w,_, _) in chunk],\n",
    "        })\n",
    "    return windows, metas\n",
    "\n",
    "def pack(words, wid, W):\n",
    "    \"\"\"ë‹¨ì–´ ì¸ë±ìŠ¤ë¥¼ ì„ë² ë”© íŠœí”Œë¡œ ë³€í™˜\"\"\"\n",
    "    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n",
    "    return [(emb[w], wid, paths[w], idxs[w]) for w in words]\n",
    "\n",
    "print(\"âœ“ í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hu8mulwsryd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:22.750177Z",
     "start_time": "2025-08-19T07:41:22.739689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Bag ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "  - Negative: 14ê°œ ë‹¨ì–´ â†’ 10ê°œ ì¸ìŠ¤í„´ìŠ¤\n",
      "  - Positive: 7+7ê°œ ë‹¨ì–´ ì…”í”Œ â†’ 10ê°œ ì¸ìŠ¤í„´ìŠ¤\n",
      "  - ìœˆë„ìš°: (win=5, stride=1)\n"
     ]
    }
   ],
   "source": [
    "# Bag ìƒì„± í•¨ìˆ˜ (ë² ì´ìŠ¤ë¼ì¸ ê·œì¹™)\n",
    "WIN = 5; STRIDE = 1; INSTANCES_PER_BAG = 10\n",
    "TOK_NEG = 14; TOK_POS_A = 7; TOK_POS_B = 7\n",
    "\n",
    "def make_negative_bag(wid, W, rng):\n",
    "    \"\"\"ë‹¨ì¼ ì‘ì„±ì Bag (ë ˆì´ë¸” 0)\"\"\"\n",
    "    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n",
    "    sel = sample_k(len(emb), TOK_NEG, rng, replace_if_needed=True)\n",
    "    seq = pack(sel, wid, W)\n",
    "    wins, metas = sliding_windows(seq, WIN, STRIDE)\n",
    "    bag = np.stack(wins[:INSTANCES_PER_BAG], axis=0)  # (10, 5, D)\n",
    "    return bag, metas[:INSTANCES_PER_BAG], [int(wid)]\n",
    "\n",
    "def make_positive_bag(widA, widB, WA, WB, rng):\n",
    "    \"\"\"ë³µìˆ˜ ì‘ì„±ì Bag (ë ˆì´ë¸” 1): A 7ê°œ + B 7ê°œ â†’ ì „ì²´ ì…”í”Œ â†’ ìœˆë„ìš°\"\"\"\n",
    "    embA, pathsA, idxA = WA['emb'], WA['paths'], WA['idx']\n",
    "    embB, pathsB, idxB = WB['emb'], WB['paths'], WB['idx']\n",
    "    \n",
    "    selA = sample_k(len(embA), TOK_POS_A, rng, replace_if_needed=True)\n",
    "    selB = sample_k(len(embB), TOK_POS_B, rng, replace_if_needed=True)\n",
    "    \n",
    "    seqA = [(embA[i], int(widA), pathsA[i], idxA[i]) for i in selA]\n",
    "    seqB = [(embB[i], int(widB), pathsB[i], idxB[i]) for i in selB]\n",
    "    \n",
    "    seq = seqA + seqB\n",
    "    rng.shuffle(seq)  # í•µì‹¬: ëœë¤ ì…”í”Œ\n",
    "    \n",
    "    wins, metas = sliding_windows(seq, WIN, STRIDE)\n",
    "    bag = np.stack(wins[:INSTANCES_PER_BAG], axis=0)\n",
    "    return bag, metas[:INSTANCES_PER_BAG], [int(widA), int(widB)]\n",
    "\n",
    "print(\"âœ“ Bag ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"  - Negative: {TOK_NEG}ê°œ ë‹¨ì–´ â†’ {INSTANCES_PER_BAG}ê°œ ì¸ìŠ¤í„´ìŠ¤\")\n",
    "print(f\"  - Positive: {TOK_POS_A}+{TOK_POS_B}ê°œ ë‹¨ì–´ ì…”í”Œ â†’ {INSTANCES_PER_BAG}ê°œ ì¸ìŠ¤í„´ìŠ¤\")\n",
    "print(f\"  - ìœˆë„ìš°: (win={WIN}, stride={STRIDE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fmruxme0xt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:22.761027Z",
     "start_time": "2025-08-19T07:41:22.752008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Split ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Split ìƒì„± í•¨ìˆ˜\n",
    "def generate_split(name, WDICT, neg_per_writer=10, pos_per_writer=10, seed=42):\n",
    "    \"\"\"ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸ split ìƒì„± (50/50 ê· í˜•)\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    writer_ids = list_writer_ids(WDICT)\n",
    "    bags, labels, metadata = [], [], []\n",
    "    \n",
    "    print(f\"  {name} split ìƒì„± ì¤‘... (Writers: {len(writer_ids)})\")\n",
    "    \n",
    "    # Negative bags (ë‹¨ì¼ ì‘ì„±ì)\n",
    "    for wid in writer_ids:\n",
    "        for _ in range(neg_per_writer):\n",
    "            bag, metas, authors = make_negative_bag(wid, WDICT[wid], rng)\n",
    "            bags.append(bag)\n",
    "            labels.append(0)\n",
    "            metadata.append({\n",
    "                'authors': authors, \n",
    "                'bag_type': 'negative',\n",
    "                'instances': metas\n",
    "            })\n",
    "    \n",
    "    # Positive bags (ë³µìˆ˜ ì‘ì„±ì, ê° Aë‹¹ pos_per_writerê°œ, íŒŒíŠ¸ë„ˆëŠ” ëœë¤)\n",
    "    for widA in writer_ids:\n",
    "        for _ in range(pos_per_writer):\n",
    "            widB = rng.choice([w for w in writer_ids if w != widA])\n",
    "            bag, metas, authors = make_positive_bag(widA, widB, WDICT[widA], WDICT[widB], rng)\n",
    "            bags.append(bag)\n",
    "            labels.append(1)\n",
    "            metadata.append({\n",
    "                'authors': authors, \n",
    "                'bag_type': 'positive',\n",
    "                'instances': metas\n",
    "            })\n",
    "    \n",
    "    # ì „ì²´ ì…”í”Œ\n",
    "    idx = rng.permutation(len(labels))\n",
    "    bags = [bags[i] for i in idx]\n",
    "    labels = [int(labels[i]) for i in idx]\n",
    "    metadata = [metadata[i] for i in idx]\n",
    "    \n",
    "    # ìš”ì•½ ì¶œë ¥\n",
    "    n_pos = sum(labels)\n",
    "    n_tot = len(labels)\n",
    "    print(f\"    â†’ Total: {n_tot}, Positive: {n_pos} ({n_pos/n_tot*100:.1f}%), Negative: {n_tot-n_pos}\")\n",
    "    \n",
    "    # ê°„ë‹¨ ê²€ì¦\n",
    "    assert len(bags) == len(labels) == len(metadata), \"Length mismatch\"\n",
    "    assert bags[0].shape == (INSTANCES_PER_BAG, WIN, embed_dim), f\"Shape mismatch: {bags[0].shape}\"\n",
    "    \n",
    "    return bags, labels, metadata\n",
    "\n",
    "print(\"âœ“ Split ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68rg6jgcskq",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:26.739554Z",
     "start_time": "2025-08-19T07:41:22.764865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ë² ì´ìŠ¤ë¼ì¸ Bags ìƒì„± ì‹œì‘...\n",
      "ì„¤ì •: Negative=10/writer, Positive=10/writer\n",
      "  Train split ìƒì„± ì¤‘... (Writers: 180)\n",
      "    â†’ Total: 3600, Positive: 1800 (50.0%), Negative: 1800\n",
      "  Val split ìƒì„± ì¤‘... (Writers: 60)\n",
      "    â†’ Total: 1200, Positive: 600 (50.0%), Negative: 600\n",
      "  Test split ìƒì„± ì¤‘... (Writers: 60)\n",
      "    â†’ Total: 1200, Positive: 600 (50.0%), Negative: 600\n",
      "\\nğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...\n",
      "ğŸ’¾ ì €ì¥: bags_arcface_margin_0.4_50p_baseline_train.pkl\n",
      "â†ªï¸  í˜¸í™˜ ë³µì‚¬: bags_arcface_margin_0.4_50p_random_train.pkl\n",
      "ğŸ’¾ ì €ì¥: bags_arcface_margin_0.4_50p_baseline_val.pkl\n",
      "â†ªï¸  í˜¸í™˜ ë³µì‚¬: bags_arcface_margin_0.4_50p_random_val.pkl\n",
      "ğŸ’¾ ì €ì¥: bags_arcface_margin_0.4_50p_baseline_test.pkl\n",
      "â†ªï¸  í˜¸í™˜ ë³µì‚¬: bags_arcface_margin_0.4_50p_random_test.pkl\n",
      "\\nğŸ“Š ìµœì¢… ìš”ì•½:\n",
      "Train: N=3600, Pos=1800 (50.0%), Neg=1800\n",
      "Val: N=1200, Pos=600 (50.0%), Neg=600\n",
      "Test: N=1200, Pos=600 (50.0%), Neg=600\n",
      "\\nâœ… Stage 2 ë² ì´ìŠ¤ë¼ì¸ ìƒì„± ì™„ë£Œ!\n",
      "ğŸ“‹ ë ˆì´ë¸” ì •ë³´:\n",
      "  - Label 0 (Negative): ë‹¨ì¼ ì‘ì„±ì (ì§„ì§œ)\n",
      "  - Label 1 (Positive): ë³µìˆ˜ ì‘ì„±ì (ìœ„ì¡°)\n",
      "ğŸ”— Stage 3ì—ì„œ ê¸°ì¡´ íŒŒì¼ëª…ìœ¼ë¡œ ë¡œë“œ ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# ë² ì´ìŠ¤ë¼ì¸ Bag ìƒì„± ì‹¤í–‰\n",
    "NEG_PW = 10  # ì‘ì„±ìë³„ negative bags\n",
    "POS_PW = 10  # ì‘ì„±ìë³„ positive bags â†’ ì „ì²´ ì•½ 50/50\n",
    "\n",
    "print(\"ğŸ”„ ë² ì´ìŠ¤ë¼ì¸ Bags ìƒì„± ì‹œì‘...\")\n",
    "print(f\"ì„¤ì •: Negative={NEG_PW}/writer, Positive={POS_PW}/writer\")\n",
    "\n",
    "# ëª¨ë“  split ìƒì„±\n",
    "train_bags, train_labels, train_meta = generate_split('Train', train_writers, NEG_PW, POS_PW, seed=SEED_BASE+0)\n",
    "val_bags,   val_labels,   val_meta   = generate_split('Val',   val_writers,   NEG_PW, POS_PW, seed=SEED_BASE+10)\n",
    "test_bags,  test_labels,  test_meta  = generate_split('Test',  test_writers,  NEG_PW, POS_PW, seed=SEED_BASE+20)\n",
    "\n",
    "# ì €ì¥ í•¨ìˆ˜\n",
    "def save_split(bags, labels, meta, tag, compat_copy=True):\n",
    "    base = os.path.join(bags_dir, f\"bags_arcface_margin_{margin_value}_50p_baseline_{tag}.pkl\")\n",
    "    with open(base, 'wb') as f:\n",
    "        pickle.dump({'bags': bags, 'labels': labels, 'metadata': meta}, f)\n",
    "    print(f\"ğŸ’¾ ì €ì¥: {os.path.basename(base)}\")\n",
    "    \n",
    "    if compat_copy:\n",
    "        # Stage3 í˜¸í™˜ì„ ìœ„í•œ ë³µì‚¬ë³¸ (ê¸°ì¡´ íŒŒì¼ëª…)\n",
    "        alias = os.path.join(bags_dir, f\"bags_arcface_margin_{margin_value}_50p_random_{tag}.pkl\")\n",
    "        with open(alias, 'wb') as f:\n",
    "            pickle.dump({'bags': bags, 'labels': labels, 'metadata': meta}, f)\n",
    "        print(f\"â†ªï¸  í˜¸í™˜ ë³µì‚¬: {os.path.basename(alias)}\")\n",
    "\n",
    "# ì €ì¥ ì‹¤í–‰\n",
    "print(\"\\\\nğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...\")\n",
    "save_split(train_bags, train_labels, train_meta, 'train', compat_copy=True)\n",
    "save_split(val_bags,   val_labels,   val_meta,   'val',   compat_copy=True)\n",
    "save_split(test_bags,  test_labels,  test_meta,  'test',  compat_copy=True)\n",
    "\n",
    "# ìµœì¢… ìš”ì•½\n",
    "def summarize(name, labels):\n",
    "    n = len(labels)\n",
    "    p = sum(labels)\n",
    "    print(f\"{name}: N={n}, Pos={p} ({p/n*100:.1f}%), Neg={n-p}\")\n",
    "\n",
    "print(\"\\\\nğŸ“Š ìµœì¢… ìš”ì•½:\")\n",
    "summarize('Train', train_labels)\n",
    "summarize('Val',   val_labels)\n",
    "summarize('Test',  test_labels)\n",
    "\n",
    "print(\"\\\\nâœ… Stage 2 ë² ì´ìŠ¤ë¼ì¸ ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"ğŸ“‹ ë ˆì´ë¸” ì •ë³´:\")\n",
    "print(\"  - Label 0 (Negative): ë‹¨ì¼ ì‘ì„±ì (ì§„ì§œ)\")\n",
    "print(\"  - Label 1 (Positive): ë³µìˆ˜ ì‘ì„±ì (ìœ„ì¡°)\")\n",
    "print(\"ğŸ”— Stage 3ì—ì„œ ê¸°ì¡´ íŒŒì¼ëª…ìœ¼ë¡œ ë¡œë“œ ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cc7a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:26.897261Z",
     "start_time": "2025-08-19T07:41:26.743994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìƒì„±ëœ ë°ì´í„° ê²€ì¦:\n",
      "  - Train bags shape: (3600, 10, 5, 256)\n",
      "  - Train labels ë¶„í¬: [1800 1800]\n",
      "  - ì²« ë²ˆì§¸ bag shape: (10, 5, 256)\n",
      "  - Embedding ì°¨ì›: 256\n",
      "\\nğŸ“‹ ìƒ˜í”Œ ë©”íƒ€ë°ì´í„°:\n",
      "  Negative bag:\n",
      "    - Authors: [64] (ê°œìˆ˜: 1)\n",
      "    - Type: negative\n",
      "    - Instances: 10\n",
      "  Positive bag:\n",
      "    - Authors: [95, 13] (ê°œìˆ˜: 2)\n",
      "    - Type: positive\n",
      "    - Instances: 10\n",
      "    - ì²« ì¸ìŠ¤í„´ìŠ¤ ì‘ì„±ìë“¤: [13, 13, 95, 95, 95]\n",
      "\\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼ - ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸš€ Stage 3ì—ì„œ AB-MIL í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨í•œ ê²€ì¦ ë° ìƒ˜í”Œ í™•ì¸\n",
    "\n",
    "# ë°ì´í„° íƒ€ì…ê³¼ í˜•íƒœ ê²€ì¦\n",
    "print(\"ğŸ” ìƒì„±ëœ ë°ì´í„° ê²€ì¦:\")\n",
    "print(f\"  - Train bags shape: {np.array(train_bags).shape}\")\n",
    "print(f\"  - Train labels ë¶„í¬: {np.bincount(train_labels)}\")\n",
    "print(f\"  - ì²« ë²ˆì§¸ bag shape: {train_bags[0].shape}\")\n",
    "print(f\"  - Embedding ì°¨ì›: {train_bags[0].shape[2]}\")\n",
    "\n",
    "# ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° í™•ì¸\n",
    "print(f\"\\\\nğŸ“‹ ìƒ˜í”Œ ë©”íƒ€ë°ì´í„°:\")\n",
    "neg_sample = next(meta for meta, label in zip(train_meta, train_labels) if label == 0)\n",
    "pos_sample = next(meta for meta, label in zip(train_meta, train_labels) if label == 1)\n",
    "\n",
    "print(f\"  Negative bag:\")\n",
    "print(f\"    - Authors: {neg_sample['authors']} (ê°œìˆ˜: {len(neg_sample['authors'])})\")\n",
    "print(f\"    - Type: {neg_sample['bag_type']}\")\n",
    "print(f\"    - Instances: {len(neg_sample['instances'])}\")\n",
    "\n",
    "print(f\"  Positive bag:\")\n",
    "print(f\"    - Authors: {pos_sample['authors']} (ê°œìˆ˜: {len(pos_sample['authors'])})\")\n",
    "print(f\"    - Type: {pos_sample['bag_type']}\")\n",
    "print(f\"    - Instances: {len(pos_sample['instances'])}\")\n",
    "print(f\"    - ì²« ì¸ìŠ¤í„´ìŠ¤ ì‘ì„±ìë“¤: {pos_sample['instances'][0]['writer_ids']}\")\n",
    "\n",
    "print(f\"\\\\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼ - ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ğŸš€ Stage 3ì—ì„œ AB-MIL í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365e8015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T07:41:26.991293Z",
     "start_time": "2025-08-19T07:41:26.899443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ Stage 2 ë² ì´ìŠ¤ë¼ì¸ ì™„ë£Œ!\n",
      "============================================================\n",
      "âœ… ê°„ì†Œí™”ëœ íŠ¹ì§•:\n",
      "  â€¢ ë‹¨ì¼ ê·œì¹™: Negative=1ì‘ì„±ì, Positive=2ì‘ì„±ì 7+7 ì…”í”Œ\n",
      "  â€¢ ê³ ì • ìœˆë„ìš°: (5, 1) â†’ 10 ì¸ìŠ¤í„´ìŠ¤\n",
      "  â€¢ 50/50 ê· í˜• ë³´ì¥\n",
      "\n",
      "ğŸ“ ìƒì„±ëœ íŒŒì¼:\n",
      "  â€¢ bags_arcface_margin_0.4_50p_baseline_*.pkl (ìƒˆ ì´ë¦„)\n",
      "  â€¢ bags_arcface_margin_0.4_50p_random_*.pkl (Stage3 í˜¸í™˜)\n",
      "\n",
      "ğŸš€ ë‹¤ìŒ ë‹¨ê³„: Stage 3ì—ì„œ AB-MIL í•™ìŠµ\n"
     ]
    }
   ],
   "source": [
    "# ë² ì´ìŠ¤ë¼ì¸ ì™„ë£Œ - ë³µì¡í•œ ì„¤ì •ë“¤ì€ ì œê±°ë¨\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ Stage 2 ë² ì´ìŠ¤ë¼ì¸ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"âœ… ê°„ì†Œí™”ëœ íŠ¹ì§•:\")\n",
    "print(\"  â€¢ ë‹¨ì¼ ê·œì¹™: Negative=1ì‘ì„±ì, Positive=2ì‘ì„±ì 7+7 ì…”í”Œ\")\n",
    "print(\"  â€¢ ê³ ì • ìœˆë„ìš°: (5, 1) â†’ 10 ì¸ìŠ¤í„´ìŠ¤\")\n",
    "print(\"  â€¢ 50/50 ê· í˜• ë³´ì¥\")\n",
    "print()\n",
    "print(\"ğŸ“ ìƒì„±ëœ íŒŒì¼:\")\n",
    "print(f\"  â€¢ bags_arcface_margin_{margin_value}_50p_baseline_*.pkl (ìƒˆ ì´ë¦„)\")\n",
    "print(f\"  â€¢ bags_arcface_margin_{margin_value}_50p_random_*.pkl (Stage3 í˜¸í™˜)\")\n",
    "print()\n",
    "print(\"ğŸš€ ë‹¤ìŒ ë‹¨ê³„: Stage 3ì—ì„œ AB-MIL í•™ìŠµ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
