{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30792b37",
   "metadata": {},
   "source": "# Stage 2 Baseline: MIL Bag Generation (50% Forgery) - 순수 윈도우 버전\n\n이 노트북은 Stage 1에서 추출한 ArcFace 임베딩을 이용해 Multiple Instance Learning(MIL) 학습을 위한 **개선된 베이스라인** Bag 데이터를 생성합니다. \n\n**핵심 개선사항 (순수 윈도우):**\n- **Negative (라벨 0)**: 한 작성자 14개 단어 → 슬라이딩 윈도우 (변경 없음)\n- **Positive (라벨 1)**: A 전용 윈도우 5개 + B 전용 윈도우 5개 → **각 윈도우는 단일 작성자만 포함**\n- **윈도우 순수성 100%**: 모든 윈도우가 단일 작성자의 토큰만으로 구성\n- **50/50 균형**: 각 split에서 정확히 50% Positive, 50% Negative 비율\n\n**변경 이유:**\n- 기존: A 7개 + B 7개를 전체 셔플 → 혼합 윈도우 발생 (한 윈도우에 A와 B가 섞임)\n- 개선: A 전용 윈도우와 B 전용 윈도우를 따로 생성 → 윈도우 레벨에서 합침 → 순수 윈도우 보장"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01af97fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:03:51.376502Z",
     "start_time": "2025-08-19T03:03:50.935669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환경 설정 완료: GPU=1, SEED=42\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 임포트 및 환경 설정\n",
    "import os, random, pickle, numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# GPU 설정 (선택적)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv('MIL_STAGE2_GPU', '1')\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "SEED_BASE = 42\n",
    "np.random.seed(SEED_BASE)\n",
    "random.seed(SEED_BASE)\n",
    "\n",
    "print(f'환경 설정 완료: GPU={os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"N/A\")}, SEED={SEED_BASE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801ad3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:04.992500Z",
     "start_time": "2025-08-19T03:03:51.379313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 완료:\n",
      "  - Embedding 차원: 256\n",
      "  - Label 컬럼: label\n",
      "  - Train: 208233, Val: 70533, Test: 72457\n",
      "  - 원본 메타데이터: 556128 rows\n"
     ]
    }
   ],
   "source": [
    "# 경로 설정 및 데이터 로딩\n",
    "embedding_dir = '/workspace/MIL/data/processed/embeddings'\n",
    "raw_meta_csv  = '/workspace/MIL/data/raw/naver_ocr.csv'  # 선택 사항\n",
    "bags_dir      = '/workspace/MIL/data/processed/bags'\n",
    "os.makedirs(bags_dir, exist_ok=True)\n",
    "\n",
    "margin_value = '0.4'\n",
    "rng_global = np.random.default_rng(SEED_BASE)\n",
    "\n",
    "# CSV 로딩 함수\n",
    "def load_split_csv(split):\n",
    "    csv_path = os.path.join(embedding_dir, f'mil_arcface_margin_{margin_value}_{split}_data.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    label_col = 'label' if 'label' in df.columns else 'author_id'\n",
    "    emb_cols  = [c for c in df.columns if c.startswith('embedding')]\n",
    "    assert len(emb_cols) > 0, \"No embedding_* columns found.\"\n",
    "    return df, label_col, emb_cols\n",
    "\n",
    "# 데이터 로딩\n",
    "train_df, label_col, emb_cols = load_split_csv('train')\n",
    "val_df,   _,         _        = load_split_csv('val')\n",
    "test_df,  _,         _        = load_split_csv('test')\n",
    "embed_dim = len(emb_cols)\n",
    "\n",
    "print(f\"데이터 로딩 완료:\")\n",
    "print(f\"  - Embedding 차원: {embed_dim}\")\n",
    "print(f\"  - Label 컬럼: {label_col}\")\n",
    "print(f\"  - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# 선택적 원본 메타데이터 로딩\n",
    "try:\n",
    "    original_df = pd.read_csv(raw_meta_csv)\n",
    "    print(f\"  - 원본 메타데이터: {len(original_df)} rows\")\n",
    "    has_raw_meta = True\n",
    "except Exception:\n",
    "    print(f\"  - 원본 메타데이터: 없음\")\n",
    "    has_raw_meta = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vlqa78d208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:05.794015Z",
     "start_time": "2025-08-19T03:04:04.995387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작성자 인덱스 구축 완료:\n",
      "  - Train writers: 180\n",
      "  - Val writers: 60\n",
      "  - Test writers: 60\n",
      "✓ 헬퍼 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# Stage 2 Baseline: MIL Bags (50% Forgery), Minimal & Reproducible\n",
    "# ==============================================================\n",
    "\n",
    "# 작성자별 인덱스 구축\n",
    "def build_writer_index(df, label_col, emb_cols):\n",
    "    w2 = {}\n",
    "    for wid, g in df.groupby(label_col):\n",
    "        w2[int(wid)] = {\n",
    "            'emb': g[emb_cols].to_numpy(dtype=np.float32),\n",
    "            'paths': g['path'].tolist() if 'path' in g.columns else [''] * len(g),\n",
    "            'idx': g.index.to_list()\n",
    "        }\n",
    "    return w2\n",
    "\n",
    "train_writers = build_writer_index(train_df, label_col, emb_cols)\n",
    "val_writers   = build_writer_index(val_df,   label_col, emb_cols)\n",
    "test_writers  = build_writer_index(test_df,  label_col, emb_cols)\n",
    "\n",
    "def list_writer_ids(wdict): \n",
    "    return list(wdict.keys())\n",
    "\n",
    "print(f\"작성자 인덱스 구축 완료:\")\n",
    "print(f\"  - Train writers: {len(train_writers)}\")\n",
    "print(f\"  - Val writers: {len(val_writers)}\")\n",
    "print(f\"  - Test writers: {len(test_writers)}\")\n",
    "\n",
    "# 샘플링 헬퍼 함수들\n",
    "def sample_k(n, k, rng, replace_if_needed=True):\n",
    "    \"\"\"n개 중에서 k개 샘플링 (부족하면 중복 허용)\"\"\"\n",
    "    if (not replace_if_needed) and n >= k:\n",
    "        return rng.choice(n, size=k, replace=False).tolist()\n",
    "    # 부족하면 중복 허용\n",
    "    return rng.choice(n, size=k, replace=True).tolist()\n",
    "\n",
    "def sliding_windows(seq, win=5, stride=1):\n",
    "    \"\"\"슬라이딩 윈도우로 시퀀스 분할\"\"\"\n",
    "    # seq: list of tuples (emb, wid, path, orig_idx)\n",
    "    windows, metas = [], []\n",
    "    for i in range(0, len(seq) - win + 1, stride):\n",
    "        chunk = seq[i:i+win]\n",
    "        windows.append(np.stack([e for (e,_,_,_) in chunk], axis=0))  # (5, D)\n",
    "        metas.append({\n",
    "            'window_idx': i,\n",
    "            'word_indices': [oi for (_,_,_,oi) in chunk],\n",
    "            'word_paths':   [p  for (_,_,p, _) in chunk],\n",
    "            'writer_ids':   [w  for (_,w,_, _) in chunk],\n",
    "        })\n",
    "    return windows, metas\n",
    "\n",
    "def pack(words, wid, W):\n",
    "    \"\"\"단어 인덱스를 임베딩 튜플로 변환\"\"\"\n",
    "    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n",
    "    return [(emb[w], wid, paths[w], idxs[w]) for w in words]\n",
    "\n",
    "print(\"✓ 헬퍼 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hu8mulwsryd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:05.806339Z",
     "start_time": "2025-08-19T03:04:05.797159Z"
    }
   },
   "outputs": [],
   "source": "# Bag 생성 함수 (개선된 베이스라인 - 순수 윈도우)\nWIN = 5; STRIDE = 1; INSTANCES_PER_BAG = 10\nTOK_NEG = 14; TOK_POS_A = 7; TOK_POS_B = 7\n\ndef make_negative_bag(wid, W, rng):\n    \"\"\"단일 작성자 Bag (레이블 0)\"\"\"\n    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n    sel = sample_k(len(emb), TOK_NEG, rng, replace_if_needed=True)\n    seq = pack(sel, wid, W)\n    wins, metas = sliding_windows(seq, WIN, STRIDE)\n    bag = np.stack(wins[:INSTANCES_PER_BAG], axis=0)  # (10, 5, D)\n    return bag, metas[:INSTANCES_PER_BAG], [int(wid)]\n\n# === (NEW) 한 작성자 전용 윈도우 생성 헬퍼 ==========================\ndef make_pure_windows_for_writer(wid, W, rng, tokens_per_writer=14, win=5, stride=1):\n    \"\"\"\n    한 작성자 wid의 임베딩에서 tokens_per_writer개를 뽑아\n    슬라이딩 윈도우(win,stride)로 '순수(single-writer) 윈도우' 리스트를 만든다.\n    반환: (windows, metas)\n      - windows: List[np.ndarray (win, D)]\n      - metas  : List[dict] (writer_ids가 모두 wid로 채워짐)\n    \"\"\"\n    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n    # 데이터가 부족하면 replace=True로 보완(현 샘플러 규약 유지)\n    sel = sample_k(len(emb), tokens_per_writer, rng, replace_if_needed=True)\n    seq = pack(sel, wid, W)                  # [(emb, wid, path, orig_idx), ...]\n    wins, metas = sliding_windows(seq, win, stride)\n    return wins, metas\n\n# === (REPLACE) Positive bag 생성 로직: 순수 윈도우만으로 구성 ==========\ndef make_positive_bag(widA, widB, WA, WB, rng,\n                      tokens_per_writer=14,  # A/B 각각에서 뽑을 토큰 수 (14면 여유있게 10윈도우 생성)\n                      inst_from_A=5, inst_from_B=5,\n                      order='A5B5'           # 'A5B5' | 'ABAB' | 'shuffle'\n                      ):\n    \"\"\"\n    목표: 한 윈도우에 항상 한 명의 작성자만 포함.\n    절차: A 전용 윈도우 K개 + B 전용 윈도우 K개 생성 → 5개씩 골라 10개로 bag 구성.\n    \"\"\"\n    # 1) A/B 전용 순수 윈도우 생성\n    winA, metaA = make_pure_windows_for_writer(widA, WA, rng,\n                                               tokens_per_writer=tokens_per_writer,\n                                               win=WIN, stride=STRIDE)\n    winB, metaB = make_pure_windows_for_writer(widB, WB, rng,\n                                               tokens_per_writer=tokens_per_writer,\n                                               win=WIN, stride=STRIDE)\n    # 2) 각 쪽에서 inst_from_*개 선택 (윈도우가 부족하면 replace로 보완)\n    def pick_k(wins, metas, k):\n        if len(wins) >= k:\n            idx = rng.choice(len(wins), size=k, replace=False)\n        else:\n            # 부족하면 중복 허용(동일 윈도우 재사용) — 데이터가 적은 작성자를 보호\n            idx = rng.choice(len(wins), size=k, replace=True)\n        return [wins[i] for i in idx], [metas[i] for i in idx]\n\n    pickA_w, pickA_m = pick_k(winA, metaA, inst_from_A)\n    pickB_w, pickB_m = pick_k(winB, metaB, inst_from_B)\n\n    # 3) 순서 구성\n    if order == 'A5B5':\n        seq_w = pickA_w + pickB_w\n        seq_m = pickA_m + pickB_m\n    elif order == 'ABAB':\n        seq_w, seq_m = [], []\n        z = min(inst_from_A, inst_from_B)\n        for i in range(z):\n            seq_w.extend([pickA_w[i], pickB_w[i]])\n            seq_m.extend([pickA_m[i], pickB_m[i]])\n        # 남는 쪽이 있다면 뒤에 붙임\n        if inst_from_A > z:\n            seq_w.extend(pickA_w[z:]); seq_m.extend(pickA_m[z:])\n        if inst_from_B > z:\n            seq_w.extend(pickB_w[z:]); seq_m.extend(pickB_m[z:])\n    else:  # 'shuffle'\n        combined = list(zip(pickA_w + pickB_w, pickA_m + pickB_m))\n        rng.shuffle(combined)\n        seq_w = [w for (w, _) in combined]\n        seq_m = [m for (_, m) in combined]\n\n    # 4) 최종 10개로 트림(혹여 초과되면)\n    seq_w = seq_w[:INSTANCES_PER_BAG]\n    seq_m = seq_m[:INSTANCES_PER_BAG]\n\n    # 5) Stack & return\n    bag_tensor = np.stack(seq_w, axis=0)  # (10, 5, D)\n    return bag_tensor, seq_m, [int(widA), int(widB)]\n\nprint(\"✓ Bag 생성 함수 정의 완료 (순수 윈도우 버전)\")\nprint(f\"  - Negative: {TOK_NEG}개 단어 → {INSTANCES_PER_BAG}개 인스턴스\")\nprint(f\"  - Positive: A/B 각각 순수 윈도우 생성 → A5B5 배치 (기본)\")\nprint(f\"  - 윈도우: (win={WIN}, stride={STRIDE})\")\nprint(f\"  - 각 윈도우는 단일 작성자만 포함!\")"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fmruxme0xt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:05.818150Z",
     "start_time": "2025-08-19T03:04:05.808353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Split 생성 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# Split 생성 함수\n",
    "def generate_split(name, WDICT, neg_per_writer=10, pos_per_writer=10, seed=42):\n",
    "    \"\"\"간단한 베이스라인 split 생성 (50/50 균형)\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    writer_ids = list_writer_ids(WDICT)\n",
    "    bags, labels, metadata = [], [], []\n",
    "    \n",
    "    print(f\"  {name} split 생성 중... (Writers: {len(writer_ids)})\")\n",
    "    \n",
    "    # Negative bags (단일 작성자)\n",
    "    for wid in writer_ids:\n",
    "        for _ in range(neg_per_writer):\n",
    "            bag, metas, authors = make_negative_bag(wid, WDICT[wid], rng)\n",
    "            bags.append(bag)\n",
    "            labels.append(0)\n",
    "            metadata.append({\n",
    "                'authors': authors, \n",
    "                'bag_type': 'negative',\n",
    "                'instances': metas\n",
    "            })\n",
    "    \n",
    "    # Positive bags (복수 작성자, 각 A당 pos_per_writer개, 파트너는 랜덤)\n",
    "    for widA in writer_ids:\n",
    "        for _ in range(pos_per_writer):\n",
    "            widB = rng.choice([w for w in writer_ids if w != widA])\n",
    "            bag, metas, authors = make_positive_bag(widA, widB, WDICT[widA], WDICT[widB], rng)\n",
    "            bags.append(bag)\n",
    "            labels.append(1)\n",
    "            metadata.append({\n",
    "                'authors': authors, \n",
    "                'bag_type': 'positive',\n",
    "                'instances': metas\n",
    "            })\n",
    "    \n",
    "    # 전체 셔플\n",
    "    idx = rng.permutation(len(labels))\n",
    "    bags = [bags[i] for i in idx]\n",
    "    labels = [int(labels[i]) for i in idx]\n",
    "    metadata = [metadata[i] for i in idx]\n",
    "    \n",
    "    # 요약 출력\n",
    "    n_pos = sum(labels)\n",
    "    n_tot = len(labels)\n",
    "    print(f\"    → Total: {n_tot}, Positive: {n_pos} ({n_pos/n_tot*100:.1f}%), Negative: {n_tot-n_pos}\")\n",
    "    \n",
    "    # 간단 검증\n",
    "    assert len(bags) == len(labels) == len(metadata), \"Length mismatch\"\n",
    "    assert bags[0].shape == (INSTANCES_PER_BAG, WIN, embed_dim), f\"Shape mismatch: {bags[0].shape}\"\n",
    "    \n",
    "    return bags, labels, metadata\n",
    "\n",
    "print(\"✓ Split 생성 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68rg6jgcskq",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:08.927779Z",
     "start_time": "2025-08-19T03:04:05.819908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 베이스라인 Bags 생성 시작...\n",
      "설정: Negative=10/writer, Positive=10/writer\n",
      "  Train split 생성 중... (Writers: 180)\n",
      "    → Total: 3600, Positive: 1800 (50.0%), Negative: 1800\n",
      "  Val split 생성 중... (Writers: 60)\n",
      "    → Total: 1200, Positive: 600 (50.0%), Negative: 600\n",
      "  Test split 생성 중... (Writers: 60)\n",
      "    → Total: 1200, Positive: 600 (50.0%), Negative: 600\n",
      "\\n💾 파일 저장 중...\n",
      "💾 저장: bags_arcface_margin_0.4_50p_baseline_train.pkl\n",
      "↪️  호환 복사: bags_arcface_margin_0.4_50p_random_train.pkl\n",
      "💾 저장: bags_arcface_margin_0.4_50p_baseline_val.pkl\n",
      "↪️  호환 복사: bags_arcface_margin_0.4_50p_random_val.pkl\n",
      "💾 저장: bags_arcface_margin_0.4_50p_baseline_test.pkl\n",
      "↪️  호환 복사: bags_arcface_margin_0.4_50p_random_test.pkl\n",
      "\\n📊 최종 요약:\n",
      "Train: N=3600, Pos=1800 (50.0%), Neg=1800\n",
      "Val: N=1200, Pos=600 (50.0%), Neg=600\n",
      "Test: N=1200, Pos=600 (50.0%), Neg=600\n",
      "\\n✅ Stage 2 베이스라인 생성 완료!\n",
      "📋 레이블 정보:\n",
      "  - Label 0 (Negative): 단일 작성자 (진짜)\n",
      "  - Label 1 (Positive): 복수 작성자 (위조)\n",
      "🔗 Stage 3에서 기존 파일명으로 로드 가능\n"
     ]
    }
   ],
   "source": [
    "# 베이스라인 Bag 생성 실행\n",
    "NEG_PW = 10  # 작성자별 negative bags\n",
    "POS_PW = 10  # 작성자별 positive bags → 전체 약 50/50\n",
    "\n",
    "print(\"🔄 베이스라인 Bags 생성 시작...\")\n",
    "print(f\"설정: Negative={NEG_PW}/writer, Positive={POS_PW}/writer\")\n",
    "\n",
    "# 모든 split 생성\n",
    "train_bags, train_labels, train_meta = generate_split('Train', train_writers, NEG_PW, POS_PW, seed=SEED_BASE+0)\n",
    "val_bags,   val_labels,   val_meta   = generate_split('Val',   val_writers,   NEG_PW, POS_PW, seed=SEED_BASE+10)\n",
    "test_bags,  test_labels,  test_meta  = generate_split('Test',  test_writers,  NEG_PW, POS_PW, seed=SEED_BASE+20)\n",
    "\n",
    "# 저장 함수\n",
    "def save_split(bags, labels, meta, tag, compat_copy=True):\n",
    "    base = os.path.join(bags_dir, f\"bags_arcface_margin_{margin_value}_50p_baseline_{tag}.pkl\")\n",
    "    with open(base, 'wb') as f:\n",
    "        pickle.dump({'bags': bags, 'labels': labels, 'metadata': meta}, f)\n",
    "    print(f\"💾 저장: {os.path.basename(base)}\")\n",
    "    \n",
    "    if compat_copy:\n",
    "        # Stage3 호환을 위한 복사본 (기존 파일명)\n",
    "        alias = os.path.join(bags_dir, f\"bags_arcface_margin_{margin_value}_50p_random_{tag}.pkl\")\n",
    "        with open(alias, 'wb') as f:\n",
    "            pickle.dump({'bags': bags, 'labels': labels, 'metadata': meta}, f)\n",
    "        print(f\"↪️  호환 복사: {os.path.basename(alias)}\")\n",
    "\n",
    "# 저장 실행\n",
    "print(\"\\\\n💾 파일 저장 중...\")\n",
    "save_split(train_bags, train_labels, train_meta, 'train', compat_copy=True)\n",
    "save_split(val_bags,   val_labels,   val_meta,   'val',   compat_copy=True)\n",
    "save_split(test_bags,  test_labels,  test_meta,  'test',  compat_copy=True)\n",
    "\n",
    "# 최종 요약\n",
    "def summarize(name, labels):\n",
    "    n = len(labels)\n",
    "    p = sum(labels)\n",
    "    print(f\"{name}: N={n}, Pos={p} ({p/n*100:.1f}%), Neg={n-p}\")\n",
    "\n",
    "print(\"\\\\n📊 최종 요약:\")\n",
    "summarize('Train', train_labels)\n",
    "summarize('Val',   val_labels)\n",
    "summarize('Test',  test_labels)\n",
    "\n",
    "print(\"\\\\n✅ Stage 2 베이스라인 생성 완료!\")\n",
    "print(\"📋 레이블 정보:\")\n",
    "print(\"  - Label 0 (Negative): 단일 작성자 (진짜)\")\n",
    "print(\"  - Label 1 (Positive): 복수 작성자 (위조)\")\n",
    "print(\"🔗 Stage 3에서 기존 파일명으로 로드 가능\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc7a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:09.050264Z",
     "start_time": "2025-08-19T03:04:08.929792Z"
    }
   },
   "outputs": [],
   "source": "# 간단한 검증 및 샘플 확인\n\n# 데이터 타입과 형태 검증\nprint(\"🔍 생성된 데이터 검증:\")\nprint(f\"  - Train bags shape: {np.array(train_bags).shape}\")\nprint(f\"  - Train labels 분포: {np.bincount(train_labels)}\")\nprint(f\"  - 첫 번째 bag shape: {train_bags[0].shape}\")\nprint(f\"  - Embedding 차원: {train_bags[0].shape[2]}\")\n\n# 샘플 메타데이터 확인\nprint(f\"\\n📋 샘플 메타데이터:\")\nneg_sample = next(meta for meta, label in zip(train_meta, train_labels) if label == 0)\npos_sample = next(meta for meta, label in zip(train_meta, train_labels) if label == 1)\n\nprint(f\"  Negative bag:\")\nprint(f\"    - Authors: {neg_sample['authors']} (개수: {len(neg_sample['authors'])})\")\nprint(f\"    - Type: {neg_sample['bag_type']}\")\nprint(f\"    - Instances: {len(neg_sample['instances'])}\")\n\nprint(f\"  Positive bag:\")\nprint(f\"    - Authors: {pos_sample['authors']} (개수: {len(pos_sample['authors'])})\")\nprint(f\"    - Type: {pos_sample['bag_type']}\")\nprint(f\"    - Instances: {len(pos_sample['instances'])}\")\n\n# 윈도우 순수성 검증 (핵심 개선사항)\nprint(f\"\\n🔍 윈도우 순수성 검증 (Positive bag):\")\nfor i, inst in enumerate(pos_sample['instances'][:5]):  # 처음 5개 인스턴스만 출력\n    writer_ids = inst['writer_ids']\n    unique_writers = len(set(writer_ids))\n    print(f\"    - 인스턴스 {i}: 작성자들 {writer_ids} → 고유 작성자 수: {unique_writers}\")\n    \n# 전체 Positive bag의 윈도우 순수성 통계\nprint(f\"\\n📊 전체 Positive bags 윈도우 순수성 통계:\")\npure_windows = 0\nmixed_windows = 0\nfor meta, label in zip(train_meta[:100], train_labels[:100]):  # 처음 100개 bag만 검사\n    if label == 1:  # Positive bags만\n        for inst in meta['instances']:\n            if len(set(inst['writer_ids'])) == 1:\n                pure_windows += 1\n            else:\n                mixed_windows += 1\n                \nprint(f\"  - 순수 윈도우 (단일 작성자): {pure_windows}\")\nprint(f\"  - 혼합 윈도우 (복수 작성자): {mixed_windows}\")\nprint(f\"  - 순수성 비율: {pure_windows/(pure_windows+mixed_windows)*100:.1f}%\")\n\nprint(f\"\\n✅ 모든 검증 통과 - 순수 윈도우 베이스라인 데이터 준비 완료!\")\nprint(f\"🚀 Stage 3에서 AB-MIL 학습을 진행할 수 있습니다.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e8015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:09.106998Z",
     "start_time": "2025-08-19T03:04:09.052276Z"
    }
   },
   "outputs": [],
   "source": "# 베이스라인 완료 - 순수 윈도우 버전\n\nprint(\"=\" * 60)\nprint(\"🎯 Stage 2 베이스라인 완료! (순수 윈도우 버전)\")\nprint(\"=\" * 60)\nprint(\"✅ 핵심 개선사항:\")\nprint(\"  • Negative: 단일 작성자 14개 단어 → 10개 윈도우 (변경 없음)\")\nprint(\"  • Positive: A 전용 5개 + B 전용 5개 윈도우 (A5B5 배치)\")\nprint(\"  • 윈도우 순수성: 100% (모든 윈도우가 단일 작성자)\")\nprint(\"  • 50/50 균형 보장\")\nprint()\nprint(\"🎯 개선 효과:\")\nprint(\"  • MIL 학습 안정성 향상\")\nprint(\"  • Attention 해석 가능성 증대\")\nprint(\"  • 더 명확한 작성자 클러스터링\")\nprint()\nprint(\"📁 생성된 파일:\")\nprint(f\"  • bags_arcface_margin_{margin_value}_50p_baseline_*.pkl (새 이름)\")\nprint(f\"  • bags_arcface_margin_{margin_value}_50p_random_*.pkl (Stage3 호환)\")\nprint()\nprint(\"🚀 다음 단계: Stage 3에서 AB-MIL 학습\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}