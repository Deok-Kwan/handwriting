{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30792b37",
   "metadata": {},
   "source": "# Stage 2 Baseline: MIL Bag Generation (50% Forgery) - ìˆœìˆ˜ ìœˆë„ìš° ë²„ì „\n\nì´ ë…¸íŠ¸ë¶ì€ Stage 1ì—ì„œ ì¶”ì¶œí•œ ArcFace ì„ë² ë”©ì„ ì´ìš©í•´ Multiple Instance Learning(MIL) í•™ìŠµì„ ìœ„í•œ **ê°œì„ ëœ ë² ì´ìŠ¤ë¼ì¸** Bag ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n\n**í•µì‹¬ ê°œì„ ì‚¬í•­ (ìˆœìˆ˜ ìœˆë„ìš°):**\n- **Negative (ë¼ë²¨ 0)**: í•œ ì‘ì„±ì 14ê°œ ë‹¨ì–´ â†’ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° (ë³€ê²½ ì—†ìŒ)\n- **Positive (ë¼ë²¨ 1)**: A ì „ìš© ìœˆë„ìš° 5ê°œ + B ì „ìš© ìœˆë„ìš° 5ê°œ â†’ **ê° ìœˆë„ìš°ëŠ” ë‹¨ì¼ ì‘ì„±ìë§Œ í¬í•¨**\n- **ìœˆë„ìš° ìˆœìˆ˜ì„± 100%**: ëª¨ë“  ìœˆë„ìš°ê°€ ë‹¨ì¼ ì‘ì„±ìì˜ í† í°ë§Œìœ¼ë¡œ êµ¬ì„±\n- **50/50 ê· í˜•**: ê° splitì—ì„œ ì •í™•íˆ 50% Positive, 50% Negative ë¹„ìœ¨\n\n**ë³€ê²½ ì´ìœ :**\n- ê¸°ì¡´: A 7ê°œ + B 7ê°œë¥¼ ì „ì²´ ì…”í”Œ â†’ í˜¼í•© ìœˆë„ìš° ë°œìƒ (í•œ ìœˆë„ìš°ì— Aì™€ Bê°€ ì„ì„)\n- ê°œì„ : A ì „ìš© ìœˆë„ìš°ì™€ B ì „ìš© ìœˆë„ìš°ë¥¼ ë”°ë¡œ ìƒì„± â†’ ìœˆë„ìš° ë ˆë²¨ì—ì„œ í•©ì¹¨ â†’ ìˆœìˆ˜ ìœˆë„ìš° ë³´ì¥"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01af97fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:03:51.376502Z",
     "start_time": "2025-08-19T03:03:50.935669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™˜ê²½ ì„¤ì • ì™„ë£Œ: GPU=1, SEED=42\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
    "import os, random, pickle, numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# GPU ì„¤ì • (ì„ íƒì )\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv('MIL_STAGE2_GPU', '1')\n",
    "\n",
    "# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
    "SEED_BASE = 42\n",
    "np.random.seed(SEED_BASE)\n",
    "random.seed(SEED_BASE)\n",
    "\n",
    "print(f'í™˜ê²½ ì„¤ì • ì™„ë£Œ: GPU={os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"N/A\")}, SEED={SEED_BASE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801ad3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:04.992500Z",
     "start_time": "2025-08-19T03:03:51.379313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¡œë”© ì™„ë£Œ:\n",
      "  - Embedding ì°¨ì›: 256\n",
      "  - Label ì»¬ëŸ¼: label\n",
      "  - Train: 208233, Val: 70533, Test: 72457\n",
      "  - ì›ë³¸ ë©”íƒ€ë°ì´í„°: 556128 rows\n"
     ]
    }
   ],
   "source": [
    "# ê²½ë¡œ ì„¤ì • ë° ë°ì´í„° ë¡œë”©\n",
    "embedding_dir = '/workspace/MIL/data/processed/embeddings'\n",
    "raw_meta_csv  = '/workspace/MIL/data/raw/naver_ocr.csv'  # ì„ íƒ ì‚¬í•­\n",
    "bags_dir      = '/workspace/MIL/data/processed/bags'\n",
    "os.makedirs(bags_dir, exist_ok=True)\n",
    "\n",
    "margin_value = '0.4'\n",
    "rng_global = np.random.default_rng(SEED_BASE)\n",
    "\n",
    "# CSV ë¡œë”© í•¨ìˆ˜\n",
    "def load_split_csv(split):\n",
    "    csv_path = os.path.join(embedding_dir, f'mil_arcface_margin_{margin_value}_{split}_data.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    label_col = 'label' if 'label' in df.columns else 'author_id'\n",
    "    emb_cols  = [c for c in df.columns if c.startswith('embedding')]\n",
    "    assert len(emb_cols) > 0, \"No embedding_* columns found.\"\n",
    "    return df, label_col, emb_cols\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "train_df, label_col, emb_cols = load_split_csv('train')\n",
    "val_df,   _,         _        = load_split_csv('val')\n",
    "test_df,  _,         _        = load_split_csv('test')\n",
    "embed_dim = len(emb_cols)\n",
    "\n",
    "print(f\"ë°ì´í„° ë¡œë”© ì™„ë£Œ:\")\n",
    "print(f\"  - Embedding ì°¨ì›: {embed_dim}\")\n",
    "print(f\"  - Label ì»¬ëŸ¼: {label_col}\")\n",
    "print(f\"  - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# ì„ íƒì  ì›ë³¸ ë©”íƒ€ë°ì´í„° ë¡œë”©\n",
    "try:\n",
    "    original_df = pd.read_csv(raw_meta_csv)\n",
    "    print(f\"  - ì›ë³¸ ë©”íƒ€ë°ì´í„°: {len(original_df)} rows\")\n",
    "    has_raw_meta = True\n",
    "except Exception:\n",
    "    print(f\"  - ì›ë³¸ ë©”íƒ€ë°ì´í„°: ì—†ìŒ\")\n",
    "    has_raw_meta = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vlqa78d208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:05.794015Z",
     "start_time": "2025-08-19T03:04:04.995387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ì„±ì ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ:\n",
      "  - Train writers: 180\n",
      "  - Val writers: 60\n",
      "  - Test writers: 60\n",
      "âœ“ í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# Stage 2 Baseline: MIL Bags (50% Forgery), Minimal & Reproducible\n",
    "# ==============================================================\n",
    "\n",
    "# ì‘ì„±ìë³„ ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "def build_writer_index(df, label_col, emb_cols):\n",
    "    w2 = {}\n",
    "    for wid, g in df.groupby(label_col):\n",
    "        w2[int(wid)] = {\n",
    "            'emb': g[emb_cols].to_numpy(dtype=np.float32),\n",
    "            'paths': g['path'].tolist() if 'path' in g.columns else [''] * len(g),\n",
    "            'idx': g.index.to_list()\n",
    "        }\n",
    "    return w2\n",
    "\n",
    "train_writers = build_writer_index(train_df, label_col, emb_cols)\n",
    "val_writers   = build_writer_index(val_df,   label_col, emb_cols)\n",
    "test_writers  = build_writer_index(test_df,  label_col, emb_cols)\n",
    "\n",
    "def list_writer_ids(wdict): \n",
    "    return list(wdict.keys())\n",
    "\n",
    "print(f\"ì‘ì„±ì ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ:\")\n",
    "print(f\"  - Train writers: {len(train_writers)}\")\n",
    "print(f\"  - Val writers: {len(val_writers)}\")\n",
    "print(f\"  - Test writers: {len(test_writers)}\")\n",
    "\n",
    "# ìƒ˜í”Œë§ í—¬í¼ í•¨ìˆ˜ë“¤\n",
    "def sample_k(n, k, rng, replace_if_needed=True):\n",
    "    \"\"\"nê°œ ì¤‘ì—ì„œ kê°œ ìƒ˜í”Œë§ (ë¶€ì¡±í•˜ë©´ ì¤‘ë³µ í—ˆìš©)\"\"\"\n",
    "    if (not replace_if_needed) and n >= k:\n",
    "        return rng.choice(n, size=k, replace=False).tolist()\n",
    "    # ë¶€ì¡±í•˜ë©´ ì¤‘ë³µ í—ˆìš©\n",
    "    return rng.choice(n, size=k, replace=True).tolist()\n",
    "\n",
    "def sliding_windows(seq, win=5, stride=1):\n",
    "    \"\"\"ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ë¶„í• \"\"\"\n",
    "    # seq: list of tuples (emb, wid, path, orig_idx)\n",
    "    windows, metas = [], []\n",
    "    for i in range(0, len(seq) - win + 1, stride):\n",
    "        chunk = seq[i:i+win]\n",
    "        windows.append(np.stack([e for (e,_,_,_) in chunk], axis=0))  # (5, D)\n",
    "        metas.append({\n",
    "            'window_idx': i,\n",
    "            'word_indices': [oi for (_,_,_,oi) in chunk],\n",
    "            'word_paths':   [p  for (_,_,p, _) in chunk],\n",
    "            'writer_ids':   [w  for (_,w,_, _) in chunk],\n",
    "        })\n",
    "    return windows, metas\n",
    "\n",
    "def pack(words, wid, W):\n",
    "    \"\"\"ë‹¨ì–´ ì¸ë±ìŠ¤ë¥¼ ì„ë² ë”© íŠœí”Œë¡œ ë³€í™˜\"\"\"\n",
    "    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n",
    "    return [(emb[w], wid, paths[w], idxs[w]) for w in words]\n",
    "\n",
    "print(\"âœ“ í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hu8mulwsryd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:05.806339Z",
     "start_time": "2025-08-19T03:04:05.797159Z"
    }
   },
   "outputs": [],
   "source": "# Bag ìƒì„± í•¨ìˆ˜ (ê°œì„ ëœ ë² ì´ìŠ¤ë¼ì¸ - ìˆœìˆ˜ ìœˆë„ìš°)\nWIN = 5; STRIDE = 1; INSTANCES_PER_BAG = 10\nTOK_NEG = 14; TOK_POS_A = 7; TOK_POS_B = 7\n\ndef make_negative_bag(wid, W, rng):\n    \"\"\"ë‹¨ì¼ ì‘ì„±ì Bag (ë ˆì´ë¸” 0)\"\"\"\n    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n    sel = sample_k(len(emb), TOK_NEG, rng, replace_if_needed=True)\n    seq = pack(sel, wid, W)\n    wins, metas = sliding_windows(seq, WIN, STRIDE)\n    bag = np.stack(wins[:INSTANCES_PER_BAG], axis=0)  # (10, 5, D)\n    return bag, metas[:INSTANCES_PER_BAG], [int(wid)]\n\n# === (NEW) í•œ ì‘ì„±ì ì „ìš© ìœˆë„ìš° ìƒì„± í—¬í¼ ==========================\ndef make_pure_windows_for_writer(wid, W, rng, tokens_per_writer=14, win=5, stride=1):\n    \"\"\"\n    í•œ ì‘ì„±ì widì˜ ì„ë² ë”©ì—ì„œ tokens_per_writerê°œë¥¼ ë½‘ì•„\n    ìŠ¬ë¼ì´ë”© ìœˆë„ìš°(win,stride)ë¡œ 'ìˆœìˆ˜(single-writer) ìœˆë„ìš°' ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“ ë‹¤.\n    ë°˜í™˜: (windows, metas)\n      - windows: List[np.ndarray (win, D)]\n      - metas  : List[dict] (writer_idsê°€ ëª¨ë‘ widë¡œ ì±„ì›Œì§)\n    \"\"\"\n    emb, paths, idxs = W['emb'], W['paths'], W['idx']\n    # ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ replace=Trueë¡œ ë³´ì™„(í˜„ ìƒ˜í”ŒëŸ¬ ê·œì•½ ìœ ì§€)\n    sel = sample_k(len(emb), tokens_per_writer, rng, replace_if_needed=True)\n    seq = pack(sel, wid, W)                  # [(emb, wid, path, orig_idx), ...]\n    wins, metas = sliding_windows(seq, win, stride)\n    return wins, metas\n\n# === (REPLACE) Positive bag ìƒì„± ë¡œì§: ìˆœìˆ˜ ìœˆë„ìš°ë§Œìœ¼ë¡œ êµ¬ì„± ==========\ndef make_positive_bag(widA, widB, WA, WB, rng,\n                      tokens_per_writer=14,  # A/B ê°ê°ì—ì„œ ë½‘ì„ í† í° ìˆ˜ (14ë©´ ì—¬ìœ ìˆê²Œ 10ìœˆë„ìš° ìƒì„±)\n                      inst_from_A=5, inst_from_B=5,\n                      order='A5B5'           # 'A5B5' | 'ABAB' | 'shuffle'\n                      ):\n    \"\"\"\n    ëª©í‘œ: í•œ ìœˆë„ìš°ì— í•­ìƒ í•œ ëª…ì˜ ì‘ì„±ìë§Œ í¬í•¨.\n    ì ˆì°¨: A ì „ìš© ìœˆë„ìš° Kê°œ + B ì „ìš© ìœˆë„ìš° Kê°œ ìƒì„± â†’ 5ê°œì”© ê³¨ë¼ 10ê°œë¡œ bag êµ¬ì„±.\n    \"\"\"\n    # 1) A/B ì „ìš© ìˆœìˆ˜ ìœˆë„ìš° ìƒì„±\n    winA, metaA = make_pure_windows_for_writer(widA, WA, rng,\n                                               tokens_per_writer=tokens_per_writer,\n                                               win=WIN, stride=STRIDE)\n    winB, metaB = make_pure_windows_for_writer(widB, WB, rng,\n                                               tokens_per_writer=tokens_per_writer,\n                                               win=WIN, stride=STRIDE)\n    # 2) ê° ìª½ì—ì„œ inst_from_*ê°œ ì„ íƒ (ìœˆë„ìš°ê°€ ë¶€ì¡±í•˜ë©´ replaceë¡œ ë³´ì™„)\n    def pick_k(wins, metas, k):\n        if len(wins) >= k:\n            idx = rng.choice(len(wins), size=k, replace=False)\n        else:\n            # ë¶€ì¡±í•˜ë©´ ì¤‘ë³µ í—ˆìš©(ë™ì¼ ìœˆë„ìš° ì¬ì‚¬ìš©) â€” ë°ì´í„°ê°€ ì ì€ ì‘ì„±ìë¥¼ ë³´í˜¸\n            idx = rng.choice(len(wins), size=k, replace=True)\n        return [wins[i] for i in idx], [metas[i] for i in idx]\n\n    pickA_w, pickA_m = pick_k(winA, metaA, inst_from_A)\n    pickB_w, pickB_m = pick_k(winB, metaB, inst_from_B)\n\n    # 3) ìˆœì„œ êµ¬ì„±\n    if order == 'A5B5':\n        seq_w = pickA_w + pickB_w\n        seq_m = pickA_m + pickB_m\n    elif order == 'ABAB':\n        seq_w, seq_m = [], []\n        z = min(inst_from_A, inst_from_B)\n        for i in range(z):\n            seq_w.extend([pickA_w[i], pickB_w[i]])\n            seq_m.extend([pickA_m[i], pickB_m[i]])\n        # ë‚¨ëŠ” ìª½ì´ ìˆë‹¤ë©´ ë’¤ì— ë¶™ì„\n        if inst_from_A > z:\n            seq_w.extend(pickA_w[z:]); seq_m.extend(pickA_m[z:])\n        if inst_from_B > z:\n            seq_w.extend(pickB_w[z:]); seq_m.extend(pickB_m[z:])\n    else:  # 'shuffle'\n        combined = list(zip(pickA_w + pickB_w, pickA_m + pickB_m))\n        rng.shuffle(combined)\n        seq_w = [w for (w, _) in combined]\n        seq_m = [m for (_, m) in combined]\n\n    # 4) ìµœì¢… 10ê°œë¡œ íŠ¸ë¦¼(í˜¹ì—¬ ì´ˆê³¼ë˜ë©´)\n    seq_w = seq_w[:INSTANCES_PER_BAG]\n    seq_m = seq_m[:INSTANCES_PER_BAG]\n\n    # 5) Stack & return\n    bag_tensor = np.stack(seq_w, axis=0)  # (10, 5, D)\n    return bag_tensor, seq_m, [int(widA), int(widB)]\n\nprint(\"âœ“ Bag ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ (ìˆœìˆ˜ ìœˆë„ìš° ë²„ì „)\")\nprint(f\"  - Negative: {TOK_NEG}ê°œ ë‹¨ì–´ â†’ {INSTANCES_PER_BAG}ê°œ ì¸ìŠ¤í„´ìŠ¤\")\nprint(f\"  - Positive: A/B ê°ê° ìˆœìˆ˜ ìœˆë„ìš° ìƒì„± â†’ A5B5 ë°°ì¹˜ (ê¸°ë³¸)\")\nprint(f\"  - ìœˆë„ìš°: (win={WIN}, stride={STRIDE})\")\nprint(f\"  - ê° ìœˆë„ìš°ëŠ” ë‹¨ì¼ ì‘ì„±ìë§Œ í¬í•¨!\")"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fmruxme0xt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:05.818150Z",
     "start_time": "2025-08-19T03:04:05.808353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Split ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Split ìƒì„± í•¨ìˆ˜\n",
    "def generate_split(name, WDICT, neg_per_writer=10, pos_per_writer=10, seed=42):\n",
    "    \"\"\"ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸ split ìƒì„± (50/50 ê· í˜•)\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    writer_ids = list_writer_ids(WDICT)\n",
    "    bags, labels, metadata = [], [], []\n",
    "    \n",
    "    print(f\"  {name} split ìƒì„± ì¤‘... (Writers: {len(writer_ids)})\")\n",
    "    \n",
    "    # Negative bags (ë‹¨ì¼ ì‘ì„±ì)\n",
    "    for wid in writer_ids:\n",
    "        for _ in range(neg_per_writer):\n",
    "            bag, metas, authors = make_negative_bag(wid, WDICT[wid], rng)\n",
    "            bags.append(bag)\n",
    "            labels.append(0)\n",
    "            metadata.append({\n",
    "                'authors': authors, \n",
    "                'bag_type': 'negative',\n",
    "                'instances': metas\n",
    "            })\n",
    "    \n",
    "    # Positive bags (ë³µìˆ˜ ì‘ì„±ì, ê° Aë‹¹ pos_per_writerê°œ, íŒŒíŠ¸ë„ˆëŠ” ëœë¤)\n",
    "    for widA in writer_ids:\n",
    "        for _ in range(pos_per_writer):\n",
    "            widB = rng.choice([w for w in writer_ids if w != widA])\n",
    "            bag, metas, authors = make_positive_bag(widA, widB, WDICT[widA], WDICT[widB], rng)\n",
    "            bags.append(bag)\n",
    "            labels.append(1)\n",
    "            metadata.append({\n",
    "                'authors': authors, \n",
    "                'bag_type': 'positive',\n",
    "                'instances': metas\n",
    "            })\n",
    "    \n",
    "    # ì „ì²´ ì…”í”Œ\n",
    "    idx = rng.permutation(len(labels))\n",
    "    bags = [bags[i] for i in idx]\n",
    "    labels = [int(labels[i]) for i in idx]\n",
    "    metadata = [metadata[i] for i in idx]\n",
    "    \n",
    "    # ìš”ì•½ ì¶œë ¥\n",
    "    n_pos = sum(labels)\n",
    "    n_tot = len(labels)\n",
    "    print(f\"    â†’ Total: {n_tot}, Positive: {n_pos} ({n_pos/n_tot*100:.1f}%), Negative: {n_tot-n_pos}\")\n",
    "    \n",
    "    # ê°„ë‹¨ ê²€ì¦\n",
    "    assert len(bags) == len(labels) == len(metadata), \"Length mismatch\"\n",
    "    assert bags[0].shape == (INSTANCES_PER_BAG, WIN, embed_dim), f\"Shape mismatch: {bags[0].shape}\"\n",
    "    \n",
    "    return bags, labels, metadata\n",
    "\n",
    "print(\"âœ“ Split ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68rg6jgcskq",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:08.927779Z",
     "start_time": "2025-08-19T03:04:05.819908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ë² ì´ìŠ¤ë¼ì¸ Bags ìƒì„± ì‹œì‘...\n",
      "ì„¤ì •: Negative=10/writer, Positive=10/writer\n",
      "  Train split ìƒì„± ì¤‘... (Writers: 180)\n",
      "    â†’ Total: 3600, Positive: 1800 (50.0%), Negative: 1800\n",
      "  Val split ìƒì„± ì¤‘... (Writers: 60)\n",
      "    â†’ Total: 1200, Positive: 600 (50.0%), Negative: 600\n",
      "  Test split ìƒì„± ì¤‘... (Writers: 60)\n",
      "    â†’ Total: 1200, Positive: 600 (50.0%), Negative: 600\n",
      "\\nğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...\n",
      "ğŸ’¾ ì €ì¥: bags_arcface_margin_0.4_50p_baseline_train.pkl\n",
      "â†ªï¸  í˜¸í™˜ ë³µì‚¬: bags_arcface_margin_0.4_50p_random_train.pkl\n",
      "ğŸ’¾ ì €ì¥: bags_arcface_margin_0.4_50p_baseline_val.pkl\n",
      "â†ªï¸  í˜¸í™˜ ë³µì‚¬: bags_arcface_margin_0.4_50p_random_val.pkl\n",
      "ğŸ’¾ ì €ì¥: bags_arcface_margin_0.4_50p_baseline_test.pkl\n",
      "â†ªï¸  í˜¸í™˜ ë³µì‚¬: bags_arcface_margin_0.4_50p_random_test.pkl\n",
      "\\nğŸ“Š ìµœì¢… ìš”ì•½:\n",
      "Train: N=3600, Pos=1800 (50.0%), Neg=1800\n",
      "Val: N=1200, Pos=600 (50.0%), Neg=600\n",
      "Test: N=1200, Pos=600 (50.0%), Neg=600\n",
      "\\nâœ… Stage 2 ë² ì´ìŠ¤ë¼ì¸ ìƒì„± ì™„ë£Œ!\n",
      "ğŸ“‹ ë ˆì´ë¸” ì •ë³´:\n",
      "  - Label 0 (Negative): ë‹¨ì¼ ì‘ì„±ì (ì§„ì§œ)\n",
      "  - Label 1 (Positive): ë³µìˆ˜ ì‘ì„±ì (ìœ„ì¡°)\n",
      "ğŸ”— Stage 3ì—ì„œ ê¸°ì¡´ íŒŒì¼ëª…ìœ¼ë¡œ ë¡œë“œ ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# ë² ì´ìŠ¤ë¼ì¸ Bag ìƒì„± ì‹¤í–‰\n",
    "NEG_PW = 10  # ì‘ì„±ìë³„ negative bags\n",
    "POS_PW = 10  # ì‘ì„±ìë³„ positive bags â†’ ì „ì²´ ì•½ 50/50\n",
    "\n",
    "print(\"ğŸ”„ ë² ì´ìŠ¤ë¼ì¸ Bags ìƒì„± ì‹œì‘...\")\n",
    "print(f\"ì„¤ì •: Negative={NEG_PW}/writer, Positive={POS_PW}/writer\")\n",
    "\n",
    "# ëª¨ë“  split ìƒì„±\n",
    "train_bags, train_labels, train_meta = generate_split('Train', train_writers, NEG_PW, POS_PW, seed=SEED_BASE+0)\n",
    "val_bags,   val_labels,   val_meta   = generate_split('Val',   val_writers,   NEG_PW, POS_PW, seed=SEED_BASE+10)\n",
    "test_bags,  test_labels,  test_meta  = generate_split('Test',  test_writers,  NEG_PW, POS_PW, seed=SEED_BASE+20)\n",
    "\n",
    "# ì €ì¥ í•¨ìˆ˜\n",
    "def save_split(bags, labels, meta, tag, compat_copy=True):\n",
    "    base = os.path.join(bags_dir, f\"bags_arcface_margin_{margin_value}_50p_baseline_{tag}.pkl\")\n",
    "    with open(base, 'wb') as f:\n",
    "        pickle.dump({'bags': bags, 'labels': labels, 'metadata': meta}, f)\n",
    "    print(f\"ğŸ’¾ ì €ì¥: {os.path.basename(base)}\")\n",
    "    \n",
    "    if compat_copy:\n",
    "        # Stage3 í˜¸í™˜ì„ ìœ„í•œ ë³µì‚¬ë³¸ (ê¸°ì¡´ íŒŒì¼ëª…)\n",
    "        alias = os.path.join(bags_dir, f\"bags_arcface_margin_{margin_value}_50p_random_{tag}.pkl\")\n",
    "        with open(alias, 'wb') as f:\n",
    "            pickle.dump({'bags': bags, 'labels': labels, 'metadata': meta}, f)\n",
    "        print(f\"â†ªï¸  í˜¸í™˜ ë³µì‚¬: {os.path.basename(alias)}\")\n",
    "\n",
    "# ì €ì¥ ì‹¤í–‰\n",
    "print(\"\\\\nğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...\")\n",
    "save_split(train_bags, train_labels, train_meta, 'train', compat_copy=True)\n",
    "save_split(val_bags,   val_labels,   val_meta,   'val',   compat_copy=True)\n",
    "save_split(test_bags,  test_labels,  test_meta,  'test',  compat_copy=True)\n",
    "\n",
    "# ìµœì¢… ìš”ì•½\n",
    "def summarize(name, labels):\n",
    "    n = len(labels)\n",
    "    p = sum(labels)\n",
    "    print(f\"{name}: N={n}, Pos={p} ({p/n*100:.1f}%), Neg={n-p}\")\n",
    "\n",
    "print(\"\\\\nğŸ“Š ìµœì¢… ìš”ì•½:\")\n",
    "summarize('Train', train_labels)\n",
    "summarize('Val',   val_labels)\n",
    "summarize('Test',  test_labels)\n",
    "\n",
    "print(\"\\\\nâœ… Stage 2 ë² ì´ìŠ¤ë¼ì¸ ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"ğŸ“‹ ë ˆì´ë¸” ì •ë³´:\")\n",
    "print(\"  - Label 0 (Negative): ë‹¨ì¼ ì‘ì„±ì (ì§„ì§œ)\")\n",
    "print(\"  - Label 1 (Positive): ë³µìˆ˜ ì‘ì„±ì (ìœ„ì¡°)\")\n",
    "print(\"ğŸ”— Stage 3ì—ì„œ ê¸°ì¡´ íŒŒì¼ëª…ìœ¼ë¡œ ë¡œë“œ ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc7a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:09.050264Z",
     "start_time": "2025-08-19T03:04:08.929792Z"
    }
   },
   "outputs": [],
   "source": "# ê°„ë‹¨í•œ ê²€ì¦ ë° ìƒ˜í”Œ í™•ì¸\n\n# ë°ì´í„° íƒ€ì…ê³¼ í˜•íƒœ ê²€ì¦\nprint(\"ğŸ” ìƒì„±ëœ ë°ì´í„° ê²€ì¦:\")\nprint(f\"  - Train bags shape: {np.array(train_bags).shape}\")\nprint(f\"  - Train labels ë¶„í¬: {np.bincount(train_labels)}\")\nprint(f\"  - ì²« ë²ˆì§¸ bag shape: {train_bags[0].shape}\")\nprint(f\"  - Embedding ì°¨ì›: {train_bags[0].shape[2]}\")\n\n# ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° í™•ì¸\nprint(f\"\\nğŸ“‹ ìƒ˜í”Œ ë©”íƒ€ë°ì´í„°:\")\nneg_sample = next(meta for meta, label in zip(train_meta, train_labels) if label == 0)\npos_sample = next(meta for meta, label in zip(train_meta, train_labels) if label == 1)\n\nprint(f\"  Negative bag:\")\nprint(f\"    - Authors: {neg_sample['authors']} (ê°œìˆ˜: {len(neg_sample['authors'])})\")\nprint(f\"    - Type: {neg_sample['bag_type']}\")\nprint(f\"    - Instances: {len(neg_sample['instances'])}\")\n\nprint(f\"  Positive bag:\")\nprint(f\"    - Authors: {pos_sample['authors']} (ê°œìˆ˜: {len(pos_sample['authors'])})\")\nprint(f\"    - Type: {pos_sample['bag_type']}\")\nprint(f\"    - Instances: {len(pos_sample['instances'])}\")\n\n# ìœˆë„ìš° ìˆœìˆ˜ì„± ê²€ì¦ (í•µì‹¬ ê°œì„ ì‚¬í•­)\nprint(f\"\\nğŸ” ìœˆë„ìš° ìˆœìˆ˜ì„± ê²€ì¦ (Positive bag):\")\nfor i, inst in enumerate(pos_sample['instances'][:5]):  # ì²˜ìŒ 5ê°œ ì¸ìŠ¤í„´ìŠ¤ë§Œ ì¶œë ¥\n    writer_ids = inst['writer_ids']\n    unique_writers = len(set(writer_ids))\n    print(f\"    - ì¸ìŠ¤í„´ìŠ¤ {i}: ì‘ì„±ìë“¤ {writer_ids} â†’ ê³ ìœ  ì‘ì„±ì ìˆ˜: {unique_writers}\")\n    \n# ì „ì²´ Positive bagì˜ ìœˆë„ìš° ìˆœìˆ˜ì„± í†µê³„\nprint(f\"\\nğŸ“Š ì „ì²´ Positive bags ìœˆë„ìš° ìˆœìˆ˜ì„± í†µê³„:\")\npure_windows = 0\nmixed_windows = 0\nfor meta, label in zip(train_meta[:100], train_labels[:100]):  # ì²˜ìŒ 100ê°œ bagë§Œ ê²€ì‚¬\n    if label == 1:  # Positive bagsë§Œ\n        for inst in meta['instances']:\n            if len(set(inst['writer_ids'])) == 1:\n                pure_windows += 1\n            else:\n                mixed_windows += 1\n                \nprint(f\"  - ìˆœìˆ˜ ìœˆë„ìš° (ë‹¨ì¼ ì‘ì„±ì): {pure_windows}\")\nprint(f\"  - í˜¼í•© ìœˆë„ìš° (ë³µìˆ˜ ì‘ì„±ì): {mixed_windows}\")\nprint(f\"  - ìˆœìˆ˜ì„± ë¹„ìœ¨: {pure_windows/(pure_windows+mixed_windows)*100:.1f}%\")\n\nprint(f\"\\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼ - ìˆœìˆ˜ ìœˆë„ìš° ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\nprint(f\"ğŸš€ Stage 3ì—ì„œ AB-MIL í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e8015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T03:04:09.106998Z",
     "start_time": "2025-08-19T03:04:09.052276Z"
    }
   },
   "outputs": [],
   "source": "# ë² ì´ìŠ¤ë¼ì¸ ì™„ë£Œ - ìˆœìˆ˜ ìœˆë„ìš° ë²„ì „\n\nprint(\"=\" * 60)\nprint(\"ğŸ¯ Stage 2 ë² ì´ìŠ¤ë¼ì¸ ì™„ë£Œ! (ìˆœìˆ˜ ìœˆë„ìš° ë²„ì „)\")\nprint(\"=\" * 60)\nprint(\"âœ… í•µì‹¬ ê°œì„ ì‚¬í•­:\")\nprint(\"  â€¢ Negative: ë‹¨ì¼ ì‘ì„±ì 14ê°œ ë‹¨ì–´ â†’ 10ê°œ ìœˆë„ìš° (ë³€ê²½ ì—†ìŒ)\")\nprint(\"  â€¢ Positive: A ì „ìš© 5ê°œ + B ì „ìš© 5ê°œ ìœˆë„ìš° (A5B5 ë°°ì¹˜)\")\nprint(\"  â€¢ ìœˆë„ìš° ìˆœìˆ˜ì„±: 100% (ëª¨ë“  ìœˆë„ìš°ê°€ ë‹¨ì¼ ì‘ì„±ì)\")\nprint(\"  â€¢ 50/50 ê· í˜• ë³´ì¥\")\nprint()\nprint(\"ğŸ¯ ê°œì„  íš¨ê³¼:\")\nprint(\"  â€¢ MIL í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ\")\nprint(\"  â€¢ Attention í•´ì„ ê°€ëŠ¥ì„± ì¦ëŒ€\")\nprint(\"  â€¢ ë” ëª…í™•í•œ ì‘ì„±ì í´ëŸ¬ìŠ¤í„°ë§\")\nprint()\nprint(\"ğŸ“ ìƒì„±ëœ íŒŒì¼:\")\nprint(f\"  â€¢ bags_arcface_margin_{margin_value}_50p_baseline_*.pkl (ìƒˆ ì´ë¦„)\")\nprint(f\"  â€¢ bags_arcface_margin_{margin_value}_50p_random_*.pkl (Stage3 í˜¸í™˜)\")\nprint()\nprint(\"ğŸš€ ë‹¤ìŒ ë‹¨ê³„: Stage 3ì—ì„œ AB-MIL í•™ìŠµ\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}