# MIL 프로젝트: 문서 내 복수 작성자 탐지 연구

## 1. 연구 개요

### 핵심 질문
**"하나의 문서 내에 복수 작성자가 존재하는지를 AI가 자동으로 탐지할 수 있는가?"**

전통적인 필적 감정은 두 문서를 비교하는 데 집중했지만, 실제 범죄 현장에서는 문서의 일부만 교묘하게 위조하는 경우가 많습니다. 본 연구는 이러한 현실적 문제를 해결하기 위해 시작되었습니다.

### 실제 시나리오와 사회적 영향

#### 법적 문서 위조
- **유언장 위조**: 상속 분쟁에서 유언장 전체는 고인이 작성했지만, 핵심적인 상속 비율이나 서명 부분만 다른 사람이 위조하는 사례가 빈번합니다. 2023년 한국에서만 유언장 관련 소송이 연간 3,000건을 넘어섰습니다.
- **계약서 변조**: 부동산 계약서나 대출 계약서에서 금액, 날짜, 조건 등 일부 내용만 변조하여 막대한 경제적 피해를 입히는 사례가 증가하고 있습니다.
- **공문서 조작**: 학위증명서, 재직증명서 등에서 특정 정보만 수정하여 자격을 위조하는 범죄가 디지털 시대에도 여전히 발생합니다.

#### 개인적 문서 조작
- **편지와 일기**: 개인 간 분쟁에서 편지나 일기의 일부를 조작하여 증거로 제출하는 경우
- **의료 기록**: 보험금 청구를 위해 의료 기록의 일부를 변조하는 사례
- **학술 문서**: 연구 노트나 실험 기록에서 일부 데이터만 조작하는 연구 부정행위

### 연구의 독창성과 도전

| 측면 | 기존 연구 (문서 간 비교) | 본 연구 (문서 내부 분석) |
|------|-------------------------|-------------------------|
| **문제 정의** | "문서 A와 문서 B가 같은 작성자인가?" | "문서 A 내부에 다른 작성자가 숨어있는가?" |
| **입력 데이터** | 두 개의 완전한 문서 | 하나의 문서 |
| **비교 대상** | 문서 전체의 평균적 특징 | 문서 내 개별 부분들의 일관성 |
| **난이도** | 상대적으로 쉬움 (많은 정보) | 매우 어려움 (미세한 차이) |
| **실용성** | 제한적 (두 문서가 모두 필요) | 높음 (단일 문서만으로 판별) |
| **정확도** | 94.45% (Kim et al., 2024) | 목표: 80% 이상 |

### 왜 이 문제가 어려운가?

1. **신호 대 잡음 비율**: 문서의 99%가 진짜이고 1%만 위조된 경우, 그 1%를 찾아내는 것은 "건초더미에서 바늘 찾기"와 같습니다.

2. **필기의 자연스러운 변동성**: 같은 사람도 피로도, 감정 상태, 필기 도구에 따라 필체가 달라집니다. 이러한 정상적 변동과 다른 작성자의 개입을 구분하는 것은 매우 어렵습니다.

3. **컨텍스트 의존성**: 단어나 문장은 주변 맥락에 따라 쓰여지므로, 고립된 패치만으로는 판단이 어렵습니다.

## 2. Multiple Instance Learning (MIL) 프레임워크

### MIL의 이론적 배경

MIL은 1997년 Dietterich et al.이 약물 발견 문제를 해결하기 위해 처음 제안한 기계학습 패러다임입니다. 전통적인 지도학습이 각 샘플에 대한 레이블을 요구하는 반면, MIL은 샘플들의 집합(Bag)에 대한 레이블만 필요합니다.

### 직관적 이해: 의학 진단 비유

병원에서 환자의 CT 스캔을 생각해보세요:
- **전통적 방법**: 의사가 각 슬라이스마다 종양 유무를 표시 (비용 높음)
- **MIL 방법**: "이 환자에게 종양이 있다"는 정보만으로 학습 (현실적)

마찬가지로 필기 분석에서:
- **전통적 방법**: 각 단어마다 작성자 표시 (불가능에 가까움)
- **MIL 방법**: "이 문서에 복수 작성자가 있다"는 정보만으로 학습

### MIL의 수학적 정의

#### 표준 MIL 가정
- Bag X = {x₁, x₂, ..., xₙ}: n개의 instance 집합
- Bag 레이블 Y ∈ {0, 1}
- Instance 레이블 yᵢ ∈ {0, 1} (관측 불가)

#### MIL 규칙
```
Y = 1 (Positive Bag) ⟺ ∃i : yᵢ = 1 (최소 하나의 positive instance)
Y = 0 (Negative Bag) ⟺ ∀i : yᵢ = 0 (모든 instance가 negative)
```

#### 확률적 표현
```
P(Y=1|X) = 1 - ∏ᵢ₌₁ⁿ (1 - P(yᵢ=1|xᵢ))
```

이 수식은 "Bag이 positive일 확률은 모든 instance가 negative일 확률의 여집합"을 의미합니다.

### 본 연구에서의 MIL 적용

#### 개념 매핑
```
문서 (Bag)
├── 슬라이딩 윈도우 1: [단어1, 단어2, 단어3, 단어4, 단어5] → Instance 1
├── 슬라이딩 윈도우 2: [단어2, 단어3, 단어4, 단어5, 단어6] → Instance 2
├── ...
└── 슬라이딩 윈도우 N: [단어N-4, 단어N-3, 단어N-2, 단어N-1, 단어N] → Instance N

Bag 레이블: 
- 0 = 단일 작성자 문서 (모든 instance가 같은 작성자)
- 1 = 복수 작성자 문서 (일부 instance가 다른 작성자)
```

#### 왜 슬라이딩 윈도우인가?

1. **필기 패턴 보존**: 단일 단어는 작성자 특성을 충분히 담지 못하지만, 연속된 5개 단어는 필압, 간격, 기울기 등의 패턴을 보존합니다.

2. **컨텍스트 정보**: 작성자는 문맥에 따라 필기 스타일을 미세하게 조정하므로, 연속된 단어들이 더 풍부한 정보를 제공합니다.

3. **중첩을 통한 강건성**: stride=1로 중첩된 윈도우는 경계 부분에서의 정보 손실을 방지합니다.

## 3. 3단계 기술 아키텍처 상세

### Step 1: Vision Transformer + ArcFace를 통한 강력한 특징 학습

#### Vision Transformer (ViT)의 선택 이유

1. **전역적 패턴 인식**: CNN과 달리 ViT는 이미지 전체의 관계를 한 번에 파악할 수 있어, 필기체의 전반적인 스타일을 효과적으로 학습합니다.

2. **패치 기반 처리**: ViT의 16×16 패치 분할은 필기체의 작은 획 단위 특징을 포착하는 데 적합합니다.

3. **사전학습의 이점**: ImageNet 등으로 사전학습된 ViT를 300명 작성자 분류로 fine-tuning하여 효율적인 학습이 가능합니다.

#### ArcFace Loss의 혁신성

**기존 Softmax Loss의 한계**:
```
L_softmax = -log(e^(W_yi^T x + b_yi) / Σⱼ e^(W_j^T x + b_j))
```
- 단순히 올바른 클래스의 확률을 높이는 데만 집중
- 클래스 간 경계가 모호함

**ArcFace Loss의 개선**:
```
L_arcface = -log(e^(s·cos(θ_yi + m)) / (e^(s·cos(θ_yi + m)) + Σⱼ≠yi e^(s·cos θ_j)))

여기서:
- θ_yi: 특징 벡터와 yi번째 가중치 벡터 간의 각도
- m: 각도 마진 (일반적으로 0.5)
- s: 스케일 팩터 (일반적으로 64)
```

**ArcFace의 기하학적 의미**:
1. **각도 기반 거리**: 유클리드 거리 대신 코사인 유사도(각도)를 사용하여 고차원 공간에서 더 안정적
2. **마진 추가**: 같은 클래스 내에서도 m만큼의 여유를 두어 더 견고한 특징 학습
3. **하이퍼스피어 매핑**: 모든 특징을 단위 구면에 매핑하여 비교 가능하게 만듦





#### Attention 메커니즘의 해석

Attention 가중치는 모델이 각 instance를 얼마나 "의심스럽게" 보는지를 나타냅니다:
- **높은 가중치**: 다른 작성자의 패치로 의심되는 부분
- **낮은 가중치**: 주 작성자와 일치하는 부분

이를 통해 모델의 판단 근거를 시각화하고 해석할 수 있습니다.

## 4. 핵심 혁신점과 기술적 기여

### 문제 정의의 패러다임 전환

#### 기존 패러다임의 한계
- **1:1 비교의 비현실성**: 실제 상황에서는 비교할 진본 문서가 없는 경우가 많음
- **전체 문서 수준 분석**: 부분 위조를 놓칠 가능성이 높음
- **이진 판별의 단순성**: "같다/다르다"만으로는 복잡한 현실을 반영하지 못함

#### 새로운 패러다임의 장점
- **단일 문서 분석**: 의심 문서 하나만으로 판별 가능
- **세밀한 부분 탐지**: 문서 내 어느 부분이 의심스러운지 지적 가능
- **확률적 판단**: 복수 작성자 존재 확률을 제시하여 더 유연한 의사결정 지원

### 약지도 학습의 실용적 가치

#### 라벨링 비용 비교
| 접근법 | 필요 라벨 수 | 라벨링 시간 | 전문가 필요 |
|--------|------------|-----------|------------|
| 완전 지도학습 | 단어당 1개 | 문서당 수 시간 | 필수 |
| MIL (본 연구) | 문서당 1개 | 문서당 수 초 | 최소 |

#### 확장성과 적용성
1. **다양한 언어 적용**: 한국어, 중국어, 아랍어 등 다양한 문자 체계에 쉽게 적용
2. **도메인 확장**: 서명, 그림, 도장 등 다른 형태의 진위 판별로 확장 가능
3. **실시간 처리**: 라벨링 부담이 적어 대규모 실시간 스크리닝 가능

### 법의학적 활용 시나리오

#### 법정 증거로서의 활용
1. **객관적 수치 제시**: "이 문서가 복수 작성자일 확률은 87.3%입니다"
2. **증거 위치 특정**: "문서의 3번째 단락이 가장 의심스럽습니다"
3. **재현 가능성**: 동일한 모델로 반복 검증 가능



## 5. 데이터셋과 실험 설계

### CSAFE 영어 필기 데이터셋 상세

#### 데이터 수집 프로토콜
1. **참가자**: 300명의
2. **수집 환경**: 통제된 실험실 환경
3. **필기 도구**: 동일한 펜과 종이 제공
4. **작성 내용**:
   - WOZ: "The Wizard of Oz" 발췌문 (서사적 텍스트)
   - LND: London Letter (공식적 편지 형식)
   - PHR: 일상 구문 모음

#### 데이터 전처리 파이프라인
```
원본 문서 스캔 (300 DPI)
    ↓
텍스트 영역 검출 (EasyOCR)
    ↓
단어 단위 분할
    ↓
크기 정규화 (224×224)
    ↓
그레이스케일 변환
    ↓
품질 검증 (blur, contrast 체크)
    ↓
메타데이터 생성 (작성자, 세션, 단어 정보)
```

#### 데이터 분할 전략
- **학습 세트**: 0-179 라벨 (180명, 60%)
- **검증 세트**: 180-239 라벨 (60명, 20%)
- **테스트 세트**: 240-299 라벨 (60명, 20%)

**중요**: 작성자 단위로 분할하여 학습 시 본 적 없는 작성자로 평가

### 평가 메트릭과 성공 기준

#### 주요 평가 지표
1. **정확도 (Accuracy)**: 전체 예측 중 맞은 비율
2. **AUC-ROC**: 다양한 임계값에서의 성능 종합 평가
3. **F1 Score**: 정밀도와 재현율의 조화 평균
4. **Confusion Matrix**: 오류 유형 분석



## 6. 도전 과제와 향후 연구 방향

### 현재의 기술적 도전

1. **클래스 불균형**: 실제로는 단일 작성자 문서가 훨씬 많음
2. **미세한 신호**: 전체 문서에서 작은 부분만 다른 경우 탐지 어려움
3. **도메인 적응**: 영어 → 한국어 등 다른 언어로의 전이 학습

### 향후 연구 확장

#### 단기 목표 (6개월)
1. **성능 향상**: 현재 55% → 목표 80% 정확도
2. **한국어 데이터셋 구축**: 300명 규모의 한글 필기 데이터
3. **실시간 처리**: 문서당 1초 이내 처리 달성

#### 중장기 비전 (1-2년)
1. **다중 작성자 수 예측**: 2명, 3명, 4명 이상 구분
2. **작성자 식별**: 단순 탐지를 넘어 "누가" 작성했는지 식별
3. **시간적 분석**: 문서 작성 시점 추정 (잉크 번짐, 필압 변화 등)



## 7. 선행 연구와의 관계 및 학술적 의의

### Kim, Park, Carriquiry (2024) 연구의 핵심 통찰

#### 주요 발견
1. **Vision Transformer의 우수성**: CNN 기반 모델(ResNet, EfficientNet) 대비 5-10% 높은 성능
2. **Autoencoder vs Siamese**: 문서 간 비교에서는 Autoencoder가 더 효과적
3. **전처리의 중요성**: 부트스트래핑 기법이 성능을 크게 향상

#### 본 연구와의 시너지
```
Kim et al. (2024): 문서 A ↔ 문서 B 비교 (Foundation)
        ↓
본 연구: 문서 A 내부 분석 (Extension)
        ↓
통합 시스템: 완전한 문서 분석 플랫폼 (Future)
```

### 학술적 기여와 혁신성

1. **새로운 문제 정의**: 필기 분석 분야에 "문서 내 복수 작성자 탐지"라는 새로운 연구 영역 개척

2. **방법론적 혁신**: MIL을 필기 분석에 최초로 적용하여 약지도 학습의 가능성 입증

3. **실용적 브리지**: 학술 연구와 실제 법의학 현장 사이의 간극을 메우는 실용적 솔루션

4. **학제간 융합**: 컴퓨터 비전, 패턴 인식, 법의학, 통계학의 교차점에서 새로운 가치 창출

## 8. 코드 파이프라인 구조

### 전체 파이프라인 개요

MIL 프로젝트는 실질적으로 **3개의 핵심 Jupyter Notebook**으로 구성된 파이프라인입니다:

```
1. ArcFace 특징 추출 (train_arcface.ipynb)
   ↓
2. MIL Bag 생성 (mil_data_generator2_arcface.ipynb)
   ↓
3. MIL 모델 학습 및 평가 (AB_MIL_arcface_300d.ipynb)
```

**참고**: Vision Transformer + ArcFace 사전학습 모델(`csafe_vit_300classes_best_model.pth`)을 사용하며, 데이터는 이미 준비되어 있습니다 

### 단계별 상세 설명

#### Stage 1: ArcFace 특징 추출
**파일**: `experiments/arcface/train_arcface.ipynb`

**목적**: 사전학습된 Vision Transformer + ArcFace 모델을 사용하여 각 단어 이미지에서 작성자 구분에 최적화된 300차원 특징 벡터를 추출합니다.

**입력**: 
- 단어 이미지 (224×224로 정규화)
- 사전학습 모델: `csafe_vit_300classes_best_model.pth`

**출력**: 
- 특징 벡터 CSV 파일 (300차원 임베딩)

#### Stage 2: MIL Bag 생성
**파일**: `experiments/arcface/mil_data_generator2_arcface.ipynb`

**목적**: 특징 벡터들을 MIL 학습에 적합한 Bag 형태로 구성합니다.

**핵심 처리**:
1. **슬라이딩 윈도우**: 5개 연속 단어를 하나의 Instance로 구성
2. **단일 작성자 Bag**: 한 작성자의 한 문서에서 모든 윈도우 추출
3. **복수 작성자 Bag**: 블록 단위(10개 윈도우)로 30%를 다른 작성자의 패치로 교체

**출력**: 
- Train/Val/Test Bag 데이터셋 (Pickle 파일)
- 각 Bag은 여러 Instance(300차원)의 집합

#### Stage 3: MIL 모델 학습 및 평가
**파일**: `experiments/arcface/AB_MIL_arcface_300d.ipynb`

**목적**: Attention 기반 MIL 모델을 학습하여 문서 내 복수 작성자를 탐지합니다.

**모델 특징**:
- **Attention Network**: 각 Instance의 중요도를 자동으로 학습
- **분류기**: Attention 가중 평균을 통한 Bag 수준 판별
- **입력 차원**: 300 (ArcFace 특징 벡터 차원)

**평가 메트릭**:
- 정확도, AUC-ROC, F1 Score
- Attention 가중치 시각화 (어떤 부분이 의심스러운지)
- 난이도별 성능 분석 (교체 비율, 작성자 수)

**출력**:
- 학습된 모델 가중치
- 성능 평가 결과 및 시각화

### 파이프라인 실행 순서

```bash
# Step 1: ArcFace 특징 추출
jupyter notebook experiments/arcface/train_arcface.ipynb

# Step 2: MIL Bag 생성
jupyter notebook experiments/arcface/mil_data_generator2_arcface.ipynb

# Step 3: MIL 학습 및 평가
jupyter notebook experiments/arcface/AB_MIL_arcface_300d.ipynb
```

### 핵심 설정값

| 단계 | 파라미터 | 값 | 설명 |
|------|---------|-----|------|
| **특징 추출** | 입력 크기 | 224×224 | 표준 ViT 입력 |
| | 출력 차원 | 300 | ArcFace 임베딩 |
| **Bag 생성** | 윈도우 크기 | 5 | 연속 단어 수 |
| | 블록 크기 | 10 | 교체 단위 |
| | 교체 비율 | 30% | 복수 작성자 비율 |
| **MIL 학습** | Hidden dim | 128 | Attention 네트워크 |
| | Learning rate | 1e-4 | Adam optimizer |
| | Batch size | 128 | GPU 메모리 고려 |

---

## 결론

본 연구는 "문서 내 복수 작성자 탐지"라는 도전적인 문제를 MIL 프레임워크와 최신 딥러닝 기술을 결합하여 해결하고자 합니다. Vision Transformer와 ArcFace로 강력한 작성자별 특징을 학습하고, Attention 기반 MIL로 문서 내 숨겨진 이질성을 탐지하는 이 접근법은 법의학 문서 분석의 새로운 지평을 열 것으로 기대됩니다.

**"진실은 디테일에 있다"** - 본 연구가 추구하는 철학입니다.