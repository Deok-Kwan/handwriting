# MIL + Siamese Network ì‹¤í—˜ í™˜ê²½ êµ¬ì¶• ê°€ì´ë“œ

## ğŸ“ í•„ìš”í•œ íŒŒì¼ ëª©ë¡

### 1. ì—…ë¡œë“œí•´ì•¼ í•  íŒŒì¼ë“¤
```
# ë°ì´í„° íŒŒì¼
- naver_ocr.csv (ì›ë³¸ ê²½ë¡œ: /data/csafeproject/another_datas/CSAFE/naver_ocr.csv)
- csafe_version5_xai_train/ í´ë”ì˜ ì´ë¯¸ì§€ë“¤ (ì„ íƒì‚¬í•­, CSVì— ê²½ë¡œë§Œ ìˆìœ¼ë©´ ë¨)

# ëª¨ë¸ ê°€ì¤‘ì¹˜
- csafe_vit_300classes_best_model.pth (ì›ë³¸ ê²½ë¡œ: /data/csafeproject/CSAFE_version5/trained_model/)

# ì½”ë“œ íŒŒì¼
- mil_data_generator.ipynb
- mil_data_generator2.ipynb
- AB_MIL_autoencoder_128d.ipynb
```

## ğŸ› ï¸ í™˜ê²½ ì„¤ì •

### Step 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html
pip install timm==0.4.12
pip install pandas numpy tqdm scikit-learn matplotlib seaborn
pip install pillow
```

### Step 2: ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
```bash
mkdir -p data/images
mkdir -p models
mkdir -p notebooks
mkdir -p output/csv
mkdir -p output/pkl
```

## ğŸ“ ì‹¤í–‰ ìˆœì„œ

### 1. Siamese Network í•™ìŠµ (ìƒˆë¡œ ì‘ì„± í•„ìš”)

`train_siamese.ipynb` ìƒì„±:
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from PIL import Image
import timm
from tqdm import tqdm
import random

# 1. Siamese Network ì •ì˜
class SiameseNetwork(nn.Module):
    def __init__(self, base_model, embedding_dim=128):
        super(SiameseNetwork, self).__init__()
        self.base_model = base_model
        self.embedding_layer = nn.Sequential(
            nn.Linear(300, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, embedding_dim),
            nn.BatchNorm1d(embedding_dim)
        )
        
    def forward_one(self, x):
        x = self.base_model(x)
        x = self.embedding_layer(x)
        return F.normalize(x, p=2, dim=1)
    
    def forward(self, x1, x2):
        out1 = self.forward_one(x1)
        out2 = self.forward_one(x2)
        return out1, out2

# 2. Contrastive Loss
class ContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin
    
    def forward(self, out1, out2, label):
        distance = F.pairwise_distance(out1, out2)
        loss = torch.mean((1-label) * torch.pow(distance, 2) +
                         label * torch.pow(torch.clamp(self.margin - distance, min=0.0), 2))
        return loss

# 3. Dataset í´ë˜ìŠ¤
class SiameseHandwritingDataset(Dataset):
    def __init__(self, df, transform):
        self.df = df
        self.transform = transform
        self.label_groups = df.groupby('label').groups
        self.labels = list(self.label_groups.keys())
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        # 50% í™•ë¥ ë¡œ positive/negative pair ìƒì„±
        if random.random() > 0.5:
            # Positive pair (ê°™ì€ ì‘ì„±ì)
            label = self.df.iloc[idx]['label']
            indices = self.label_groups[label]
            positive_idx = random.choice(indices)
            
            img1_path = self.df.iloc[idx]['image_path']
            img2_path = self.df.iloc[positive_idx]['image_path']
            label_tensor = torch.tensor(0.0)  # ê°™ì€ ì‘ì„±ì = 0
        else:
            # Negative pair (ë‹¤ë¥¸ ì‘ì„±ì)
            label1 = self.df.iloc[idx]['label']
            label2 = random.choice([l for l in self.labels if l != label1])
            negative_idx = random.choice(self.label_groups[label2])
            
            img1_path = self.df.iloc[idx]['image_path']
            img2_path = self.df.iloc[negative_idx]['image_path']
            label_tensor = torch.tensor(1.0)  # ë‹¤ë¥¸ ì‘ì„±ì = 1
        
        img1 = Image.open(img1_path).convert('RGB')
        img2 = Image.open(img2_path).convert('RGB')
        
        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)
            
        return img1, img2, label_tensor

# 4. í•™ìŠµ ì½”ë“œ
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Transform ì •ì˜
import torchvision.transforms as transforms
transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.Grayscale(num_output_channels=1),
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# ë°ì´í„° ë¡œë“œ
data = pd.read_csv('naver_ocr.csv')
data = data[data['label'] > 299].reset_index(drop=True)

# Train/Val ë¶„í• 
train_data = data[(data['label'] >= 300) & (data['label'] <= 414)]
val_data = data[(data['label'] > 414) & (data['label'] <= 444)]

# Dataset ë° DataLoader
train_dataset = SiameseHandwritingDataset(train_data, transform)
val_dataset = SiameseHandwritingDataset(val_data, transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

# ëª¨ë¸ ì´ˆê¸°í™”
base_model = timm.create_model('vit_base_patch16_224', pretrained=True)
base_model.head = nn.Linear(base_model.head.in_features, 300)
base_model.load_state_dict(torch.load('csafe_vit_300classes_best_model.pth'))

siamese_model = SiameseNetwork(base_model, embedding_dim=128).to(device)

# ì˜µí‹°ë§ˆì´ì € ë° ì†ì‹¤í•¨ìˆ˜
optimizer = torch.optim.Adam(siamese_model.parameters(), lr=0.0001)
criterion = ContrastiveLoss(margin=1.0)

# í•™ìŠµ
num_epochs = 20
best_loss = float('inf')

for epoch in range(num_epochs):
    # Training
    siamese_model.train()
    train_loss = 0.0
    for img1, img2, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):
        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)
        
        optimizer.zero_grad()
        out1, out2 = siamese_model(img1, img2)
        loss = criterion(out1, out2, labels)
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item()
    
    # Validation
    siamese_model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for img1, img2, labels in val_loader:
            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)
            out1, out2 = siamese_model(img1, img2)
            loss = criterion(out1, out2, labels)
            val_loss += loss.item()
    
    avg_train_loss = train_loss / len(train_loader)
    avg_val_loss = val_loss / len(val_loader)
    
    print(f'Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')
    
    # Save best model
    if avg_val_loss < best_loss:
        best_loss = avg_val_loss
        torch.save(siamese_model.state_dict(), 'siamese_best_model.pth')
        print('Model saved!')
```

### 2. mil_data_generator.ipynb ìˆ˜ì •

ê¸°ì¡´ ì½”ë“œì—ì„œ ë‹¤ìŒ ë¶€ë¶„ë§Œ ìˆ˜ì •:

```python
# ê¸°ì¡´ Autoencoder ëª¨ë¸ ëŒ€ì‹  Siamese ëª¨ë¸ ì‚¬ìš©
class SiameseEmbedder(nn.Module):
    def __init__(self, siamese_model):
        super().__init__()
        self.siamese_model = siamese_model
    
    def get_latent_vector(self, x):
        return self.siamese_model.forward_one(x)

# ëª¨ë¸ ë¡œë“œ ë¶€ë¶„ ìˆ˜ì •
base_model = timm.create_model('vit_base_patch16_224', pretrained=True)
base_model.head = nn.Linear(base_model.head.in_features, 300)
base_model.load_state_dict(torch.load('csafe_vit_300classes_best_model.pth'))

siamese_model = SiameseNetwork(base_model, embedding_dim=128)
siamese_model.load_state_dict(torch.load('siamese_best_model.pth'))
modified_model = SiameseEmbedder(siamese_model).to(device)

# data_info ë³€ê²½
data_info = 'siamese_128d'

# ì¶œë ¥ íŒŒì¼ëª…ì´ ìë™ìœ¼ë¡œ ë³€ê²½ë¨:
# mil_siamese_128d_train_data.csv
# mil_siamese_128d_val_data.csv
# mil_siamese_128d_test_data.csv
```

### 3. mil_data_generator2.ipynb ìˆ˜ì •

ì…ë ¥ íŒŒì¼ëª…ë§Œ ë³€ê²½:
```python
data_info = 'siamese_128d'  # 'autoencoder_128d' ëŒ€ì‹ 
train_file = f"mil_{data_info}_train_data.csv"
val_file = f"mil_{data_info}_val_data.csv"
test_file = f"mil_{data_info}_test_data.csv"

# ì¶œë ¥ íŒŒì¼:
# train_bags_siamese_128d.pkl
# val_bags_siamese_128d.pkl
# test_bags_siamese_128d.pkl
```

### 4. AB_MIL_autoencoder_128d.ipynb ìˆ˜ì •

ë°ì´í„° ë¡œë“œ ë¶€ë¶„ë§Œ ë³€ê²½:
```python
# ë°ì´í„° ë¡œë“œ
train_bags = pd.read_pickle("train_bags_siamese_128d.pkl")
val_bags = pd.read_pickle("val_bags_siamese_128d.pkl")
test_bags = pd.read_pickle("test_bags_siamese_128d.pkl")

# ëª¨ë¸ ì €ì¥ ì´ë¦„ ë³€ê²½
model_name = 'ab_mil_siamese_128d'
```

## âš ï¸ ì¤‘ìš” ì‚¬í•­

1. **ê²½ë¡œ ìˆ˜ì •**: ëª¨ë“  íŒŒì¼ ê²½ë¡œë¥¼ ìƒˆë¡œìš´ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
2. **GPU ë©”ëª¨ë¦¬**: ë°°ì¹˜ í¬ê¸° ì¡°ì • í•„ìš”ì‹œ train_loaderì˜ batch_size ìˆ˜ì •
3. **ë°ì´í„° ê²½ë¡œ**: naver_ocr.csvì˜ image_pathê°€ ì‹¤ì œ ì´ë¯¸ì§€ ìœ„ì¹˜ë¥¼ ê°€ë¦¬í‚¤ë„ë¡ ìˆ˜ì •
4. **ì €ì¥ ê²½ë¡œ**: ëª¨ë“  ì¶œë ¥ íŒŒì¼ ê²½ë¡œ í™•ì¸

## ğŸ¯ ì˜ˆìƒ ê²°ê³¼

1. Siamese ë„¤íŠ¸ì›Œí¬ í•™ìŠµ í›„: `siamese_best_model.pth` ìƒì„±
2. ìƒˆë¡œìš´ ì„ë² ë”©ìœ¼ë¡œ CSV ìƒì„±: `mil_siamese_128d_*.csv` íŒŒì¼ë“¤
3. Bag ë°ì´í„° ìƒì„±: `*_bags_siamese_128d.pkl` íŒŒì¼ë“¤
4. MIL ëª¨ë¸ í•™ìŠµ: ê¸°ì¡´ 50% ì •í™•ë„ë³´ë‹¤ í–¥ìƒëœ ê²°ê³¼ ê¸°ëŒ€

## ğŸ“Š ì„±ëŠ¥ ê²€ì¦

Siamese ì„ë² ë”©ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì—ˆëŠ”ì§€ í™•ì¸:
```python
# t-SNE ì‹œê°í™”
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# ì„ë² ë”© ì¶”ì¶œ í›„
embeddings = []
labels = []
# ... ì„ë² ë”© ì¶”ì¶œ ì½”ë“œ ...

tsne = TSNE(n_components=2, random_state=42)
embeddings_2d = tsne.fit_transform(embeddings)

plt.figure(figsize=(10, 8))
scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap='tab20', alpha=0.6)
plt.colorbar(scatter)
plt.title('Siamese Embeddings t-SNE Visualization')
plt.show()
```

ì‘ì„±ìë³„ë¡œ í´ëŸ¬ìŠ¤í„°ê°€ í˜•ì„±ë˜ë©´ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµëœ ê²ƒì…ë‹ˆë‹¤.