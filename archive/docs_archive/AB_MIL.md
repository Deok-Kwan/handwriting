## 복수 필체 문서 분석을 위한 MIL 기반 딥러닝 연구 프로젝트 인수인계 자료

안녕하세요.
본 문서는 "복수 필체 문서 분석을 위한 MIL 기반 딥러닝 연구" 프로젝트의 현황과 향후 방향을 공유하기 위해 작성되었습니다. 이 자료를 통해 프로젝트의 맥락을 이해하고, 현재까지의 진행 상황과 분석 결과를 바탕으로 성공적으로 연구를 이어나가시길 바랍니다.

---

### **1. 연구 개요 (Project Overview)**

*   **연구 목표 (Core Objective):**
    법과학 분야에서 활용할 수 있는, **여러 사람의 필적이 섞인 문서(복수 필체 문서)**를 자동으로 분석하는 딥러닝 모델을 개발하는 것입니다. 최종적으로는 문서 내에 특정 작성자의 필적이 포함되어 있는지, 있다면 어느 부분에 기여했는지를 식별하는 것을 목표로 합니다.

*   **핵심 접근 방식 (Core Approach):**
    1.  **Multiple Instance Learning (MIL):** 문서 전체를 **Bag**으로, 문서 내 개별 필적 조각(패치)을 **Instance**로 정의하여, 문서 전체 수준의 레이블(단일/복수 작성자)만으로 학습하는 접근 방식을 채택했습니다.
    2.  **패치 기반 분석 (Patch-based Analysis):** 문서 이미지를 작은 패치로 분할하여 필적의 세밀한 특징 손실을 최소화하고, 효율적으로 학습합니다.
    3.  **합성 데이터 생성 (Synthetic Data Generation):** 실제 복수 필체 문서 확보의 어려움을 해결하기 위해, 단일 작성자 문서에서 일부 필적을 다른 작성자의 것으로 교체하여 **합성 복수 필체 데이터**를 생성하여 사용합니다.

*   **기대 효과 (Expected Outcomes):**
    복수 필체 문서에 대한 신뢰도 높은 자동 분석 시스템을 구축하고, Attention 메커니즘을 통해 모델의 판단 근거(중요 필적 영역)를 시각화하여 법과학 분야에 실질적인 도움을 주는 것을 기대합니다.

---

### **2. 현재까지의 진행 상황 (Progress to Date)**

프로젝트는 크게 **(A) 데이터 준비 및 패치 생성 → (B) 특징 벡터 추출 → (C) MIL Bag 데이터셋 구축 → (D) 모델 학습 및 평가**의 4단계로 진행되었습니다.

**(A) 데이터 준비 및 패치 생성 (`train/val/test_generator.ipynb`)**
*   **작업 내용:** 원본 필적 이미지(`original/`)를 MIL의 Instance로 사용하기 위한 작은 패치들로 변환했습니다.
*   **처리 과정:**
    1.  원본 파일명을 파싱하여 작성자 ID(`label`), 문서 ID(`repeat`) 등의 메타데이터를 추출했습니다.
    2.  `label`을 기준으로 Train/Validation/Test 데이터셋을 분할했습니다.
    3.  아래 3가지 전략으로 패치를 생성하여 각각 다른 폴더에 저장했습니다.
        *   **`simple_split`:** 이미지를 224x224 크기로 균등 분할.
        *   **`text_detection`:** EasyOCR을 사용해 텍스트 영역만 정확히 추출.
        *   **`bootstrapping`:** 텍스트 영역 주변에서 무작위로 패치를 다수 추출 (데이터 증강 효과).

**(B) 특징 벡터 추출 (`mil_data_generator.ipynb`)**
*   **작업 내용:** (A)에서 생성된 이미지 패치들을 딥러닝 모델이 처리할 수 있는 숫자 형태의 **임베딩(특징) 벡터**로 변환했습니다.
*   **핵심 요소:**
    *   **`modified_model`:** 사전 훈련된 Autoencoder의 인코더 부분으로, 이미지 패치를 입력받아 **128차원 벡터**를 출력합니다.
    *   **`naver_ocr.csv`:** 각 패치의 경로, 작성자 `label`, OCR로 인식된 `text` 정보를 담은 메타데이터 파일입니다.
*   **처리 과정:** `naver_ocr.csv`의 이미지 경로를 따라 패치를 로드하고, `modified_model`을 통과시켜 128차원 벡터를 추출한 후, 이 벡터를 메타데이터와 함께 새로운 CSV 파일로 저장했습니다.

**(C) MIL Bag 데이터셋 구축 (`mil_data_generator.ipynb2`)**
*   **작업 내용:** (B)에서 생성된 인스턴스(특징 벡터)들을 묶어 MIL 학습에 사용할 Bag 데이터셋을 구축했습니다. **이 단계가 연구의 핵심적인 가설 검증 부분입니다.**
*   **처리 과정:**
    1.  **False Bag (단일 작성자):** 동일 작성자(`label`)와 동일 문서(`repeat`)에 속한 모든 인스턴스 벡터들을 하나의 Bag으로 묶고, 레이블을 `False`로 지정했습니다.
    2.  **True Bag (합성 복수 작성자):** False Bag을 기반으로, 그 안의 인스턴스 중 **단 하나**를 다른 작성자의 인스턴스 벡터로 **교체**했습니다. 이 Bag의 레이블은 `True`로 지정했습니다.
*   **출력:** 최종적으로 모델 학습에 사용될 Train/Validation/Test Bag 데이터셋을 Pickle 파일(`.pkl`)로 저장했습니다.

**(D) 모델 학습 및 평가 (`AB_MIL_autoencoder_128d.ipynb`)**
*   **작업 내용:** (C)에서 생성된 Bag 데이터셋으로 Attention-Based MIL 모델을 학습하고 평가했습니다.
*   **모델:** 각 Instance의 중요도를 학습하여 Bag 전체의 레이블을 예측하는 `ABMILModel`을 사용했습니다.
*   **학습:** Train 데이터로 모델을 학습시키고, Validation 데이터로 성능을 검증하며 Early Stopping을 적용했습니다.

---

### **3. 주요 결과 및 분석 (Key Results & Analysis)**

*   **결과 요약:**
    *   **Test Accuracy: 0.5019 (50.2%)**
    *   **Test AUC: 0.4971 (0.5에 근접)**
    *   **결론:** 최종 모델 성능은 **완전한 무작위 추측(Random Guessing) 수준**입니다. 학습 로그를 보면, Train/Val Loss가 `ln(2) ≈ 0.693`에서 전혀 감소하지 않았으며, 이는 모델이 데이터로부터 **어떠한 유의미한 패턴도 학습하지 못했음**을 의미합니다.

*   **핵심 원인 분석:**
    1.  **임베딩 벡터의 표현력 부족:**
        *   **가장 큰 원인으로 추정됩니다.** `modified_model`(Autoencoder)이 생성하는 128차원 벡터가 필적의 "스타일"이나 "작성자 고유의 습관"을 구분할 만큼의 정보를 담고 있지 못합니다. 재구성(Reconstruction)에 초점을 맞춘 Autoencoder의 특성상, 작성자 식별(Discrimination)에 필요한 미세한 특징을 학습하지 못했을 가능성이 매우 높습니다.
    2.  **합성 데이터의 변별력 한계:**
        *   전체 Bag(최대 75개 인스턴스)에서 **단 하나의 인스턴스만 교체**한 방식은 True Bag과 False Bag 간의 차이를 **너무 미미하게** 만들었습니다. 모델이 이 미세한 신호 차이를 감지하고 학습하기에는 역부족이었습니다.
    3.  **종합 결론 (Garbage In, Garbage Out):**
        *   **표현력 없는 임베딩 벡터 (Garbage In)**를 사용하여 **변별력 없는 데이터셋**을 만들었기 때문에, MIL 모델이 학습할 수 있는 의미 있는 패턴이 존재하지 않았고, 결국 **무의미한 결과 (Garbage Out)**로 이어졌습니다.

---

### **4. 향후 연구를 위한 제언 (Recommendations for Future Research)**

현재 결과는 실패가 아닌, "이 접근법으로는 어렵다"는 중요한 것을 배운 과정입니다. 다음 단계는 명확합니다.

*   **최우선 과제: 임베딩 벡터 개선 (Task-Specific Embedding)**
    *   **방법 1 (강력 추천): Siamese 또는 Triplet Network 도입:**
        *   "같은 작성자의 필적은 가깝게, 다른 작성자의 필적은 멀게" 임베딩하도록 명시적으로 학습하는 네트워크입니다. 이를 통해 **작성자 식별에 최적화된 임베딩 공간**을 학습할 수 있습니다. 이렇게 학습된 인코더를 새로운 `modified_model`로 사용해야 합니다.
    *   **방법 2: 기존 모델 Fine-tuning:**
        *   현재 Autoencoder 인코더에 분류 레이어를 추가하여, 작성자 `label`을 맞추는 Task로 추가 학습(Fine-tuning)시켜 임베딩의 표현력을 높입니다.

*   **차순위 과제: 합성 데이터 생성 방식 고도화**
    *   **다중 인스턴스/영역 교체:** 단일 인스턴스가 아닌, **연속된 여러 인스턴스(문장, 단어 단위) 또는 특정 영역을 교체**하여 True/False Bag 간의 차이를 명확하게 만들어야 합니다.
    *   **필적량 조절:** 복수 작성자의 기여도(예: 9:1, 7:3, 5:5)를 다양하게 조절하여 더 현실적인 데이터를 생성해야 합니다.

*   **기타 제언:**
    *   **MIL 모델 구조 변경:** 임베딩과 데이터 문제가 해결된 후, Gated-Attention MIL 등 더 정교한 모델을 시도해볼 수 있습니다.
    *   **분석 목표 확장:** 모델이 True/False 예측을 넘어, Bag 내에 어떤 작성자들이 포함되었는지(Multi-label) 예측하도록 확장하는 것을 고려할 수 있습니다.
    *   **Attention 시각화:** 모델이 유의미한 학습을 시작하면, Attention 가중치를 시각화하여 어떤 인스턴스가 판단에 중요한 영향을 미쳤는지 분석해야 합니다.

---

### **5. 프로젝트 자원 (Project Resources)**

*   **코드:**
    *   `train_generator.ipynb`, `validation_generator.ipynb`, `test_generator.ipynb`: 원본 이미지로부터 패치를 생성하는 코드.
    *   `mil_data_generator.ipynb`: 패치로부터 128차원 특징 벡터를 추출하는 코드.
    *   `mil_data_generator.ipynb2`: 특징 벡터를 묶어 최종 Bag 데이터셋(.pkl)을 생성하는 코드.
    *   `AB_MIL_autoencoder_128d.ipynb`: MIL 모델을 학습하고 평가하는 코드.
*   **데이터:**
    *   `/workspace/Hand/original/`: 원본 필적 이미지.
    *   `/workspace/Hand/{train/validation/test}_data/`: 생성된 패치 이미지.
    *   `/data/csafeproject/.../mil_*_data.csv`: 특징 벡터가 포함된 CSV 파일.
    *   `/data/csafeproject/.../*_bags_autoencoder_128d.pkl`: 모델 학습에 직접 사용된 최종 Pickle 파일.
*   **결과물:**
    *   `/data/csafeproject/.../trained_mil_model/`: 학습된 모델 가중치(.pt) 저장 경로.

---

